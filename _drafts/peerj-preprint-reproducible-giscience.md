---
layout: post
title: "Preprint \"Reproducible research and GIScience: an evaluation using AGILE conference papers\" published"
categories:
  - science
  - preprint
  - PeerJ
  - GIScience
  - 'AGILE conference'
  - 'open science'
  - 'open data'
  - 'open source'
  - geoinformatics
author: 'Daniel NÃ¼st'
---

[![screenshot of preprint landing page](/public/images/2018-03_preprint-screenshot.jpg)](https://doi.org/10.7287/peerj.preprints.26561v1)

Last week we published the first preprint coming out of the project. Read
_**"Reproducible research and GIScience: an evaluation using AGILE conference papers"**_ online at [PeerJ](https://peerj.com/preprints): 

**[https://doi.org/10.7287/peerj.preprints.26561v1](https://doi.org/10.7287/peerj.preprints.26561v1)**

**Abstract**

> _The demand for <!--more-->reproducibility of research is on the rise in disciplines concerned with data analysis and computational methods. In this work existing recommendations for reproducible research are reviewed and translated into criteria for assessing reproducibility of articles in the field of geographic information science (GIScience). Using a sample of GIScience research from the Association of Geographic Information Laboratories in Europe (AGILE) conference series, we assess the current state of reproducibility of publications in this field. Feedback on the assessment was collected by surveying the authors of the sample papers. The results show the reproducibility levels are low. Although authors support the ideals, the incentives are too small. Therefore we propose concrete actions for individual researchers and the AGILE conference series to improve transparency and reproducibility, such as imparting data and software skills, an award, paper badges, author guidelines for computational research, and Open Access publications._

It is a collaboration started at [one of our workshops](/2017/05/10/o2r-at-AGILE/) with contributions by o2r team members [Daniel](https://orcid.org/0000-0002-0024-5046) and [Markus](https://orcid.org/0000-0001-6651-0976) together with [Carlos Granell](https://orcid.org/0000-0003-1004-9695), [Barbara Hofer](https://orcid.org/0000-0001-7078-3766), [Frank Ostermann](https://orcid.org/0000-0002-9317-8291), [Rusne Sileryte](https://orcid.org/0000-0002-8245-3016) and [Valentina Cerutty](https://orcid.org/0000-0002-9612-1581).
We invite the AGILE community to comment on the preprint and look forward to discuss our findings at the upcoming [AGILE pre-conference workshop "Reproducible Research Publications"](http://o2r.info/reproducible-agile/).

**[Non-specialist summary](ttps://twitter.com/Protohedgehog/status/949315968903376896)** (feedback welcome!):

> More and more research uses algorithms to analyse data.
> That makes it harder for researchers to understand a scientific publication, because you need more than just the text to understand what is really going on.
> You need the software and the data to be able to tell if everything is done correctly.
> We take a look at the existing guides for such research and create our own criteria for research in geographic information science.
> We use the criteria to test how reproducible a set of papers from the AGILE conference are.
> The conference is quite established and the papers are of high quality because they were all suggested for the "best paper" awards at the conference.
>
> The results are quite bad!
> We could not re-create any of the analyses.
> Then we asked the authors of the papers we evaluated if they had considered that someone else might want to re-do their work.
> While they all think the idea is great, many said they do not have the time for it.
>
> The only way for researchers to have the time and resources to work in a way that is transparent to others is either to convince them of the importance, or to force them.
> We come up with a list of suggestions to publishers and scientific conference organisers to create enough reasons for researchers to publish science in a re-creatable way.
