I"£m<p><img src="/public/images/logo-transparent.png" alt="o2r logo" /></p>

<h1 id="opening-reproducible-research-research-project-website-and-blog">Opening Reproducible Research: research project website and blog</h1>

<p><strong>Blog post authors</strong>:</p>

<ul>

<li>Daniel N√ºst</li>

<li>Jan Koppe</li>

<li>Laura Goulier</li>

<li>Lukas Lohoff</li>

<li>Marc Schutzeichel</li>

<li>Markus Konkol</li>

<li>Matthias Hinz</li>

<li>R√©mi Rampin</li>

<li>Tom Niers</li>

<li>Vicky Steeves</li>

<li>Yousef Qamaz</li>

</ul>

<div style="page-break-before: always !important;"></div>

<h2 id="blog-posts">Blog posts</h2>

<div class="post">
<h3 class="post-title"><a href="/2020/06/15/lg/">Student Assistant Laura Goulier talking about her experience @ o2r</a></h3>
<span class="post-date">15 Jun 2020 | By Laura Goulier</span>
<p>‚ÄúGeoscientist with experience in or willingness to learn R programming for reproducible research wanted!‚Äù I had just completed a beginner course in R programming for my master‚Äôs thesis and saw my chance to further develop this knowledge and enter the geoinformatic field, also get a little away from the pure ecology of my master studies in landscape ecology. I had never before heard of the words ‚Äúreproducible research‚Äù, neither heard of any reason why this topic is of importance. I took the job and worked my way in. After a couple of months I had to realize that to publish my master‚Äôs thesis (<a href="https://doi.org/10.3390/ijerph17062025">Modelling of Urban Air Pollutant Concentrations with Artificial Neural Networks Using Novel Input Variables</a>) in an international journal, all code and data had to be made freely available to enable other researchers to fully understand and reuse my analysis. And there I was, as a landscape ecologist who believed I had nothing to do with reproducible research. Apparently it is not that simple after all.</p>

<p>During my work in the o2r project I experienced the whole range of reasons why people struggle so much making their work reproducible for others. The main argument, also for me, was this giant amount of additional work. Is it really worth it, I thought? I also believed I had my own structure while scripting and it is way easier for me not to script in order to make other people understand my analysis, but to make myself understand it. ‚ÄúI would have to spend an entire year of my PhD, just to prepare all scripts again for everyone to comprehend‚Äù, said some PhD students from the atmospheric sciences to me. The desire for reproducibility in research is not always an open door. But maybe it‚Äôs the same as for everything else. A clean method of working should always be the goal. A student in school should write cleanly so that the teacher can read his essay. Every company needs a well organised structure and a clean and transparent way of working to be successful. Scripting, so that only oneself and no one else can understand what has been calculated, may in the short term have its own order that the writer understands. After two years at the latest, however, not even the author himself looks through his work and could answer specific questions about his calculations. If we are honest, it happens far too often that we lose the overview in the chaos and don‚Äôt know exactly what we thought at that time, which scripts contain which results, how a certain parameter was calculated, how to see what the results would look like if we would change certain values. Getting it right from the beginning is not an extra effort, it is just a change in the way we work, which saves us time in the long run. And not only for us, but also for many others who no longer need to reask or redo the things themselves.</p>

<p>Now that I finished my master‚Äôs thesis, my time in the o2r project is over and I am starting my PhD at a research institute. During my job interview they asked me quite a lot of details about my work at o2r, about limitations, obstacles, about difficulties and successes. This signals to me that reproducibility is not only gladly implemented, but is also an inevitable change that everyone must consider and adapt to, even if it is sometimes bothersome and entails some difficulties that we did not have to think about before. For me, reproducibility also has a social component. To do things not only for oneself, but for making others‚Äô work easier and letting them benefit from one‚Äôs own method. For my PhD, I am taking along to learn this method of working at best practice, because it certainly takes a lot of training. As a beginner in the scientific world, I strongly hope for my PhD to also get help by detailed insights into the scripts of more experienced scientists in order to facilitate my entry into scientific work.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2020/04/26/Introducing-geoextent/">Introducing geoextent</a></h3>
<span class="post-date">26 Apr 2020 | By Yousef Qamaz, Daniel N√ºst</span>
<p><code class="highlighter-rouge">geoextent</code> is an easy to use library for extracting the geospatial extent from data files with multiple data formats.</p>

<p>Take a look at the <a href="https://github.com/o2r-project/geoextent.git">source code on GitHub</a>, the <a href="https://pypi.org/project/geoextent/">library on PyPI</a> and the <a href="https://o2r.info/geoextent/">documentation website</a>.
You can view and test geoextent implementation through interactive notebooks on <a href="https://mybinder.org">mybinder.org</a> with a click on the following binder.</p>

<p><a href="https://mybinder.org/v2/gh/o2r-project/geoextent/master"><img src="https://mybinder.org/badge_logo.svg" alt="Binder" /></a></p>

<p>Here is a small example how to use <code class="highlighter-rouge">geoextent</code>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>geoextent <span class="nt">-b</span> <span class="nt">-t</span> <span class="nt">-input</span><span class="o">=</span> <span class="s1">'cities_NL.csv'</span>
</code></pre></div></div>

<p>The output will show the rectangular bounding box, time interval and crs extracted from file data, as follow:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">{</span><span class="s1">'format'</span>: <span class="s1">'text/csv'</span>,
 <span class="s1">'crs'</span>: <span class="s1">'4326'</span>,
 <span class="s1">'tbox'</span>: <span class="o">[</span><span class="s1">'30.09.2018'</span>, <span class="s1">'30.09.2018'</span><span class="o">]</span>,
 <span class="s1">'bbox'</span>: <span class="o">[</span>4.3175, 51.434444, 6.574722, 53.217222]<span class="o">}</span>
</code></pre></div></div>

<p>The input file used above was obtained from <a href="https://sandbox.zenodo.org/record/256820#.XeGcJJko85k">Zenodo</a>.
The map below<!--more--> based on <a href="https://www.openstreetmap.org/export#map=8/52.347/5.446">OpenStreetMap</a> shows the area of extracted bounding box.</p>

<p><img src="https://i.imgur.com/3JICNjd.png" alt="" /></p>

<p>You can get quick usage help instructions on the command line, too:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>geoextent <span class="nt">--help</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>geoextent is a Python library <span class="k">for </span>extracting geospatial and temporal extents of a file or a directory of multiple geospatial data formats.

usage: geoextent <span class="o">[</span><span class="nt">-h</span><span class="o">]</span> <span class="o">[</span><span class="nt">-formats</span><span class="o">]</span> <span class="o">[</span><span class="nt">-b</span><span class="o">]</span> <span class="o">[</span><span class="nt">-t</span><span class="o">]</span> <span class="o">[</span><span class="nt">-input</span><span class="o">=</span> <span class="s1">'[filepath|input file]'</span><span class="o">]</span>

optional arguments:
  <span class="nt">-h</span>, <span class="nt">--help</span>            show <span class="nb">help </span>message and <span class="nb">exit</span>
  <span class="nt">-formats</span>              show supported formats
  <span class="nt">-b</span>, <span class="nt">--bounding-box</span>    extract spatial extent <span class="o">(</span>bounding box<span class="o">)</span>
  <span class="nt">-t</span>, <span class="nt">--time-box</span>        extract temporal extent
  <span class="nt">-input</span><span class="o">=</span> <span class="nv">INPUT</span><span class="o">=</span> <span class="o">[</span><span class="nv">INPUT</span><span class="o">=</span> ...]
                        input file or path

By default, both bounding box and temporal extent are extracted.

Examples:

geoextent path/to/geofile.ext
geoextent <span class="nt">-b</span> path/to/directory_with_geospatial_data
geoextent <span class="nt">-t</span> path/to/file_with_temporal_extent
geoextent <span class="nt">-b</span> <span class="nt">-t</span> path/to/geospatial_files


Supported formats:
- GeoJSON <span class="o">(</span>.geojson<span class="o">)</span>
- Tabular data <span class="o">(</span>.csv<span class="o">)</span>
- Shapefile <span class="o">(</span>.shp<span class="o">)</span>
- GeoTIFF <span class="o">(</span>.geotiff, .tif<span class="o">)</span>
</code></pre></div></div>

<h4 id="motivation">Motivation</h4>

<p>Geospatial properties of data can serve as a useful integrator of diverse data sets and can improve discovery of datasets.
However, spatial and temporal metadata is rarely used in common data repositories, such as <a href="https://zenodo.org/">Zenodo</a>.
Users may ask <em>what data is available for my area of interest over a specific time interval?</em>
This question formed the initial idea for creating a library that can serve as the basis for integration geospatial metadata in data repositories.
Because a core function is the extraction of the geospatial extent, we named it <strong><code class="highlighter-rouge">geoextent</code></strong>.
The data extracted using the library can be added to record metadata, which will allow users, specifically researchers, to find relevant data with less time and effort.</p>

<h4 id="origins">Origins</h4>

<p>The library‚Äôs source code is based on two groups projects (<a href="https://github.com/KathHv/geosoftware2_ct">Cerca Trova</a> and <a href="https://github.com/carobro/Geosoftware2">Die Gruppe 1</a>) of the study project <a href="https://geosoft2.github.io/2018.html">Enhancing discovery of geospatial datasets in data repositories</a>.
We decided to develop the library with Python as we plan to integrate it with o2r‚Äôs metadata extraction and processing tool <a href="https://github.com/o2r-project/o2r-meta"><code class="highlighter-rouge">o2r-meta</code></a>.</p>

<h4 id="process-of-creating-the-codebase">Process of creating the codebase</h4>

<p>Luckily we did not have to start from scratch but could make <code class="highlighter-rouge">geoextent</code> a reimplementation of existing prototypes.
We roughly followed these steps:</p>

<ul>
  <li>Evaluate the existing code of the <a href="https://geosoft2.github.io/2018.html">study project groups</a>
    <ul>
      <li>Review the code implementation</li>
      <li>Identify parts of the code that are re-usable</li>
    </ul>
  </li>
  <li>Integrate chosen parts</li>
  <li>Develop of core features</li>
  <li>Set up <a href="https://travis-ci.org/github/o2r-project/geoextent/">tests on Travis CI</a></li>
  <li>Publication of library <a href="https://pypi.org/project/geoextent/">on PyPI</a></li>
  <li>Writing library documentation using <a href="https://www.sphinx-doc.org/en/master/">Sphinx</a> and render it as part of the Travis CI process</li>
  <li>Adding introduction Notebooks for easy testing with <a href="https://mybinder.org/v2/gh/o2r-project/geoextent/master">MyBinder</a></li>
</ul>

<h4 id="current-features">Current features</h4>

<ul>
  <li>Extract bounding box.
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  geoextent -b -input= 'wf_100m_klas.tif'
</code></pre></div>    </div>
    <p>Output:</p>
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  {'format': 'image/tiff',
   'crs': '4326',
   'bbox': [5.91530075647532,
    50.3102519741084,
    9.46839871248415,
    52.5307755328733]}
</code></pre></div>    </div>
  </li>
  <li>Extract time interval
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  geoextent -t -input= 'muenster_ring_zeit.geojson'
</code></pre></div>    </div>
    <p>Output:</p>
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  {'format': 'application/geojson',
   'crs': 4326,
   'tbox': ['2018-11-14', '2018-11-14']}

</code></pre></div>    </div>
  </li>
  <li>Show coordinate reference system (CRS) used</li>
  <li>Supported formats:
    <ul>
      <li>GeoJSON (.geojson)</li>
      <li>Tabular data (.csv)</li>
      <li>Shapefile (.shp)</li>
      <li>GeoTIFF (.geotiff, .tif)</li>
    </ul>
  </li>
</ul>

<p>For more examples, see <a href="https://o2r.info/geoextent/">documentation</a>.</p>

<h4 id="next-steps">Next steps</h4>

<p>As an immediate next steps, we want to integrate the extraction of extents into <code class="highlighter-rouge">or2-meta</code> so that users creating an ERC will have to do less manual metadata creation.
We also hope that <code class="highlighter-rouge">geoextent</code> is useful to others and have plenty ideas about extending the library.
For example, being a Python project, we would like to explore integrating <code class="highlighter-rouge">geoextent</code> into Zenodo.
Most importantly, we will add support for multiple files and directories, but also further data formats - see <a href="https://github.com/o2r-project/geoextent/issues">project issues on GitHub</a>.
<em>We welcome your ideas, feature requests, comments, and of course contributions!</em></p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2020/02/26/OJS-workshop-HD/">Next generation journal publishing and containers</a></h3>
<span class="post-date">26 Feb 2020 | By Daniel N√ºst, Tom Niers</span>
<p>Some challenges of working on the next generation of research infrastructures can be solved most effectively by talking to other people.
That is why o2r team members Tom and Daniel were happy to learn about the <a href="https://www.ojs-de.net/news-und-veranstaltungen/news/save-the-date-ojs-entwickler-workshop-am-20-21022020-in-heidelberg">announcement</a> of an <a href="https://pkp.sfu.ca/ojs/">Open Journal Systems</a> (OJS) <a href="https://journals.ub.uni-heidelberg.de/index.php/ojs/announcement/view/103">workshop organised by Heidelberg University Publising (heiUP)</a>.</p>

<p>The o2r team was a little bit the odd one out.
Other workshop participants<!--more--> either had extensive OJS development experience, or were not developers at all but running production systems of many OJS journals across the German university landscape.
But that could not keep us from telling everyone about <a href="https://doi.org/10.1045/january2017-nuest">Executable Research Compendia</a>, of course.
We briefly summarised our plans to <a href="/2019/10/15/Opening-Reproducible-Research-with-OJS">extend OJS with ERC capabilities</a>, <em>but we also had new stuff to share!</em>
Tom is considering to put his <em>geo</em>-informatics skills to use and extend the metadata of OJS articles with geospatial features in his Bachelor thesis.
This would allow to display the spatial area of articles on a map, and even browse articles by their location(s).
<strong>Learn more about these ideas in our <a href="https://docs.google.com/presentation/d/12jTl4MM7QNfs_609c6WEZ3NCrM8yM1c1ZVl9y_15leU/edit#slide=id.g2ee631db89_2_75">slides</a></strong>.</p>

<blockquote class="twitter-tweet" data-dnt="true"><p lang="en" dir="ltr">Today team members <a href="https://twitter.com/nordholmen?ref_src=twsrc%5Etfw">@nordholmen</a> <a href="https://twitter.com/herrniers?ref_src=twsrc%5Etfw">@herrniers</a> meet the German <a href="https://twitter.com/hashtag/OJS?src=hash&amp;ref_src=twsrc%5Etfw">#OJS</a> developer and user community at a workshop organised by <a href="https://twitter.com/heiUP_HD?ref_src=twsrc%5Etfw">@heiUP_HD</a> <a href="https://twitter.com/ojs_pkp?ref_src=twsrc%5Etfw">@ojs_pkp</a> <br /><br />Of course we want to talk <a href="https://twitter.com/hashtag/spatial?src=hash&amp;ref_src=twsrc%5Etfw">#spatial</a> data and <a href="https://twitter.com/hashtag/ERC?src=hash&amp;ref_src=twsrc%5Etfw">#ERC</a> in OJS!<br /><br />üåç‚ù§Ô∏èüìö<a href="https://twitter.com/hashtag/SpatialIsSpecial?src=hash&amp;ref_src=twsrc%5Etfw">#SpatialIsSpecial</a> <a href="https://twitter.com/hashtag/ResearchCompendium?src=hash&amp;ref_src=twsrc%5Etfw">#ResearchCompendium</a> <a href="https://twitter.com/hashtag/ScholComm?src=hash&amp;ref_src=twsrc%5Etfw">#ScholComm</a><a href="https://t.co/5FenW7WUae">https://t.co/5FenW7WUae</a> <a href="https://t.co/BrxkAiSE72">pic.twitter.com/BrxkAiSE72</a></p>&mdash; o2r (@o2r_project) <a href="https://twitter.com/o2r_project/status/1230482699930013697?ref_src=twsrc%5Etfw">February 20, 2020</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>But Tom and Daniel also came with a mission: to jumpstart the struggling OJS developments with the help of some experiences OJS developers.
None of our team has extensive experience with PHP, so getting control over the huge OJS codebase and setting up a proper <strong>OJS development environment with debugging</strong> was an important task they‚Äôve been pushing aside since autumn last year.
<em>And we got it!</em> 
[Note to self: don‚Äôt forget to enable <code class="highlighter-rouge">remote_enable</code> and <code class="highlighter-rouge">remote_autostart</code> for Xdebug in the file <code class="highlighter-rouge">/etc/php/7.3/cli/conf.d/20-xdebug.ini</code> for debugging to work - then the default VSCode configuration with port <code class="highlighter-rouge">9000</code> will just work (-:].
On top of that, Tom got a very <strong>helpful introduction to writing OJS plug-ins</strong>, and Daniel now has a good graps on the <a href="https://github.com/pkp/docker-ojs/">currently developed <strong>Docker images for OJS</strong></a>.
The Docker images are not a simple project, since the PKP team plans to support multiple webserver implementations, multiple PHP versions, and all OJS versions still in production somewhere‚Ä¶ phew!
Daniel even <a href="https://github.com/pkp/docker-ojs/pull/14">opened a pull request</a> and suggests a different way to support both remotely and locally built images.
This prepares us well for the moment when we want to run OJS on our own servers - in containers of course.
So the expectations were high, but eventually they were not disappointed.
Daniel was glad to see some familiar faces from the <a href="https://www.ojs-de.net/">OJS-de.net community</a> he met at a previous workshop in Heidelberg.
The new contacts made were more just as important as the helpful practical tipps towards becoming real ‚ÄúOJS devs‚Äù üê±‚Äçüíª.</p>

<p><strong>Other groups at the workshop</strong> reported very interesting results, for example on the connection of OJS with proper digitial archives (with promising mentions of also archiving data‚Ä¶ and code?), more flexible publishing workflows with own tools (mentioning Pandoc, which might make these flexible pipelines a first  step towards (R) Markdown-based OJS publications ‚öôÔ∏è), and using search indexes such as Solr and Elasticsearch within OJS (which also have geospatial capabilities üíØ).
As you can see, we‚Äôre very hopeful future collaborations will spark from these educational and entertaining encounters.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2020/02/19/wwu-workshop/">WWU workshop on Reproducible Research</a></h3>
<span class="post-date">19 Feb 2020 | By Daniel N√ºst</span>
<p>Reproducible research is a topic relevant for all scientific disciplines.
We in the o2r project have a continued focus on the challenges originating in the software stacks and visualialisations for the analysis of geospatial data.
But that does not mean that our experiences may not be helpful for other disciplines.
In does also not mean that our approaches for improving research reproducibility and reusability can not profit from learning about challenges and solutions in other domains.</p>

<p>That is why we decided to reach out to the local scientific community and talk about reproducibility.
We invited all professors and post-docs of the University of M√ºnster (WWU) to a workshop at the Institute for Geoinformatics.
Why only seniour researchers? One goal was to start discussions about collaborating on new projects and writing proposals, and we thought this group would be interested in that.
We welcomed over 20 researchers across the full diversity of WWU, e.g., neuroscience, landscape ecology, business informatics, and psychology.
The event was held in German and all material is available <a href="/wwu">on the workshop website</a>.</p>

<blockquote class="twitter-tweet" data-dnt="true" data-theme="light"><p lang="en" dir="ltr">Learning about concepts and experiences across these communities show the many different perspectives and challenges around the ideal of <a href="https://twitter.com/hashtag/reproducibility?src=hash&amp;ref_src=twsrc%5Etfw">#reproducibility</a> Now we continue in group discussions to identify common pain points and start new collaborations. <a href="https://twitter.com/hashtag/interdisciplinary?src=hash&amp;ref_src=twsrc%5Etfw">#interdisciplinary</a> <a href="https://t.co/tegKwBKjjo">pic.twitter.com/tegKwBKjjo</a></p>&mdash; o2r (@o2r_project) <a href="https://twitter.com/o2r_project/status/1227237659011010562?ref_src=twsrc%5Etfw">February 11, 2020</a></blockquote>

<p>We thank our colleagues for the interesting discussions and new perspectives on a topic we thought we would have a good grasp of - there‚Äôs so much more to learn!
Special thanks go to<!--more--> our fellow researchers who prepared short talks on their experiences and ongoing work to improve reproducibility.</p>

<blockquote class="twitter-tweet" data-conversation="none" data-dnt="true" data-theme="light"><p lang="en" dir="ltr">We thank the participants for a great day with interesting discussions and plenty of looking of the rims of one&#39;s own disciplines tea cups (if that makes sense). We collected creative and innovative ideas for inter/trans/cross-disciplinary projects to improve <a href="https://twitter.com/hashtag/reproducibility?src=hash&amp;ref_src=twsrc%5Etfw">#reproducibility</a>. <a href="https://t.co/FUccyC4AOg">pic.twitter.com/FUccyC4AOg</a></p>&mdash; o2r (@o2r_project) <a href="https://twitter.com/o2r_project/status/1230146896754364416?ref_src=twsrc%5Etfw">February 19, 2020</a></blockquote>

<p>Very special thanks go to <a href="">Dr. Lisanne Pauw</a>, [Dr. Nils Schuhmacher], <a href="">Dr. Ben St√∂ver</a>, and o2r team member <a href="">Daniel N√ºst</a>, who volunteered to write up a short story about their personal work connected with reproducible research.
These stories are published on the university website <a href="https://www.uni-muenster.de/news/view.php?cmdid=10847&amp;lang=en">in English</a> and <a href="https://www.uni-muenster.de/news/view.php?cmdid=10846&amp;lang=de">German</a>.
We hope these spark the interest of fellow scientists or even the general public.
Thanks to Kathrin Kottke from the WWU public relations team for making this happen.</p>

<blockquote class="twitter-tweet" data-conversation="none" data-dnt="true"><p lang="en" dir="ltr">Four researchers contributed short stories about <a href="https://twitter.com/hashtag/reproducibility?src=hash&amp;ref_src=twsrc%5Etfw">#reproducibility</a> in their fields, published now in German and English on <a href="https://twitter.com/WWU_Muenster?ref_src=twsrc%5Etfw">@WWU_Muenster</a>&#39;s news page:<br /><br />üá©üá™ <a href="https://t.co/SZDLAdURq3">https://t.co/SZDLAdURq3</a><br /><br />üá¨üáßüá∫üá∏ <a href="https://t.co/ciYibkaTLp">https://t.co/ciYibkaTLp</a> <a href="https://twitter.com/hashtag/spatialsciences?src=hash&amp;ref_src=twsrc%5Etfw">#spatialsciences</a> <a href="https://twitter.com/hashtag/psychology?src=hash&amp;ref_src=twsrc%5Etfw">#psychology</a> <a href="https://twitter.com/hashtag/bioinformatics?src=hash&amp;ref_src=twsrc%5Etfw">#bioinformatics</a> <a href="https://t.co/04GGnNeA9L">pic.twitter.com/04GGnNeA9L</a></p>&mdash; o2r (@o2r_project) <a href="https://twitter.com/o2r_project/status/1230146909458849792?ref_src=twsrc%5Etfw">February 19, 2020</a></blockquote>

<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2020/02/03/o2r2-project-proposal/">o2r2 project proposal publiciation</a></h3>
<span class="post-date">03 Feb 2020 | By Daniel N√ºst</span>
<p><img src="/public/images/2020-01_o2r2-proposal-titlepage.png" alt="o2r2 work programme and objectives" width="300" class="img rightfloat" /></p>

<p><a href="/2019/04/15/o2r2-and-egu/">Ten months ago</a>, we announced that the o2r team received funding for a second project phase.
Today we publish our project proposal on the University of M√ºnster‚Äôs institutional repository MIAMI: <strong><a href="https://doi.org/10.17879/42149626934">https://doi.org/10.17879/42149626934</a></strong> (<a href="https://nbn-resolving.org/urn:nbn:de:hbz:6-42149629066">urn:nbn:de:hbz:6-42149629066</a>)</p>

<p>We hope this publication of our proposal serves several purposes: it<!--more--> encourages fellow researchers to also share their plans openly (both funded and rejected), it motivates us to achieve the ambitious goals, and (we have to admit) the proposal‚Äôs indexing in search engines hopefuly leads to some attention for the o2r project and subsequent new contacts and collaborations.
Science reinvents the wheel much too often, and the o2r project team wants not only to <a href="/about">increase openness, transparency and reusability of research workflows</a> but also in the bigger picture of research funding and building of research infrastructures.
Our perspective on the distinction between o2r and other projects described in the proposals is also the motivation behind our recent preprint on ArXiv: <a href="https://arxiv.org/abs/2001.00484"><em>‚ÄúPublishing computational research ‚Äì A review of infrastructures for reproducible and transparent scholarly communication‚Äù</em></a>.</p>

<hr />

<p><strong>Figure</strong>: <em>Overview of the work programme and objectives.</em>
<em>The table shows key barriers, how these were initially tackled during ORR, and which implementations are planned to overcome them during O2R2 (green and blue boxes).</em>
<em>Orange boxes show how we plan to evaluate implementations and deployment. The success measures indicate how we determine success. The blue box (bottom) summarises the technical outcomes of O2R2.</em></p>

<p><a href="/public/images/2020-01_o2r2-proposal-figure-1.png"><img src="/public/images/2020-01_o2r2-proposal-figure-1.png" alt="o2r2 work programme and objectives" /></a></p>

<hr />

<p>The document is a shortened version of the second revision submitted in May 2018, without funding information and project planning details but with a slightly updated title page to include <a href="https://en.wikipedia.org/wiki/Digital_object_identifier">DOI</a>, <a href="https://en.wikipedia.org/wiki/Uniform_Resource_Name">URN</a>, and a subtitle marking the public version.
The submission underwent a single-blind peer review by experts from information science and geosciences after first submission in August 2017.
The first version originally included a thematic extension into life sciences, with a number of new collaborators at the University of M√ºnster, and the inclusion of Python as a second supported base software.
A remaining point of critique was the description of our methodology from a research perspective.
We were lucky that the information science reviewers and ultimately the deciding council agreed in the value of the experiences made from the perspective of infrastructure development, which can only be made with a concrete practial evaluation.
The increased focus allowed us to reduce the project duration and continue with the existing approach, but also puts the remaining <a href="/pilots">pilots</a> under time pressure.
More on the pilots soon!</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2019/10/21/ecmwf/">o2r @ ECMWF Workshop in Reading, GB</a></h3>
<span class="post-date">21 Oct 2019 | By Markus Konkol</span>
<p><a href="https://twitter.com/clavitolo">Claudia Vitolo</a> from the <a href="https://www.ecmwf.int/">European Centre for Medium-Range Weather Forecasts (ECMWF)</a> had the brilliant idea to host a workshop about <a href="https://www.ecmwf.int/en/learning/workshops/building-reproducible-workflows">building reproducible workflows for earth sciences</a>. It is not surprising that weather forecasts strongly depend on computational analyses, statistics, and data. Wait! Isn‚Äôt this exactly what o2r addresses? Well observed, that is certainly correct. For this reason, we were very happy to receive an invitation from Claudia for giving a keynote. But let‚Äôs start from the beginning.</p>

<p><a href="https://twitter.com/atrisovic?s=17">Ana Trisovic</a> from the Harvard University opened the workshop with an interesting keynote about the reproducibility challenges in physics and the social sciences. She also conducted a reproducibility study to investigate if R scripts stored on Dataverse are actually reproducible. Her results were similarly worrying as those reported in our paper about <a href="https://www.tandfonline.com/doi/full/10.1080/13658816.2018.1508687">computational reproducibility in the geosciences</a>. From the 3208 R files, only 502 could be executed successfully. The remaining scripts had issues such as a wrong file directory or a missing functionality.</p>

<p>The second keynote was given by <a href="https://twitter.com/willingcarol?lang=de">Carol Willing</a> from <a href="https://twitter.com/projectjupyter">Project Jupyter</a>. She argued that lives depend on scaling reproducible research and took the example of the typhoon that hit Japan recently. Her main point was that reproducible research improves prediction which is particularly necessary in the context of storms. Having reliable predictions can help people to prepare accordingly. Based on this use case, she presented some Jupyter-based tools such as Jupyter notebooks and Binder.</p>

<p>Many other talks presented approaches to address very specific reproducibility issues. Some of these approaches build on top of Jupyter notebooks and containers which demonstrates again that these two tools are probably the right way to go for the next few years. However, the speakers did not put much focus on user-related aspects and the publication process. As a consequence, the talks were more about the technical realization and less about creating a connection between the article and the reproducible analysis. This was a nice gap for o2r to fill. <a href="https://twitter.com/MarkusKonkol">Markus</a> presented our key concepts such as the <a href="http://www.dlib.org/dlib/january17/nuest/01nuest.html">Executable Research Compendium</a> (ERC) and <a href="https://dl.acm.org/citation.cfm?doid=3340630.3331158">bindings</a> and how these can be integrated into the process of publishing scientific articles.</p>

<p>All in all, the number of talks indicates that there is some need for exchange about reproducibility in weather forecasting. This is not surprising due to the intense and often emotional discussion about climate change. Reproducible research can help to demonstrate the robustness of the results and to find errors in the analysis before publication. Hence, this way of publishing research makes it easier to counteract two popular points of attack used by climate change deniers. We hope ECMWF is going for a second edition next year!</p>

<p>By the way, all slides and even the video recordings of the talks are available online: <a href="https://events.ecmwf.int/event/116/timetable/#20191014.detailed">https://events.ecmwf.int/event/116/timetable/#20191014.detailed</a></p>

<p><a href="/public/images/ecmwf.jpg"><img src="/public/images/ecmwf.jpg" alt="ecmwf" /></a></p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2019/10/15/Opening-Reproducible-Research-with-OJS/">Opening Reproducible Research with OJS</a></h3>
<span class="post-date">15 Oct 2019 | By Daniel N√ºst, Tom Niers</span>
<p>Data and software are crucial components of research.
They go well beyond the workflows one would call <em>Data Science</em> today. Only openly available building blocks can ensure transparency, reproducibility, and reusability of computer-based research outputs.
More and more researchers rely on small or large datasets and use analysis tools to analyse variables, create figures, and derive conclusions.
That is why the project Opening Reproducible Research (<a href="https://o2r.info/"><em>o2r</em></a>) implements the concept of the Executable Research Compendium (<a href="https://o2r.info/erc-spec/">ERC</a>) to capture all bits and pieces underlying a research article.
In a <a href="/pilots">pilot study</a>, we plan to connect the Open Journal Systems (<a href="https://pkp.sfu.ca/ojs/">OJS</a>) with the ERC.
On the one hand this connection enables submission, review, and publishing of <a href="http://research-compendium.science/">research compendia</a> and ERC.
On the other hand while it leverages the publishing capabilities and workflow management of OJS.
We will implement this integration in form of an <a href="https://docs.pkp.sfu.ca/learning-ojs/en/settings-website#plugins">OJS plug-in</a> so it becomes readily available for all maintainers of OJS instances.</p>

<p>In this blog post <a href="https://github.com/tnier01">Tom</a> and <a href="https://orcid.org/0000-0002-0024-5046">Daniel</a> describe our general procedure, the first concrete plug-in idea, and the planned plug-in structure.</p>

<p><em>o2r</em> is a joint project by the Institute for Geoinformatics (<a href="https://www.uni-muenster.de/Geoinformatics/en/">ifgi</a>) and the University and State Library (<a href="https://www.ulb.uni-muenster.de/">ULB</a>) at the University of M√ºnster (<a href="https://www.uni-muenster.de/">WWU</a>).
The project is supported by the German Research Foundation (<a href="https://www.dfg.de/">DFG</a>, see <a href="/about">About</a> page for details).</p>

<h4 id="procedure">Procedure</h4>

<p>After a first collection of ideas we started concretizing them in <a href="https://en.wikipedia.org/wiki/User_story">user stories</a>.
The main user stories concern the idea of making research compendia, such as ERC, useable in the OJS-workflow (see details in the next paragraph).
These stories may contain potentially generic features that could be realised as individual plug-ins for</p>

<ul>
  <li>uploading multiple submission files, even from cloud storage, including large size files and public or authenticated shares, e.g. ownCloud, Dropbox, or GitHub,</li>
  <li>connecting articles with external data repositories (e.g. listing and preview of supplemental data published in <a href="https://en.wikipedia.org/wiki/Open-access_repository">Open data repositories</a>),</li>
  <li>supporting <a href="https://en.wikipedia.org/wiki/Literate_programming">literate programming</a>-based article formats (e.g. ERC with R Markdown, Jupyter Notebooks) with rendering to HTML and/or PDF, or</li>
  <li>seamlessly connecting articles with interactive online workspaces with reusable data and code as an alternative to static fixed articles (e.g. using <a href="http://mybinder.org/">Binder</a>).</li>
</ul>

<p>However, the focus will initially be on the integration of a full ERC-based workflow into OJS.
At a later stage, parts of this integration could be the starting point for the above individual plug-ins.</p>

<p>Based on the user stories, we then developed a few mockups (or <a href="https://en.wikipedia.org/wiki/Website_wireframe">wireframes</a>) to get a better understanding how our ideas will likely look and to ease communication about the stories. 
The next step starts now: we develop the plug-in based on our mockups and user stories.
To make sure we‚Äôre on the right track we want to use this blog post to connect with the OJS community on our ideas and specifically search for feedback on the plans described below.</p>

<h4 id="user-stories">User stories</h4>

<p>The full list of user stories can be found <a href="https://uni-muenster.sciebo.de/apps/onlyoffice/1513199997?filePath=%2FNiers%2FuserStories2.0_blogArticle.xlsx">in this spreadsheet</a>.
They are roughly sorted by priority.
We even tried to guesstimate the efforts, though we expect to be quite far off during the first few stories until we get a better understanding of developing with OJS.</p>

<p>The following main user stories will be implemented first.
They can be grouped into stories concerning creation (inluding upload) and examination (viewing, manipulating) ERCs.</p>

<p><strong>ERC creation in OJS</strong></p>

<ul>
  <li>As author I want to upload all my files (data, code, text) directly from my computer, so that I save time (not each file individually) and the complete workflow is published.</li>
  <li>As author I want to insert the metadata for a submission at one location, so that I do not have to insert them several times.</li>
  <li>As editor I want my authors to be able to upload an (optional ‚Äúexecutable‚Äù) research compendium from their computer, so that data and software can be published as a unit and I can find suitable reviewers.</li>
  <li>As editor I want there to be a review step regarding reproducibility of the article, so that the quality of reproducibility of articles in my journal increases.</li>
  <li>As editor I want research compendia in general and ERCs to be automatically validated on the platform, so that I don‚Äôt have trouble with them and the compendia are  nevertheless complete.</li>
  <li>As site admin I would like to install a Research Compendium Upload from my computer as a plug-in in OJS, so that I can offer this feature to authors.</li>
</ul>

<p><strong>ERC examination in OJS</strong></p>

<ul>
  <li>As reviewer I want to view, download, survey and manipulate the ERC, so that I can check even complex workflows without much additional effort.</li>
  <li>As reader I want to view, download, survey and manipulate the ERC within the article page, so that I am able to understand the research work.</li>
  <li>As editor I would like the readers of the journal to be able to view the ERC in the issue of the journal, so that the quality of the journal increases.</li>
  <li>As site admin I want to be able to install a plug-in in OJS that allows you to view and manipulate ERCs, so that I can offer this feature to authors and reviewers.</li>
</ul>

<h4 id="erc-plug-in-for-ojs">ERC plug-in for OJS</h4>

<p><em>How do we want to realize our user stories?</em></p>

<h5 id="upload-executable-research-compendium">Upload Executable Research Compendium</h5>

<p>To replace a regular article with an ERC in OJS, there is of course the need to upload it.
The idea is to add a new file type for finished ERCs.
But we also want to give the user the opportunity to create a ERC during the submission process within OJS.
Therefore we plan to customize the upload process.
The user will have the option to upload the files for the ERC and then to modify ERC metadata (publication metadata, spatio-temporal metadata).
The authors will also be able to create <a href="/2019/08/28/bindings/">bindings</a>.
The following mockup shows how we imagine the upload process of an ERC.</p>

<p><a href="/public/images/2019-10-15-Opening-Reproducible-Research-with-OJS/Mockup1.png"><img src="/public/images/2019-10-15-Opening-Reproducible-Research-with-OJS/Mockup1.png" alt="" /></a>
Mockup 1.: Submit an ERC in OJS (metadata form)</p>

<h5 id="review-executable-research-compendium">Review Executable Research Compendium</h5>

<p>After uploading the article, the next step in the OJS workflow is the review prozess.
In this process the reviewer should be able to both download the ERC and to inspect the ERC online.
Therefore a preview is needed, which does not differ from the view the reader is finally seeing.
The preview only shows an additional link which brings the reviewer back to the review page.
In this view the user can read the main text document of the ERC (PDF or HTML), look at data and code files and figures, and manipulate a workflow with bindings.
To provide feedback to the author, a new text area ‚ÄúReproducibility Review‚Äù is added to the third step ‚ÄúDownload &amp; Review‚Äù in the review stage in OJS. Here the reviewer can comment on the understandability and reproducibility of the given workflow.</p>

<p><a href="/public/images/2019-10-15-Opening-Reproducible-Research-with-OJS/Mockup2.png"><img src="/public/images/2019-10-15-Opening-Reproducible-Research-with-OJS/Mockup2.png" alt="" /></a>
Mockup 2.: Examine an ERC subission (download, preview links) and write review comments (reproducibility text box)</p>

<h5 id="examine-executable-research-compendium">Examine Executable Research Compendium</h5>

<p>The examiniation of an ERC in OJS, i.e. the viewing of compendium files and manipulation of workflows by reviewers and readers, is a core feature of the plug-in.
The only differ in the link to get back to either the review form in the case of the reviewer or back to the article landing page in the case of the reader.
We have two two different ideas how to realize ERC examination.</p>

<p>First, there is the possiblity to integrate it directly on the main article page.
The ERC with its file view and manipulation area is directly shown on the article page.</p>

<p><a href="/public/images/2019-10-15-Opening-Reproducible-Research-with-OJS/Mockup3.1.png"><img src="/public/images/2019-10-15-Opening-Reproducible-Research-with-OJS/Mockup3.1.png" alt="" /></a>
Mockup 3.1: View of an ERC for a reader (idea 1)</p>

<p><a href="/public/images/2019-10-15-Opening-Reproducible-Research-with-OJS/Mockup3.2.png"><img src="/public/images/2019-10-15-Opening-Reproducible-Research-with-OJS/Mockup3.2.png" alt="" /></a>
Mockup 3.2: View of an ERC for a reviewer (idea 1)</p>

<p>Second, a realization similar to <a href="https://github.com/paflov/lensGalleyBits">lensGalleyBits</a> is imaginable.
In this case the reader is taken to a new page where can can show the regular o2r platform‚Äôs user interface.</p>

<p><a href="/public/images/2019-10-15-Opening-Reproducible-Research-with-OJS/Mockup4.1.1.png"><img src="/public/images/2019-10-15-Opening-Reproducible-Research-with-OJS/Mockup4.1.1.png" alt="" /></a>
Mockup 4.1.1: View of an ERC for a reader - article view (idea 2)</p>

<p><a href="/public/images/2019-10-15-Opening-Reproducible-Research-with-OJS/Mockup4.1.2.png"><img src="/public/images/2019-10-15-Opening-Reproducible-Research-with-OJS/Mockup4.1.2.png" alt="" /></a>
Mockup 4.1.2: View of an ERC for a reader - ERC view (idea 2)</p>

<p><a href="/public/images/2019-10-15-Opening-Reproducible-Research-with-OJS/Mockup4.2.png"><img src="/public/images/2019-10-15-Opening-Reproducible-Research-with-OJS/Mockup4.2.png" alt="" /></a>
Mockup 4.2: View of an ERC for a reader (idea 2)</p>

<p>In both cases the user has all possibilitys concerning reading the PDF of the ERC and manipulating its figures and tables.
In the first case we preserve the journal‚Äôs branding at the top of the page, which might be desirable for editors and publishers.
In the second case we only have the default o2r UI which might be easier to integrate as a standalone page.</p>

<h4 id="plug-in-structure">Plug-in structure</h4>

<p>We sketched a structure for our ERC plug-in.
The plug-in consists of two parts, one for the examination of ERCs and one part for the creation/upload of ERCs.
The <a href="https://docs.pkp.sfu.ca/dev/plugin-guide/en/categories">plug-in category</a> or type probably needs to be a ‚Äúgeneric‚Äù plug-in to realise the deep integration of ERC into many different pages of OJS.</p>

<p><a href="/public/images/2019-10-15-Opening-Reproducible-Research-with-OJS/o2r2_OJS_plug-in.png"><img src="/public/images/2019-10-15-Opening-Reproducible-Research-with-OJS/o2r2_OJS_plug-in.png" alt="" /></a>
Plug-in structure of (E)RC in OJS</p>

<h4 id="conclusion">Conclusion</h4>

<p>We hope this post gives you a good impression of our plans.
As you may have noticed, some of the features we plan to implement for ERCs might also be interesting for OJS users who just want to upload multiple files, for journals who want to support other types of <a href="https://research-compendium.science/">research compendia</a>, or for an OJS maintainer who wants to allow a Markdown based workflow.
We can imagine several plug-ins could be extracted from the ERC plugin <a href="#procedure">as described above</a>, depending on time left in our schedule and interest by other OJS users/developers.
<em>What do you think?</em></p>

<p>Please do not hesitate to comment on this blogpost with your ideas and questions, either below or in a <a href="https://forum.pkp.sfu.ca/t/opening-reproducible-research-with-ojs-plug-in/56336">related thread in the PKP Community Forum</a>.
We would be pleased to learn about your ideas and receive your feedback.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2019/10/11/markus-konkol-defends-phd-thesis/">Markus Konkol defends PhD Thesis</a></h3>
<span class="post-date">11 Oct 2019 | By Daniel N√ºst</span>
<p>Markus Konkol successfully defended his PhD thesis, <em>‚ÄúPublishing Reproducible Geoscientific Papers: Status quo, benefits, and opportunities‚Äù</em>, today Friday Oct 11 at the Institute for Geoinformatics (<a href="https://www.uni-muenster.de/Geoinformatics/en/">ifgi</a>) at University of M√ºnster (<a href="https://www.uni-muenster.de/">WWU</a>).</p>

<p>üéâ Congratulations Markus on completing this important step in your career! ü•Ç</p>

<p><em>Dr. rer. nat. Markus Konkol is pictured with his Mentor Prof. Dr. Christian Kray and the examination committee: Jun. Prof. Dr. Judith Verstegen, Prof. Dr. Edzer Pebesma, Prof. Dr. Carsten Kessler and Prof. Dr. Harald Strau√ü.</em></p>

<p><img src="/public/images/2019-10-11_defense-markus.jpg" alt="Markus Konkol successfully defended his PhD thesis; examination committee" title="Markus Konkol successfully defended his PhD thesis; examination committee" width="600" /></p>

<p>Markus has been a core o2r team member since the project‚Äôs start in January 2016.
He lead<!--more--> the development of the user interface for creating and examing reproducible research and conducted comprehensive reproduction studies as well as several user studies and surveys, successfully connecting the o2r project with the needs of the geoscience communities.
<a href="https://scholar.google.de/citations?user=zlyQYmwAAAAJ&amp;hl=de&amp;oi=ao">His</a> <a href="https://orcid.org/0000-0001-6651-0976">work</a> contributes great insights on the technical and individual challenges - the status quo in the geosciences - as well as incentives and solutions for making research more open and reproducible.
His concept and implementation of <em>bindings</em> demonstrate a novel groundbreaking method for exposing the true core and value of research outputs that reach beyond geoscience applications and impact transparency, understandability, and discoverability.
Markus is a welcome <a href="https://o2r.info/publications/#talks-1">advocator and speaker</a> on reproducible research in the geosciences at local and international events.
The o2r project is fortunate that he will continue to take down barriers for openness and reproducibility and push towards better science.</p>

<p>Follow <a href="https://twitter.com/MarkusKonkol">@MarkusKonkol</a> on Twitter and <a href="https://github.com/MarkusKonk">@MarkusKonk</a> on GitHub.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2019/09/10/o2r-on-tour-elife-sprint-and-jupyterhub-binder-workshop/">o2r on tour: eLife Sprint and JupyterHub/Binder workshop</a></h3>
<span class="post-date">10 Sep 2019 | By Daniel N√ºst, Markus Konkol</span>
<!-- Tweet gif: https://giphy.com/gifs/kochstrasse-cute-sweet-plazahelden-JpLh4diVtbClvZCP70 -->

<p>This week, the o2r team was <em>on tour</em>.
We put our o2r tasks aside for a few days to interact with and contribute to the awesome Open Science/publishing/research community.</p>

<p>Markus and Daniel were two of the fortunate few who<!--more--> were invited to participate in the <strong><a href="https://sprint.elifesciences.org/">eLife Innovation Sprint 2019</a></strong>.
Thanks eLife!
eLife is a non-profit Open Access publisher <a href="https://elifesciences.org/about/innovation">with a mission to innovate</a> and push scholarly communication, peer review, and publication of reproducible articles to new heights.
The <a href="https://twitter.com/hashtag/eLifeSprint"><code class="highlighter-rouge">#eLifeSprint</code></a> is a two-day event and brings together scientists, developers, designers, architects, thinkers, community leaders, publishers, and early career researchers to come up with relevant challenges and promising ideas for the scientific community.
It took place for the second time in Cambridge, UK, where eLife‚Äôs headquarter is located, in the welcoming <a href="https://www.junction.co.uk/">Cambridge Junction</a>.
Just like last year, the event was excellently organised and run by eLife staff.</p>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">And that&#39;s a wrap for <a href="https://twitter.com/hashtag/eLifeSprint?src=hash&amp;ref_src=twsrc%5Etfw">#eLifeSprint</a> 2019! üé¨<br /><br />A huge thank you to everyone involved for making this event so productive and fun! You&#39;ve all been amazing! ‚ú®‚ù§Ô∏èüòÅ <a href="https://t.co/lAwi3pgaNY">pic.twitter.com/lAwi3pgaNY</a></p>&mdash; eLife Innovation (@eLifeInnovation) <a href="https://twitter.com/eLifeInnovation/status/1169641663549059072?ref_src=twsrc%5Etfw">September 5, 2019</a></blockquote>

<p>After introductions and pitching ideas, the participants formed into project groups and spent ~1.5 days on realising a first prototype.
You can learn about the results in the <a href="https://docs.google.com/presentation/d/1dGERl3b68Crsnc2wptFjzTNkgmcYNUs6kyUqeZN48GE/edit#slide=id.g3d962427da_0_0">‚Äútime to shine‚Äù</a> presentation and on social media under <a href="https://twitter.com/search?q=%23eLifeSprint%20%23TimeToShine"><code class="highlighter-rouge">#eLifeSprint #timetoshine</code></a>: an Open Science card game, a user interface for generating citation files for software, extracting data from text such as the used instruments, a prototype for discovering preprints from authors with underrepresented backgrounds, or a template project for running a journal on GitHub, to name just a few.
Daniel and Markus really enjoyed the event and contributed with their developer skills (containers, UI development, eating cake) to several projects.</p>

<blockquote class="twitter-tweet" data-dnt="true" data-theme="light"><p lang="en" dir="ltr"><a href="https://twitter.com/hashtag/TimeToShine?src=hash&amp;ref_src=twsrc%5Etfw">#TimeToShine</a>: Ankit, Stephen, Daniel have made a UI prototype on GitHub and Docker Hub, worked on UI development for Binder, written case studies and more principles for CODECHECK, as well as helping others with Docker projects at the <a href="https://twitter.com/hashtag/eLifeSprint?src=hash&amp;ref_src=twsrc%5Etfw">#eLifeSprint</a> <a href="https://t.co/YJWrsvqWkN">pic.twitter.com/YJWrsvqWkN</a></p>&mdash; eLife Innovation (@eLifeInnovation) <a href="https://twitter.com/eLifeInnovation/status/1169624391442997249?ref_src=twsrc%5Etfw">September 5, 2019</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Team <a href="https://twitter.com/hashtag/SoftwareCitation?src=hash&amp;ref_src=twsrc%5Etfw">#SoftwareCitation</a> ready for <a href="https://twitter.com/hashtag/TimeToShine?src=hash&amp;ref_src=twsrc%5Etfw">#TimeToShine</a> <a href="https://twitter.com/hashtag/eLifeSprint?src=hash&amp;ref_src=twsrc%5Etfw">#eLifeSprint</a> <a href="https://twitter.com/eLifeInnovation?ref_src=twsrc%5Etfw">@eLifeInnovation</a> <a href="https://twitter.com/MarkusKonkol?ref_src=twsrc%5Etfw">@MarkusKonkol</a> Sarthak, me <a href="https://twitter.com/eScienceCenter?ref_src=twsrc%5Etfw">@eScienceCenter</a> Jen <a href="https://twitter.com/ELIXIREurope?ref_src=twsrc%5Etfw">@ELIXIREurope</a> , Melissa <a href="https://twitter.com/eLife?ref_src=twsrc%5Etfw">@eLife</a> , Sarala <a href="https://twitter.com/datacite?ref_src=twsrc%5Etfw">@datacite</a> <a href="https://t.co/jxjCDLFRIs">pic.twitter.com/jxjCDLFRIs</a></p>&mdash; Mateusz Kuzak (@matkuzak) <a href="https://twitter.com/matkuzak/status/1169625245302579201?ref_src=twsrc%5Etfw">September 5, 2019</a></blockquote>

<p>While it was a little disappointing that Markus‚Äô idea of a JavaScript image comparison library (hopefully more on that soon!) did gain attention but did not end up in a team, the sprint was a great occasion to give back to the community, to broaden the horizon beyond the o2r project, to make new acquaintances, and to get to know potential collaborators.
<em>And we did all that!</em></p>

<hr />

<p>After the #eLifeSprint, Daniel hopped on a plane to Oslo, Norway, to participate in a <strong><a href="https://binderhub.readthedocs.io/en/latest/">Binder/BinderHub</a>/<a href="https://mybinder.org/">MyBinder.org</a>/<a href="https://jupyter.org/hub">JupyterHub</a></strong> event generously organised by <a href="https://www.simula.no/">Simula</a>.
The event allowed long-term collaborators to meet in person, some for the first time, for some effective joint work.
Participants happily hacked away on their own or formed discussion groups on specific topics for a few hours before taking on a new challenge.
Ten to twelve developers of diverse backgrounds filled a hotel meeting room and turned coffee and delicious catering into pull requests, issues, and hackpads with new ideas and solutions in the Binder/Jupyter universe. 
It was a great experience to get to know the friendly faces and delightful personalities behind GitHub usernames.
Daniel enjoyed participating in the discussions and picking the brains of the core developers of BinderHub and repo2docker, and the maintainers of mybinder.org.
He was able to contribute a <a href="https://github.com/jupyter/repo2docker/pull/788">few</a> <a href="https://github.com/jupyter/repo2docker/pull/778">pull</a> <a href="https://github.com/jupyter/repo2docker/pull/785">request</a> to <a href="https://repo2docker.readthedocs.io/en/latest/">repo2docker</a> and enjoyed the discussions on future directions of the core tool in the Binderverse, such as a new user interface (a must to make BinderHub even more like magic), pinning the repo2docker version (a must for reproducibility) and re-enabling composability for all <a href="https://repo2docker.readthedocs.io/en/latest/config_files.html">supported configurations</a> (a must for many users).</p>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">My kind of crowd üôá‚Äç‚ôÇÔ∏èüôá‚Äç‚ôÄÔ∏è! <a href="https://t.co/q8fvImQnEL">https://t.co/q8fvImQnEL</a></p>&mdash; Binder Team (@mybinderteam) <a href="https://twitter.com/mybinderteam/status/1170740818442956800?ref_src=twsrc%5Etfw">September 8, 2019</a></blockquote>

<p><em>Thanks to all participants for making the meeting so much fun and educational.</em>
Daniel‚Äôs participation will surely help to pave the way for a Binder-powered scalable infrastructure for the <a href="https://o2r.info/pilots/">o2r pilots</a> and for <a href="https://codecheck.org.uk/">CODE CHECK</a>.
You can learn more about the numerous tasks tackled in the sprint in this HackMD pad: <a href="https://hackmd.io/N-uffNhvRdOgt1OvTuoq5w?view">https://hackmd.io/N-uffNhvRdOgt1OvTuoq5w?view</a></p>

<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2019/08/28/bindings/">Why PDFs are not suitable for communicating (geo)scientific results</a></h3>
<span class="post-date">28 Aug 2019 | By Markus Konkol</span>
<p>In 2016, Dottori et al. published a <a href="https://www.nat-hazards-earth-syst-sci.net/16/2577/2016/">paper</a> about a flood damage model. The model calculates the damage costs caused by a flood event, e.g., for repairing buildings or cleaning. This model is based on a number of parameters, such as <strong>flow velocity</strong> and <strong>flood duration</strong>. In the paper, the authors discuss a scenario in which a flood has a velocity of 2m/s and a duration of 24 hours. The resulting damage costs are shown in a figure and also alternative values are discussed in the text. This is where the paper format, i.e. a PDF file, is limited. A mere format change does not help - a static HTML rendering has the same issues. Describing within the article text how changes to the parameter set affect the damage costs might be possible possible but is surely a daunting and time-consuming task. Authors need to find the right words to briefly describe these changes, and readers need to imagine how the results change.</p>

<p>Wouldn‚Äôt it be nice if readers, while reading the article, could also simply change the parameters in order to see how the figure changes? We recently published an article on how to achieve this by <a href="https://doi.org/10.1145/3331158">‚ÄúCreating Interactive Scientific Publications using Bindings‚Äù</a>.</p>

<p>A <strong>binding</strong> describes which source code lines and data subsets were used to produce an individual computational result, such as a figure, table, or number in the text. A binding explicitly refers to single parameters in the code which influence the result. By specifying a user interface widget (e.g. a slider) for a parameter, a binding can then be used to create an interactive figure.</p>

<p>Ok, cool, that sounds just awesome, but how does it look like? Let‚Äôs check both perspectives, the author who creates a binding, and the reader who uses the interactive figure. Just four steps are needed to create a binding for an interactive figure:</p>
<ol>
  <li>Specify the result, e.g. ‚ÄúFigure 3‚Äù</li>
  <li>Mark the plot function in the code that creates the figure. From that plot function we automatically extract all relevant code lines, at least we plan to do so since this feature is currently under development.</li>
  <li>Mark the parameter that should be made interactive, e.g. ‚Äúduration‚Äù or ‚Äúvelocity‚Äù</li>
  <li>Configure the user interface widget, e.g. a slider
That‚Äôs how authors can create interactive figures easily. Please note that we did not yet fully implement the functionality for specifying data subsets.</li>
</ol>

<iframe width="900" height="600" src="https://www.youtube-nocookie.com/embed/7CB-K1cEKYM" frameborder="0" allow="encrypted-media" allowfullscreen=""></iframe>

<p>The readers‚Äô view was integrated into the implementation discussed in an article published last year (<a href="https://doi.org/10.1080/15230406.2018.1512421">‚ÄúIn-depth examination of spatio-temporal figures‚Äù</a>) and the previous <a href="https://o2r.info/2019/07/15/4plus1incentives/">blog post</a>. 
The left side shows the static version of the paper. On the right side, readers can use the slider to change the two parameters velocity and duration. The changes are immediately reflected in the figure. Since it might be difficult to spot differences, we also implemented a simple view to compare two figures created through parameter manipulation by the reader.</p>

<iframe width="900" height="600" src="https://www.youtube-nocookie.com/embed/jAAgI7aLMik" frameborder="0" allow="encrypted-media" allowfullscreen=""></iframe>

<p>Such explorable papers are the next generation of scholarly communications.  Being able to provide interactive figures is beneficial for authors, who can explain visually how changes to the parameters affect the figure, and for readers, who better understand complex models. They are also a sign of quality for the analysis workflow, because they demonstrate that all pieces (data, software) needed to create the figure are encapsulated in the Executable Research Compendium (<a href="https://o2r.info/results/">ERC</a>) on which the bindings are based.</p>

<p>By the way, we also presented the paper at the Engineering Interactive Computing Systems Conference 2019 in Valencia. Of course, the slides are available online on <a href="https://zenodo.org/record/3253692#.XWd9K99fjmE">Zenodo</a>.</p>


</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2019/07/15/4plus1incentives/">4+1 quick incentives of open reproducible research</a></h3>
<span class="post-date">15 Jul 2019 | By Markus Konkol</span>
<p>A few months ago, o2r team member <a href="https://orcid.org/0000-0001-6651-0976">Markus</a> published the article <a href="https://doi.org/10.1080/15230406.2018.1512421">‚ÄúIn-depth examination of spatiotemporal figures in open reproducible research‚Äù</a> in the journal <a href="https://www.tandfonline.com/toc/tcag20/current">Cartography and Geographic Information science</a>. Our goal was to identify a set of concrete incentives for authors to publish open reproducible research, and for readers to engage with it. Based on semi-structured interviews, a focus group discussion, and an online survey with geoscientists, we summarised the incentives in a four-step workflow for readers who work with scientific papers (see figure below). Let‚Äôs see what these four workflow steps are who their <strong>+1</strong> is.</p>

<h4 id="discovery">Discovery</h4>

<p>By having all materials available in a publicly accessible way, we obtain additional capabilities to search for scientific papers which go beyond today‚Äôs keyword-based search engines. The materials underlying a paper include a bunch of information which can be extracted automatically (see <a href="https://github.com/o2r-project/o2r-meta">o2r-meta</a>) and put on display (see <a href="https://doi.org/10.31223/osf.io/xtsqh">geospatial data science badges</a>) to improve discovery. You were wondering how to use a specific software library in your R code in practice? Just search for papers with computations based on that library. Spatial information, temporal properties, models, parameters - this all becomes searchable which is good for readers, and findable which is good for the impact of authors.</p>

<h4 id="inspection">Inspection</h4>

<p>Once researchers found a suitable paper, they can continue with inspecting it. Parallel to reading the actual text of the paper, they can inspect the underlying source code and data. This is of particular interest for reviewers who want to check how the authors achieved the results reported in the paper. By the way, more and more reviewers <a href="https://twitter.com/edzerpebesma/status/1130055583489581057">reject papers</a> reporting on computational results that do not contain code or data - Think about it! Again, this step is not only beneficial for readers and reviewers but also for the authors who can make their research workflows more reusable resulting in a higher research impact.</p>

<h4 id="manipulation">Manipulation</h4>

<p>Many results in scientific papers are based on computational analyses. These calculations often include parameters which were set in a specific way by the author of the article. For example, a model that computes the damage costs caused by a flood strongly depends on the flow velocity (see <a href="https://doi.org/10.5194/nhess-16-2577-2016">Dottori et al., 2016</a>) of the water. It is difficult to show in static papers, how changes to the flow velocity affect the final damage costs. One idea to solve this issue is an interactive figure. Readers and Reviewers can, for example, use a slider to change the parameter value interactively.</p>

<h4 id="substitution">Substitution</h4>

<p>Finally, other researchers can substitute, for instance, the original dataset by an own compatible dataset. This opportunity not only makes other researchers‚Äô life easier as they can reuse existing materials, but might also bring citations, co-authorships, and cooperations for the original author.</p>

<p><img src="https://media.giphy.com/media/2YpQm0zBnv0I86uAa6/giphy.gif" alt="" /></p>

<h4 id="1">+1</h4>

<p>So who is this workflow steps‚Äô +1?</p>

<p>It‚Äôs <strong>understanding</strong>.</p>

<p>In the paper, we argue that each of the steps contribute to a reader‚Äôs understanding in a better way than traditional papers could do. Already during the inspection phase, researchers get to know about spatio-temporal properties, used functions and so on. During inspection, they can see how the authors produced a specific figure, experience the data from the analysts perspective, and finally understand how the authors came to their conclusions. By manipulating parameters, readers and reviewers can comprehend better how the model actually works. Substituting datasets provides insights into the applicability to other settings and evaluates robustness of an approach. A key requirement for the realization of understanding is being able to compare, for example, the original figure with one resulting from parameter manipulation.</p>

<p>You think that this was nice to read but difficult to realize? Correct, it is. And that is why the o2r team works hard to make the five incentives easier to achieve and received funding for two more years.</p>

<p><a href="/public/images/workflow.jpeg"><img src="/public/images/workflow.jpeg" alt="workflow" /></a></p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2019/07/01/AGILE-2019-Limassol/">Reproducible Research and Geospatial Badges at AGILE 2019 conference in Limassol</a></h3>
<span class="post-date">01 Jul 2019 | By Daniel N√ºst</span>
<p>Last week o2r team member <a href="https://orcid.org/0000-0002-0024-5046">Daniel</a> went to <a href="https://www.sporcle.com/blog/2018/12/is-cyprus-in-europe-or-asia/">Asia (or not?)</a> to help a European conference with the transformation towards reproducible research.
<em>How?</em></p>

<p>The <a href="https://agile-online.org/conference-2019/">2019</a> edition of the <a href="https://agile-online.org/past-conferences-and-proceedings/">annual conference</a> of the <a href="https://agile-online.org/">Association of Geographic Information Laboratories in Europe‚Äôs</a> (AGILE) took place in <a href="https://www.openstreetmap.org/node/9331795#map=14/34.6803/33.0547">Limassol, Cyprus</a>.
It was excellently <a href="https://agile-online.org/conference-2019/committees-2019/">organised</a> at the <a href="https://www.cut.ac.cy/">Cyprus University of Technology</a> and consisted of a pre-conference day of workshops and <a href="https://agile-online.org/conference-2019/programme-2019/accepted-papers-and-posters-2019">three days of talks and posters</a> across the full breadth of GI Science.</p>

<p>On the first day, Daniel contributed to the organisation of the third workshop in the ‚ÄúReproducible Research @ AGILE‚Äù <a href="https://o2r.info/reproducible-agile/">series of workshops</a>.
Adjusting the scope of the workshop after the <a href="/2017/05/10/o2r-at-AGILE/">first</a> <a href="/2018/06/21/agile-2018-pre-conference-workshop-report/">two</a> iterations, the participants<!--more--> learned first about the basics of reproducibility before being split up into a ‚Äúbeginners‚Äù and ‚Äúadvanced‚Äù group.
The former continued with practical experiences in reproducing a tailored small manuscript with data and code, while the latter took on real world papers in a reproduction sprint.
Starting only with a DOI, the participants skimmed real articles for practical instructions and shared how far they got after only 30 minutes.
The results were mixed, as it could be expected, but the lessons that could be drawn were already very educational and could be connected directly with concrete steps towards preproducibility.</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr"><a href="https://twitter.com/hashtag/agileconf2019?src=hash&amp;ref_src=twsrc%5Etfw">#agileconf2019</a> starting today in ‚òÄÔ∏è Limassol with workshops. <a href="https://twitter.com/f_ostermann?ref_src=twsrc%5Etfw">@f_ostermann</a> is kicking things off at our <a href="https://twitter.com/hashtag/rragile19?src=hash&amp;ref_src=twsrc%5Etfw">#rragile19</a> workshop on reproducible research! <a href="https://twitter.com/hashtag/openscience?src=hash&amp;ref_src=twsrc%5Etfw">#openscience</a> <a href="https://twitter.com/hashtag/reproducibleresearch?src=hash&amp;ref_src=twsrc%5Etfw">#reproducibleresearch</a> <a href="https://t.co/SecPmEFl6z">pic.twitter.com/SecPmEFl6z</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/1140507048175706112?ref_src=twsrc%5Etfw">17. Juni 2019</a></blockquote>

<p>After lunch, the groups joined again for getting to know the <a href="https://osf.io/c8peu/"><em>AGILE Reproducible Paper Guidelines</em></a>.
The guidelines were developed in online collaboration and a recent expert meeting at TU Delft (see <a href="https://osf.io/8d6yt/">report</a>).
They require authors to be transparent about the underlying building blocks of their work by adding a <em>Data and Software Availability</em> section.
Beyond this minimal requirement of transparency, the guidelines intent to nudge authors towards higher degrees of reproducibility with concrete steps and recommendations for both data and software.
The steps are illustrated by examples from the GI Science domain.
<a href="https://osf.io/phmce/">Leave your feedback about the guidelines OSF</a>!
The ensuing discussion about the challenges, opportunities, and ethics of reproducible research made clear the participants were serious on their way to becoming experts in RR.
They continued on this path in the final session, in which both groups took on the role of an author and applied practices of Open Science and reproducible research.
Find all workshop material online at <a href="https://osf.io/d9kcr/">https://osf.io/d9kcr/</a>.</p>

<p>Besides the workshop, the RR@AGILE team advertised and sought feedback on the guidelines in many small discussions and with a <a href="https://osf.io/y2rk4/">dedicated poster</a>.
The feedback will be incorporated into a first release of the guidelines in the coming weeks, just in time for the call for papers for the <a href="https://twitter.com/0mgould/status/1141658244311638016">next AGILE conference</a> in <a href="https://www.openstreetmap.org/node/31376615#map=13/35.5141/24.0246">Chania, Crete</a>!
The RR@AGILE team is proud that the AGILE council and next year‚Äôs organising team support a transformation towards reproducible research publications and looks forward to working with authors, reviewers and organisers to making the move a success.</p>

<hr />

<p>On the second day of the conference, Daniel presented the short paper <em>‚ÄúGuerrilla Badges for Reproducible Geospatial Data Science‚Äù</em>.
The paper is <a href="/2017/09/12/reproducible-research-badges/">based on</a> the work of a project seminar at the Institute for Geoinformatics from 2017, which explains the long list of co-authors.
The article demonstrates how and what kind of novel badges can be created based on executable research compendia (<a href="https://o2r.info/erc-spec/">ERC</a>) and how they can be distributed on the web.
The full postprint of the peer-reviewed article is available on <a href="https://doi.org/10.31223/osf.io/xtsqh">EarthArXiv</a> and it contains links to the related software projects.</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">Just presented short paper at <a href="https://twitter.com/hashtag/agileconf2019?src=hash&amp;ref_src=twsrc%5Etfw">#agileconf2019</a> - Thanks the <a href="https://twitter.com/hashtag/SDI?src=hash&amp;ref_src=twsrc%5Etfw">#SDI</a> session participants &amp; fun questions. Slides: <a href="https://t.co/N1OMj3iNJv">https://t.co/N1OMj3iNJv</a> Paper (postprint w/ DOI pending): <a href="https://t.co/gvkalcchHt">https://t.co/gvkalcchHt</a> Reproduction package: <a href="https://t.co/SC4i99pk5l">https://t.co/SC4i99pk5l</a> <a href="https://twitter.com/hashtag/badges?src=hash&amp;ref_src=twsrc%5Etfw">#badges</a> <a href="https://t.co/Uyv8jyIAUS">pic.twitter.com/Uyv8jyIAUS</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/1140959648494866432?ref_src=twsrc%5Etfw">18. Juni 2019</a></blockquote>

<hr />

<p>As always, AGILE was a delightful conference with many engaging discussions which may have started more collaborations to foster reproducible research.
Daniel also continued the text analysis of all AGILE papers for this year‚Äôs conference.</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">Obviously this needs advertising, as no one spotted the error in the &quot;trends&quot; analysis: Increase in &quot;reproducibility&quot; keywords can be largely awarded to mine and <a href="https://twitter.com/pjkedron?ref_src=twsrc%5Etfw">@pjkedron</a>&#39;s papers. Still lots of data, algorithms, and processing going on - clear need for reproducibility! <a href="https://t.co/W4FMhtm3as">pic.twitter.com/W4FMhtm3as</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/1144237629027835904?ref_src=twsrc%5Etfw">27. Juni 2019</a></blockquote>

<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>A small rise in ‚Äúreproducibility‚Äù terms can be traced to a couple of articles on the topic.
Yet the stronger trend prevails: AGILE papers talk about data, processing, and algorithms - so the transformation for more transparency and reproducibility continues to be relevant.</p>

<p>Find the <a href="https://rpubs.com/nuest/reproducible-agile-text-analysis">full analysis online on RPubs</a> and see the <a href="https://github.com/nuest/reproducible-research-and-giscience/blob/master/agile-rr-yearly-textanalysis.Rmd">source code</a> on GitHub.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2019/06/27/o2r2-and-conquaire/">o2r2 @ Conquaire Workshop</a></h3>
<span class="post-date">27 Jun 2019 | By Markus Konkol</span>
<p>Now that we have two more years to work on open reproducible research (see our last <a href="https://o2r.info/2019/04/15/o2r2-and-egu/">blog post</a>), there is also some space for an exchange with related projects and to explore potential new collaborations. We were thus very happy to receive an invitation from the <a href="https://conquaire.uni-bielefeld.de/about/">Conquaire</a> project at the University of Bielefeld for the workshop on <a href="https://uni-bielefeld.de/(en)/conquaire/reproducibility-workshop/">data quality and reproducibility</a> (03.04.2019). Conquaire started about the same time as o2r and strives for similar goals, i.e. assisting scholars in making their research results reproducible and reusable. The workshop was located at the Center for Interdisciplinary Research in a very nice room that looked a bit like the United Nations headquarter - so it was good practice for the bigger goals we have in mind.</p>

<p><a href="/public/images/o2rconquaire.jpg"><img src="/public/images/o2rconquaire.jpg" alt="room" /></a></p>

<p><a href="http://www.sc.cit-ec.uni-bielefeld.de/de/team/philipp-cimiano/">Prof. Dr. Philipp Cimiano</a> gave the first talk of the day. He presented <!--more-->the general Conquaire approach which focuses on storing all materials in a GitLab repository and running checks with the help of continuous integration based on <a href="https://jenkins.io/">Jenkins</a>. Researchers can thus create an incremental publication where each  git commit triggers and automatic validation process. They also had a promising number of use cases. However, similar to us, they struggled a bit with the amount of effort needed from authors to make research reproducible.</p>

<p><a href="https://www.ub.uni-bielefeld.de/~cpietsch/">Christian Pietsch</a> then gave a quick introduction into versioning tools such as GitLab and which benefits users get. I particularly liked his answer to the question from the audience if the Conquaire approach is also feasible with licensed software: Use free open source software! It‚Äôs that easy.</p>

<p>Afterwards, Conquaire team member Fabian Herrman talked about their validation approach by using continuous integration (<a href="https://www.ub.uni-bielefeld.de/div/kwi_vortraege/2019-04-12_UB-Kolloquium_Conquaire_qc_herrmann.pdf">Slides</a>). They check, for example, if all files are available (including readme and license) and convey the result in two ways: First, by assigning a badge to the repository and second, by emailing the author of the repository.</p>

<p>The following talks were about <strong>F</strong>indable, <strong>A</strong>ccessible, <strong>I</strong>nteroperable, and <strong>R</strong>eusable data principles (by Silvia Wissel and Amrapali Zaveri) and the Jupyter Notebook, which was used in the context of history science by Malte Vogl. One benefit of Jupyter notebooks he mentioned stuck with us: it is also readable when the base software does not exist anymore. This is also one of the essential advantages of the Dockerfiles and R Markdown documents used in our executable research compendia (ERCs).</p>

<p>Last but not least, we were allowed to present our approach and what we plan to achieve in the next two years. The slides are available online: <a href="https://doi.org/10.5281/zenodo.2628278">https://zenodo.org/record/2628278</a>.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2019/04/15/o2r2-and-egu/">o2r2 - Putting ERC into practice</a></h3>
<span class="post-date">15 Apr 2019 | By Daniel N√ºst</span>
<p><em>The o2r project‚Äôs journey continues.</em></p>

<p><img src="/public/images/o2r2-logo.png" alt="o2r2 logo" width="300" class="img rightfloat" />
On April 1st 2019 the o2r team started into a new phase (<em>‚Äúo2r2‚Äù</em>).
In the next 30 months we plan to put our prototypes to the test with <em>real articles</em>, of course not without considerably improving them beforehand.</p>

<p>As detailed in the University of M√ºnster‚Äôs press releases (<a href="https://www.uni-muenster.de/news/view.php?cmdid=10183&amp;lang=en">English</a>, <a href="https://www.uni-muenster.de/news/view.php?cmdid=10182">German</a>), we are<!--more-->fortunate to collaborate with publishers to achieve the following objectives:</p>

<ul>
  <li>Use ERCs for actual scientific publications in <strong><a href="/pilots">pilot studies</a></strong> with original research manuscripts in a scholarly peer review</li>
  <li><strong>Eliminate barriers</strong> for using ERCs as part of a publishing process</li>
  <li><strong>Evaluate</strong> concept and pilots with user studies and monitoring to understand the costs and benefits of ERC-based authoring, publishing, and reading</li>
</ul>

<p><a href="/public/images/2019-04-15_platform-pr.png"><img src="/public/images/2019-04-15_platform-pr.png" alt="o2r platform mockup" /></a></p>
<p class="attributionInlineImage">
This is how a scientific publication can be presented in the future: on the left is the original publication, on the right the readers can work with the research data themselves. ¬© o2r - based on <a href="https://doi.org/10.5194/nhess-16-2577-2016">F. Dottori et al./ Nat. HazardsEarth Syst. Sci.</a>
</p>

<p>As the official press statement was edited for brevity, we‚Äôd like to use the opportunity to extend on it here:</p>

<blockquote>
  <p>The project ‚ÄúOpening Reproducible Research II‚Äù (o2r2) will be supported by the German Research Foundation (<a href="https://www.dfg.de/en/">DFG</a>) under the umbrella of the programme for Library Services and Information Systems (<a href="https://www.dfg.de/en/research_funding/programmes/infrastructure/lis/index.html">LIS</a>).
Building on the results of the predecessor project, it will test, evaluate, and further develop solutions for improving reproducibility of research results in practice over the next 30 months.
The o2r project will conduct three pilot studies.
The Open Access publisher <a href="https://publications.copernicus.org/"><em>Copernicus Publications</em></a> and a large commercial publisher could be won for the project to conduct two pilot studies in the form of special issues for scientific journals, in which classic articles will be enriched with interactive and transparent analyses.
In a third pilot, an open source software for the publication of scientific journals, Open Journal Systems by the Public Knowledge Project (<a href="https://pkp.sfu.ca/ojs/">OJS by PKP</a>), which is widely used in the scientific community, will be connected to the o2r reproducibility service and piloted at the ULB M√ºnster together with researchers and students from the geosciences.
Developments for OJS will be contributed to the global and national communities, including <a href="http://www.ojs-de.net/">OJS-de.net</a>.
These pilots will be accompanied by various evaluations: with the help of authors, reviewers, and students, the transformation potential of reproducible scientific articles will be investigated.
A focus lies on analyses based on geospatial data and the programming language R.
Futhermore, the operation provides relevant insights into the costs and efforts for contemporary publishing of and interaction with data-based scientific research.
All specifications and tools of o2r2 are published under free licenses and where possible are realised as contributions to existing Open Source projects.
The project‚Äôs developments and results provide building blocks and concepts for a future infrastructure for enhanced scholarly communication and academic publications.</p>
</blockquote>

<p>We realise these goals are ambitious, but look forward confidently to work with the Open Science and Open Source communities to make them reality.</p>

<hr />

<p>As a first action, o2r team member Daniel attended the <a href="https://egu2019.eu/">EGU General Assembly in Vienna last week</a> to start the conversation about the pilot with EGU journals with journal editors.
With the support of Copernicus staff, we distributed flyers about the planned Virtual Special Issue to journal editors of the Copernicus journals.
You can read more about the plans <a href="/pilots/#copernicus">on the Pilots page</a>.
Since we are very early in the project, it comes only as a little setback that Daniel could only speak to a handful of editors.
We plan to intensify our outreach to journals and editors later this year, when the first working prototypes can tell the story much more convincing than a paper leaflet can - <em>isn‚Äôt that what executable interactive publications are all about?</em></p>

<p>Besides reaching out to editors, discussing <a href="https://twitter.com/EarthArXiv/status/1115700257856397313">Open Access &amp; preprints</a>, and putting <a href="https://twitter.com/search?q=%23egu19rse">research software</a> on the map, Daniel also presented <a href="https://doi.org/10.5281/zenodo.2630482">a poster</a> on <em>packaging research</em>, with many fun interactions and discussions.</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">One more (hopefully) <a href="https://twitter.com/hashtag/betterposter?src=hash&amp;ref_src=twsrc%5Etfw">#betterposter</a>  at <a href="https://twitter.com/hashtag/EGU19?src=hash&amp;ref_src=twsrc%5Etfw">#EGU19</a> on advantages on packaging research using containers and community standards, powered by <a href="https://twitter.com/o2r_project?ref_src=twsrc%5Etfw">@o2r_project</a> Find poster and abstract at <a href="https://t.co/fKjQ57uuhp">https://t.co/fKjQ57uuhp</a> <a href="https://t.co/tjeJ582ZRq">pic.twitter.com/tjeJ582ZRq</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/1116682650910064640?ref_src=twsrc%5Etfw">12. April 2019</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2019/02/24/archiving-jekyll-zenodo/">Archiving a Research Project Website on Zenodo</a></h3>
<span class="post-date">24 Feb 2019 | By Daniel N√ºst</span>
<p>The o2r project website‚Äôs first entry <a href="/2016/01/19/introducing-o2r/">Introducing o2r</a> was published <a href="https://www.timeanddate.com/date/durationresult.html?d1=19&amp;m1=1&amp;y1=2016&amp;d2=24&amp;m2=2&amp;y2=2019">1132 days ago</a>.
Since then we‚Äôve published short and long reports about events the o2r team participated in, advertised new scholarly publications we were lucky to have accepted in journals, and reported on results of workshops organised by o2r.
But there has also been some original content from time to time, such as the extensive articles on <a href="/2016/12/15/investigating-docker-and-R/">Docker and R</a>, which received several updates over the last years (some still pending), on the <a href="/2018/11/21/elife-sprint-integrating-stencila-and-binder/">integration of Stencila and Binder</a>, or on <a href="/2019/02/04/write-reproducible-manuscripts-for-copernicus-publications-journals/">writing reproducible articles for Copernicus Publications</a>.
These posts are a valuable output of the project, and contribute to the scholarly discussion.
Therefore, when it came to writing a report on the project‚Äôs activities and outputs, it was time to consider the <a href="https://en.wikipedia.org/wiki/Digital_preservation">preservation</a> of the project website and blog.
The website is built with <a href="http://jekyllrb.com/">Jekyll</a> (with Markdown source files) and <a href="https://github.com/o2r-project/o2r-project.github.io">hosted with GitHub pages</a>, but GitHub may disappear and Jekyll might stop working at some point.</p>

<p><em>So how can we archive the blog post and website in a sustainable way, without any manual interference?</em></p>

<p>Today‚Äôs blog post documents the steps to automatically deposit the sources, the HTML rendering, a PDF rendering, and the whole git repository in a new version of a <a href="https://doi.org/10.5281/zenodo.1485437">Zenodo deposit</a> with each new blog post using <a href="help.zenodo.org#versioning">Zenodo‚Äôs DOI versioning</a>.
The PDF was especially tricky but is very important, because the format is established for archival of content, while using the Zenodo API was pretty straightforward.
We hope the presented workflow might be useful for other websites and blogs in a scientific context.
It goes like this:</p>

<ol>
  <li>The <a href="https://en.wikipedia.org/wiki/Makefile">Makefile</a> target <code class="highlighter-rouge">update_zenodo_deposit</code> starts the whole process with <code class="highlighter-rouge">make update_zenodo_deposit</code>. It triggers several other make targets, some of which require two processes to run at the same time:</li>
  <li>Remove previously existing outputs (‚Äúclean‚Äù).</li>
  <li>Build the whole page with Jekyll and <a href="https://jekyllrb.com/docs/usage/">serve</a> it using a local web server.</li>
  <li>Create a PDF from the whole website from the local web server using <a href="https://wkhtmltopdf.org/"><code class="highlighter-rouge">wkhtmltopdf</code></a> and the special page <a href="/all_content">/all_content</a>, which renders <em>all</em> blog entries in a suitable layout together with an automatically compiled list of author names and all website pages, unless they are excluded from the menu (e.g. manual redirection/shortened URLs) or excluded from ‚Äúall pages‚Äù (e.g. the 404 page, blogroll, or publications list).</li>
  <li>Create a ZIP archive with the sources, HTML rendering and PDF capture.</li>
  <li>Run a Python script to upload the PDF and ZIP files to Zenodo using the <a href="http://developers.zenodo.org/">Zenodo API</a>, which includes several requests to retrieve the latest version metadata, check that there really is a new blog post, create a new deposit, remove the existing files in the deposit, upload the new files, and eventually publish the record.</li>
  <li>Kill the still running web server.</li>
</ol>

<p>For these steps to run automatically, the <a href="https://travis-ci.org/">Travis CI</a> configuration file, <a href="https://github.com/o2r-project/o2r-project.github.io/blob/master/.travis.yml"><code class="highlighter-rouge">.travis.yml</code></a>, installs the required software environment () to conduct all above steps during <a href="https://travis-ci.org/o2r-project/o2r-project.github.io/builds">each build</a>.
It also includes a <a href="https://docs.travis-ci.com/user/encryption-keys/">encrypted environment variable</a> with a Zenodo API key, so the build system provided by Travis CI can manipulate the record, the first version of which was created manually and included the record description, authors, tags, etc.</p>

<p><a href="https://doi.org/10.5281/zenodo.1485437"><img src="/public/images/2019-02_zenodo-record-screenshot.png" alt="" width="300" class="img rightfloat" /></a></p>

<p><em>So what is possible now?</em>
As pointed out in the citation note at the bottom of pages and posts, the Digital Object Identifier (<a href="https://en.wikipedia.org/wiki/Digital_object_identifier">DOI</a>) allows referencing the whole website or specific posts (via pages in the PDF) in scholarly publications.
Manual archival from a local computer is still possible by triggering the same make target.
As long as Zenodo exists, readers have access to all content published by the o2r research project on its website.</p>

<p>There are no specific next steps planned, but there‚Äôs surely room for improvement as the current workflow is pretty complex.
The post publication date is the trigger for a new version, so changes in a page such as <a href="/about">About</a> or in an existing post requires a manual triggering of the workflow (and commenting out the check for a new post) or wait for the next blog entry.
The created PDF <a href="https://github.com/o2r-project/o2r-project.github.io/issues/29">could be made compliant</a> with <a href="https://en.wikipedia.org/wiki/PDF/A">PDF/A</a>.
The control flow could also be implemented completely in Python instead of using multiple files and languages; a Python module might even properly manage the system dependencies.
Though large parts of the process are not limited to pages generated with Jekyll (the capturing and uploading), it might be effectively wrapped in a standalone Jekyll <a href="https://jekyllrb.com/docs/plugins/">Jekyll plugin</a>, or a combination of a Zenodo plugin together with the (stale?) <a href="https://github.com/abeMedia/jekyll-pdf"><code class="highlighter-rouge">jekyll-pdf</code> plugin</a>?
<em>Your feedback is very welcome!</em></p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2019/02/16/r-r-workshop-at-sparc/">R&amp;R Workshop at SPARC</a></h3>
<span class="post-date">16 Feb 2019 | By Daniel N√ºst</span>
<p>The capabilities of containerisation and the concept of the <a href="https://doi.org/10.1045/january2017-nuest">Executable Research Compendium</a> form the basis for o2r‚Äôs <a href="https://o2r.info/results/">reproducibility service</a>.
But the demonstration how latest technology may support a more open and transparent scholarly publication alone is only one half the battle.
Breakthroughs in tools and infrastructure must be accompanied by outreach activities to highlight the need for opening reproducible research to all stakeholders (scientists, editors, publishers, funding agencies).
That is why I was extremely glad to join some of the most renowned researchers of geography and GI Science at the <a href="https://sgsup.asu.edu/sparc/RRWorkshop">‚ÄúReplicability and Reproducibility Workshop‚Äù</a> in Tempe, Arizona, on February 11 and 12, 2019.
The event was organised by the Spatial Analysis Research Center (<a href="https://sgsup.asu.edu/SPARC">SPARC</a>) at Arizona State University (<a href="https://www.asu.edu/">ASU</a>).</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">Daniel Nust from the University of Munster presenting at our Replicability and Reproducibility in Geospatial Research: Open is not enough for reproducibility! <a href="https://t.co/PwpVmwdQ7b">pic.twitter.com/PwpVmwdQ7b</a></p>&mdash; SPARC at ASU (@SPARC_ASU) <a href="https://twitter.com/SPARC_ASU/status/1095001323299172352?ref_src=twsrc%5Etfw">11. Februar 2019</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>The events featured<!--more--> four full talks.
I was invited to go first and report on the activities of o2r as well as the <a href="https://o2r.info/reproducible-agile/">Reproducible AGILE</a> conference series and initiative for developing new submission and reviewing guidelines.
The expectations were high, but after three years of intense work by the o2r team, the allotted time was easily filled.
After introducing <em>challenges</em> which disrupt scholarly publication practices, I reported on <em>observations</em> made by <a href="https://o2r.info/publications/">our own surveys</a> and others on reproducibility, including the <a href="https://o2r.info/publications/">two reproduction campaigns</a> let be the o2r team.
The painted picture unsurprisingly left a lot of room for improvement, for which the talk provided technical as well as organisational <em>approaches</em>.</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">Just finished my talk on challenges, observations and approaches towards reproducible research at the SPARC workshop <a href="https://twitter.com/hashtag/RandR?src=hash&amp;ref_src=twsrc%5Etfw">#RandR</a> <a href="https://twitter.com/hashtag/geospatial?src=hash&amp;ref_src=twsrc%5Etfw">#geospatial</a> <a href="https://twitter.com/ASU?ref_src=twsrc%5Etfw">@ASU</a> Find the slides and material (including speaker notes in the source file with all the stuff I forgot!) at <a href="https://t.co/cSRZ1DkwhO">https://t.co/cSRZ1DkwhO</a> <a href="https://t.co/FXjNj0hT2K">pic.twitter.com/FXjNj0hT2K</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/1095029238132948992?ref_src=twsrc%5Etfw">11. Februar 2019</a></blockquote>

<p>In the second talk, ASU‚Äôs own <a href="https://sgsup.asu.edu/peter-kedron">Peter Kedron</a> took a step back and surveyed the existing definitions of replicability and reproducibility.
Peter then excellently connected and extended these terms with the intricacies and specifics of geospatial sciences.
The technical and theoretical groundwork was layed, so the discussion following the first talks set the bar for the remainder of the workshop quite high.
Many critical and thoughtful comments were made and viewpoints shared.
One of the main take-home messages for me was that while geography/GI Science/related disciplines may take advantage of the hard lessons learned in other domains (which faced a ‚Äòreplication crisis‚Äô), the uniqueness of geography as a science that always had to deal with uncertainty and <em>context</em> may also contribute a unique perspective on replicability and reproducibility.
It was great to see that the topic of reproducibility is widely acknowledged as a relevant challenge and the interest to initiate improvement was unilateral.</p>

<p>The first day continued with <em>lightning talks</em>.
As could be expected, the diverse backgrounds (eScience, ecology, political geography, ‚Ä¶) let to a very useful diversity in topics and perspectives.
Afterwards the participants split up into three groups to tackle technical, organisational, and institutional aspects of replicability and reproducibility, which gave input for yet another thoughtful debate in the assembly to conclude day one.
The discussions continued between old colleagues and new friends during a delightful evening reception and dinner.</p>

<p>Day two kicked of in a similar fashion with talks by <a href="https://directory.uark.edu/people/dsui">Daniel Sui</a>, University of Arkansas, and Esri‚Äôs <a href="https://en.wikipedia.org/wiki/Dawn_Wright">Dawn Wright</a> and Kevin Butler.
Again two very different takes on the topic, with valuable new ideas.
The following discussion was lively and included potential venues for the newly formed group to continue the collaboration, most importantly to increase the awareness of the topic across all communities working with spatial data.
The whole meeting was nicely guided and framed by contributions from ASU‚Äôs <a href="https://en.wikipedia.org/wiki/Michael_Frank_Goodchild">Mike Goodchild</a> and <a href="https://sgsup.asu.edu/stewart-fotheringham">Stewart Fotheringham</a>.
All participants were united in their interest to advance transparency and openness and a realisation that there is a need for action from many different angles, including education and evaluation, if a ‚Äòcrisis‚Äô shall be avoided.
Despite some concerns how the topic might be received by critics, the meeting ended in a positive mood of newfound mutual support and of acknowledging the value of the work ahead.</p>

<p><em>My personal opinion is that the disruptions in science are more pressing than a traditional scholarly approach (organising a special issue for 2020, writing an editorial) can answer.
Yet the old-school way may be able to bridge across the divide and different skill-set/mindset/needs between computational/junior/young/technical and theoretical/senior researchers, and is as such worth pursuing.
For future discussions, I plan to frame reproducibility as an ideal that is worth striving for and worth to reward (e.g. in evaluations, during reviews, using badges, in funding schemes), but to be careful with too simple checklists and dos/don‚Äôts, because there will always be corner cases and limitations for specific circumstances.
This is a core difference between reproducibility and openness - you can not be a little or partially open, but being almost reproducible is still an important achievement.
Reproducibility and replicability will not be helped by whataboutism nor by pointing fingers, but the positive <a href="https://doi.org/10.1038/d41586-018-05256-0">spirit of preproducibility</a>.</em></p>

<p>Luckily there is no need to echo all insights by talks and during the discussions: the sessions were recorded on video they will be published together with slides and position papers in an OSF project soon.
<!-- **[https://osf.io/gvp3q/](https://osf.io/gvp3q/)**. -->
This post will be updated then. <a href="https://twitter.com/nordholmen">Follow</a> <a href="https://twitter.com/o2r_project">us</a> on Twitter to not miss it.
Until then you can take a look at my position paper <a href="https://gitlab.com/nuest/rr-geospatial-sparc/">on GitLab</a>, even the speaker notes in the presentation source file if you dare.</p>

<p>This post would be incomplete without a big <em>Thank You</em> to the sponsoring and excellent organisation provided by <a href="https://www.esri.com/">Esri</a> and the hosting School of Geographical Sciences and Urban Planning (<a href="https://sgsup.asu.edu/">SGSUP</a>).
I am confident this workshop may spark new collaborations and be able to put replicability and reproducibility on the map for more researchers in geography and related disciplines.</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">On the last flight back home after a great week with <a href="https://twitter.com/SPARC_ASU?ref_src=twsrc%5Etfw">@SPARC_ASU</a>. They brought together a great group of people to talk about <a href="https://twitter.com/hashtag/reproducibleresearch?src=hash&amp;ref_src=twsrc%5Etfw">#reproducibleresearch</a>. Thank you!<br />I enjoyed learning more about geospatial specialities with R&amp;R, hiking Arizona, and starting new collaborations. <a href="https://twitter.com/hashtag/PhDlife?src=hash&amp;ref_src=twsrc%5Etfw">#PhDlife</a> <a href="https://t.co/mb1lu9Nc0Q">pic.twitter.com/mb1lu9Nc0Q</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/1096437456583512065?ref_src=twsrc%5Etfw">15. Februar 2019</a></blockquote>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2019/02/04/write-reproducible-manuscripts-for-copernicus-publications-journals/">How to increase reproducibility and transparency in your research</a></h3>
<span class="post-date">04 Feb 2019 | By Daniel N√ºst</span>
<p><em>[This article is cross posted-on the <a href="https://blogs.egu.eu/geolog/2019/02/01/reproducibility-and-transparency-in-research/">EGU GeoLog</a>.]</em></p>

<p>Contemporary science faces many challenges in publishing results that are reproducible.
This is due to increased usage of data and digital technologies as well as heightened demands for scholarly communication.
These challenges have led to widespread <a href="#munafo">calls</a> for more research transparency, accessibility, and reproducibility from the science community.
This article presents current findings and solutions to these problems, including recent new software that makes writing submission-ready manuscripts for journals of <em><a href="https://www.copernicus.org/">Copernicus Publications</a></em> a lot easier.
<!--more-->
While it can be debated if science really faces a <a href="#baker">reproducibility</a> <a href="#fanelli">crisis</a>, the challenges of computer-based research have sparked numerous articles on new <a href="#wilson">good</a> <a href="#gil">research</a> <a href="#sandve">practices</a> and their <a href="#hardwicke">evaluation</a>.
The challenges have also driven researchers to develop infrastructure and tools to help scientists effectively write articles, publish data, share code for computations, and communicate their findings in a reproducible way, for example <a href="#jupyter">Jupyter</a>, <a href="#reprozip">ReproZip</a> and <a href="https://research-compendium.science/">research compendia</a>.</p>

<p><a href="#konkol">Recent</a> <a href="#nuest">studies</a> <a href="#ostermann">showed</a> that the geosciences and geographic information science are not beyond issues with reproducibility, just like other domains.
Therefore, more and more <a href="https://www.nature.com/authors/policies/availability.html">journals</a> have <a href="#stodden">adopted policies</a> on sharing data and code.
However, it is equally important that scientists foster an <a href="#nosek">open research culture</a> and teach researchers how they adopt more transparent and reproducible workflows, for example at skill-building workshops at conferences offered by fellow researchers, such as the EGU short courses, community-led non-profit organisations such as the <a href="https://carpentries.org/">Carpentries</a>, <a href="#toelch">open courses for students</a>, small discussion groups at research labs, or individual efforts of self-learning.
In the light of prevailing <a href="#barba">issues of a common definition</a> of reproducibility, <a href="#stark">Philip Stark</a>, a statistics professor and associate dean of mathematical and physical sciences at the University of California, Berkeley, recently coined the term <a href="#stark"><em>preproducibility</em></a>: <em>‚ÄúAn experiment or analysis is preproducible if it has been described in adequate detail for others to undertake it.‚Äù</em>
The neologism intends to reduce confusion and also to embrace a positive attitude for more openness, honesty, and helpfulness in scholarly communication processes.</p>

<!-- image here! -->
<p><a href="https://twitter.com/NatureNews/status/999715421208104960"><img src="/public/images/2018-11_showme-nottrustme-nature.png" alt="" /></a></p>

<p>In the spirit of these activities, this article describes a modern workflow made possible by recent software releases.
The new features allow the EGU community to write preproducible manuscripts for submission to the large variety of academic journals published by <a href="https://www.copernicus.org/"><em>Copernicus Publications</em></a>.
The new workflow might require hard-earned adjustments for some researchers, but it pays off because of an increase in transparency and effectivity.
This is especially the case for early career scientists.
An open and reproducible workflow enables researchers to build on others‚Äô and own previous work and better collaborate on solving the societal challenges of today.</p>

<h4 id="reproducible-research-manuscripts">Reproducible research manuscripts</h4>

<p><a href="https://en.wikipedia.org/wiki/Open-notebook_science">Open</a> digital <a href="https://arxiv.org/abs/1804.05492">notebooks</a>, which <a href="https://en.wikipedia.org/wiki/Literate_programming">interweave data and code</a> and can be exported to different output formats such as PDF, are powerful means to improve transparency and preproducibility of research.
<a href="https://jupyter.org/">Jupyter Notebook</a>, <a href="http://stenci.la/">Stencila</a> and <a href="https://rmarkdown.rstudio.com/">R Markdown</a> let researchers combine long-form text of a publication and source code for analysis and visualisation in a single document.
Having text and code side-by-side makes them easier to grasp and ensures consistency, because each rendering of the document executes the whole workflow using the original data.
Caching for long-lasting computations is possible, and researchers working with supercomputing infrastructures or huge datasets may limit the executed code to purposes of visualisation using processed data as input.
Authors can transparently expose specific code snippets to readers but also publish the complete source code of the document openly for collaboration and review.</p>

<p>The popular notebook formats are plain text-based, like <a href="https://en.wikipedia.org/wiki/Markdown">Markdown</a> in case of R Markdown.
Therefore an R Markdown document can be managed with <a href="https://en.wikipedia.org/wiki/Version_control">version control software</a>, which are programs for managing multiple versions and contributions, even by different people, to the same documents.
Version control provides traceability of authorship, a time machine for going back to any previous ‚Äúworking‚Äù version, and online collaboration such as on <a href="https://en.wikipedia.org/wiki/GitLab">GitLab</a>.
This kind of workflow also stops <a href="http://phdcomics.com/comics/archive_print.php?comicid=1531">the madness of using file names for versions</a> yet still lets authors use <a href="https://speakerdeck.com/jennybc/how-to-name-files">awesome file names</a> and apply domain-specific <a href="#marwick">guidelines for packaging research</a>.</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">Final.doc <a href="https://t.co/YXJaSacHWu">https://t.co/YXJaSacHWu</a> <a href="https://t.co/4bBDzn7TXt">pic.twitter.com/4bBDzn7TXt</a></p>&mdash; PHD Comics (@PHDcomics) <a href="https://twitter.com/PHDcomics/status/826861642507882496?ref_src=twsrc%5Etfw">1. Februar 2017</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>R Markdown supports <a href="https://rmarkdown.rstudio.com/lesson-5.html">different programming languages</a> besides the popular namesake <a href="https://www.r-project.org/">R</a> and is a sensible solution even if you do not analyse data with scripts nor have any code in your scholarly manuscript.
It is easy to write, allows you to <a href="https://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html">manage your bibliography</a> effectively, can be used for websites, <a href="https://bookdown.org/">books</a> or <a href="https://bookdown.org/yihui/blogdown/">blogs</a>, but most importantly <em>it does not fall short when it is time to submit a manuscript article to a journal</em>.</p>

<p>The <a href="https://cran.r-project.org/package=rticles"><code class="highlighter-rouge">rticles</code></a> extension package for R provides a number of templates for popular journals and publishers.
Since version <code class="highlighter-rouge">0.6</code> (<a href="https://github.com/rstudio/rticles/releases/tag/v0.6">published Oct 9 2018</a>) these <a href="https://github.com/rstudio/rticles/pull/172">templates include</a> the <a href="https://publications.copernicus.org/for_authors/manuscript_preparation.html">Copernicus Publications Manuscript preparations guidelines for authors</a>.
The Copernicus Publications staff was kind enough to give a test document a quick review and all seems in order, though of course any problems and questions shall be directed to the software‚Äôs vibrant community and not the publishers.</p>

<p>The following code snippet and screen shot demonstrate the workflow.
Lines starting with <code class="highlighter-rouge">#</code> are code comments and explain the steps.
Code examples provided here are ready to use and only lack the installation commands for required packages.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># load required R extension packages:</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="s2">"rticles"</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="s2">"rmarkdown"</span><span class="p">)</span><span class="w">

</span><span class="c1"># create a new document using a template:</span><span class="w">
</span><span class="n">rmarkdown</span><span class="o">::</span><span class="n">draft</span><span class="p">(</span><span class="n">file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"MyArticle.Rmd"</span><span class="p">,</span><span class="w">
                 </span><span class="n">template</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"copernicus_article"</span><span class="p">,</span><span class="w">
                 </span><span class="n">package</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"rticles"</span><span class="p">,</span><span class="w"> </span><span class="n">edit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">

</span><span class="c1"># render the source of the document to the default output format:</span><span class="w">
</span><span class="n">rmarkdown</span><span class="o">::</span><span class="n">render</span><span class="p">(</span><span class="n">input</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"MyArticle/MyArticle.Rmd"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="/public/images/2018-10_rmd-pdf-example.png" alt="" /></p>

<p>The commands created a directory with the Copernicus Publications template‚Äôs files, including an R Markdown (<code class="highlighter-rouge">.Rmd</code>) file ready to be edited by you (left-hand side of the screenshot), a <a href="https://en.wikipedia.org/wiki/LaTeX">LaTeX</a> (<code class="highlighter-rouge">.tex</code>) file for submission to the publisher, and a <code class="highlighter-rouge">.pdf</code> file for inspecting the final results and sharing with your colleagues (right-hand side of the screenshot).
You can see how simple it is to format text, insert citations, chemical formulas or equations, and add figures, and how they are rendered into a high-quality output file.</p>

<p>All of these steps may also be completed with user-friendly forms when using <a href="https://en.wikipedia.org/wiki/RStudio">RStudio</a>, a popular development and authoring environment available for all operating systems.
The left-hand side of the following screenshot shows the form for creating a new document based on a template, and the right-hand shows side the menu for rendering, called ‚Äúknitting‚Äù with R Markdown because code and text are combined into one document like threads in a garment.</p>

<p><img src="/public/images/2018-10_rstudio-ui-example.png" alt="" /></p>

<p>And in case you decide last minute to submit to a different journal, <a href="https://github.com/rstudio/rticles#overview"><code class="highlighter-rouge">rticles</code> supports many publishers</a> so you only have to adjust the template while the whole content stays the same.</p>

<h4 id="sustainable-access-to-supplemental-data">Sustainable access to supplemental data</h4>

<p>Data published today <a href="http://www.copdess.org/enabling-fair-data-project/commitment-to-enabling-fair-data-in-the-earth-space-and-environmental-sciences/">should</a> be published and properly cited using appropriate <a href="https://www.re3data.org/">research data repositories</a> following the <a href="https://en.wikipedia.org/wiki/FAIR_data">FAIR data</a> <a href="https://www.force11.org/group/fairgroup/fairprinciples">principles</a>.
Journals require authors to follow these principles, see for example the <a href="https://publications.copernicus.org/services/data_policy.html">Copernicus Publications data policy</a> or a recent <a href="#nature">announcement by <em>Nature</em></a>.
Other publishers required, or still do today, to store supplemental information (SI), such as dataset files, extra figures, or extensive descriptions of experimental procedures, as part of the article.
Usually only the article itself receives a digital object identifier (<a href="https://en.wikipedia.org/wiki/Digital_object_identifier">DOI</a>) for long-term identification and availability.
The DOI <a href="https://www.helmholtz-berlin.de/zentrum/locations/bibliothek/dokumentationhaupt/veroeffentlichungsverzeichnis-kopie/doi-vergabe_en.html">minted</a> by the publisher is not suitable for direct access to supplemental files, because it points to a <a href="https://support.crossref.org/hc/en-us/articles/214669863-Your-landing-page">landing</a> <a href="https://support.datacite.org/docs/datacite-doi-display-guidelines#section-applying-the-guidelines">page</a> about the identified object.
This landing page is designed to be read by humans but not by computers.</p>

<p>The R package <a href="https://github.com/ropensci/suppdata"><code class="highlighter-rouge">suppdata</code></a> <a href="#pearse">closes this gap</a>.
It supports downloading supplemental information using the article‚Äôs DOI.
This way <code class="highlighter-rouge">suppdata</code> enables long-term reproducible data access when data was published as SI in the past or in exceptional cases today, for example if you write about a reproduction of a published article.
In the latest version available <a href="https://github.com/ropensci/suppdata/blob/master/README.md">from GitHub</a> (suppdata is <a href="https://github.com/ropensci/suppdata/issues/31">on its way</a> to <a href="https://cran.r-project.org/package=suppdata">CRAN</a>) the <a href="https://github.com/ropensci/suppdata#supported-publishers-and-repositories">supported publishers</a> include Copernicus Publications.
The following example code downloads a data file for the article <a href="https://doi.org/10.5194/bg-14-1739-2017">‚ÄúDivergence of seafloor elevation and sea level rise in coral reef ecosystems‚Äù</a> by Yates et al. published in <em>Biogeosciences</em> in 2017.
The code then creates a mostly meaningless plot shown below.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># load required R extension package:</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="s2">"suppdata"</span><span class="p">)</span><span class="w">

</span><span class="c1"># download a specific supplemental information (SI) file</span><span class="w">
</span><span class="c1"># for an article using the article's DOI:</span><span class="w">
</span><span class="n">csv_file</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">suppdata</span><span class="o">::</span><span class="n">suppdata</span><span class="p">(</span><span class="w">
  </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"10.5194/bg-14-1739-2017"</span><span class="p">,</span><span class="w">
  </span><span class="n">si</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Table S1 v2 UFK FOR_PUBLICATION.csv"</span><span class="p">)</span><span class="w">
</span><span class="n">supplemental</span><span class="w">

</span><span class="c1"># read the data and plot it (toy example!):</span><span class="w">
</span><span class="n">my_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.csv</span><span class="p">(</span><span class="n">file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">csv_file</span><span class="p">,</span><span class="w"> </span><span class="n">skip</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">my_data</span><span class="o">$</span><span class="n">NAVD88_G03</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">my_data</span><span class="o">$</span><span class="n">RASTERVALU</span><span class="p">,</span><span class="w">
     </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Historical elevation (NAVD88 GEOID03))"</span><span class="p">,</span><span class="w">
     </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"LiDAR elevation (NAVD88 GEOID03)"</span><span class="p">,</span><span class="w">
     </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"A data plot for article 10.5194/bg-14-1739-2017"</span><span class="p">,</span><span class="w">
     </span><span class="n">pch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<!--
png(file = "public/images/2018-10_suppdata-example-plot.png", width = 512, height = 512, bg = "white")
plot(x = my_data$NAVD88_G03, y = my_data$RASTERVALU,
  xlab = "Historical elevation (NAVD88 GEOID03))",
  ylab = "LiDAR elevation (NAVD88 GEOID03)",
  main = "A silly plot for article 10.5194/bg-14-1739-2017",
  pch = 20, cex = 0.5)
dev.off()
-->

<p><img src="/public/images/2018-10_suppdata-example-plot.png" alt="" /></p>

<h4 id="main-takeaways">Main takeaways</h4>

<p>Authoring submission-ready manuscripts for journals of Copernicus Publications just got a lot easier.
Everybody who can write manuscripts with a word processor can learn quickly R Markdown and benefit from a preproducible data science workflow.
Digital notebooks not only improve day-to-day research habits, but the same workflow is suitable for authoring high-quality scholarly manuscripts and graphics.
The interaction with the publisher is smooth thanks to the LaTeX submission format, but you never have to write any LaTeX.
The workflow is based on an established <a href="https://en.wikipedia.org/wiki/Free_and_Open-Source_Software">Free and Open Source</a> software stack and embraces the idea of preproducibility and the principles of <a href="https://en.wikipedia.org/wiki/Open_science">Open Science</a>.
The software is maintained by an <a href="https://stackoverflow.com/questions/tagged/r">active</a>, <a href="https://stackoverflow.blog/2017/10/10/impressive-growth-r/">growing</a>, and welcoming community of researchers and developers with a <a href="https://www.r-spatial.org/">strong connection</a> to <a href="https://gis.stackexchange.com/questions/tagged/r">the</a> <a href="https://geocompr.github.io/">geospatial</a> <a href="https://asdar-book.org/">sciences</a>.
Because of the complete and consistent notebook, <a href="#markowetz">you</a>, a colleague, or a student can easily pick up the work at a later time.
The road to effective and transparent research begins with a first step - <a href="https://vickysteeves.gitlab.io/repro-papers/">take it</a>!</p>

<h4 id="acknowledgements">Acknowledgements</h4>

<p>The software updates were contributed by <a href="https://orcid.org/0000-0002-0024-5046">Daniel N√ºst</a> from the project <a href="https://o2r.info">Opening Reproducible Research</a> (o2r) at the Institute for Geoinformatics, University of M√ºnster, Germany, but would not be able without the support of Copernicus Publications, the software maintainers most notably <a href="https://yihui.name/">Yihui Xie</a> and <a href="http://www.pearselab.com/">Will Pearse</a>, and the general awesomeness of the R, R-spatial, Open Science, and Reproducible Research communities.
The blog text was greatly improved with feedback by EGU‚Äôs <a href="http://oliviatrani.org/">Olivia</a> <a href="https://twitter.com/oliviatrani">Trani</a> and Copernicus Publications‚Äô <a href="https://twitter.com/XeniavanEdig">Xenia</a> <a href="https://www.copernicus.org/contact_us.html">van Edig</a>.
Thank you!</p>

<h4 id="references">References</h4>

<!-- https://crosscite.org/ has a style "copernicus-publications" -->

<ul>
  <li><a name="nature"></a><a href="https://doi.org/10.1038/d41586-019-00075-3">Announcement: FAIR data in Earth science</a>, Nature, 565(7738), 134‚Äì134, doi:10.1038/d41586-019-00075-3, 2019.</li>
  <li><a name="baker"></a>Baker, M.: <a href="https://doi.org/10.1038/533452a">1,500 Scientists Lift the Lid on Reproducibility</a>, Nature, 533(7604), 452‚Äì454, doi:10.1038/533452a, 2016.</li>
  <li><a name="barba"></a>Barba, L.¬†A.: <a href="http://arxiv.org/abs/1802.03311">Terminologies for Reproducible Research</a>, ArXiv:1802.03311 [Cs], February 9, 2018.</li>
  <li><a name="fanelli"></a>Fanelli, D.: <a href="https://doi.org/10.1073/pnas.1708272114">Opinion: Is Science Really Facing a Reproducibility Crisis, and Do We Need It To?</a>, Proceedings of the National Academy of Sciences, 115(11), 2628‚Äì2631, doi:10.1073/pnas.1708272114, 2018.</li>
  <li><a name="gil"></a>Gil, Y., David, C.¬†H., Demir, I., Essawy, B.¬†T., Fulweiler, R.¬†W., Goodall, J.¬†L., Karlstrom, L., Lee, H., Mills, H.¬†J., Oh, J.-H., Pierce, S.¬†A., Pope, A., Tzeng, M.¬†W., Villamizar, S.¬†R.¬†and Yu, X.: <a href="https://doi.org/10.1002/2015EA000136">Towards the Geoscience Paper of the Future: Best Practices for Documenting and Sharing Research from Data to Software to Provenance</a>, Earth and Space Science, 3(10), 388‚Äì415, doi:10.1002/2015ea000136, 2016.</li>
  <li><a name="hardwicke"></a>Hardwicke, T.¬†E., Mathur, M.¬†B., MacDonald, K., Nilsonne, G., Banks, G.¬†C., Kidwell, M.¬†C., Hofelich Mohr, A., Clayton, E., Yoon, E.¬†J., Henry Tessler, M., Lenne, R.¬†L., Altman, S., Long, B. and Frank, M.¬†C.: <a href="https://doi.org/10.1098/rsos.180448">Data availability, reusability, and analytic reproducibility: evaluating the impact of a mandatory open data policy at the journal Cognition</a>, Royal Society Open Science, 5(8), 180448, doi:10.1098/rsos.180448, 2018.</li>
  <li><a name="konkol-cgis"></a>Konkol, M. and Kray, C.: <a href="https://doi.org/10.1080/15230406.2018.1512421">In-depth examination of spatiotemporal figures in open reproducible research</a>, Cartography and Geographic Information Science, 1‚Äì16, doi:10.1080/15230406.2018.1512421, 2018.</li>
  <li><a name="konkol-ijgis"></a>Konkol, M., Kray, C. and Pfeiffer, M.: <a href="https://doi.org/10.1080/13658816.2018.1508687">Computational reproducibility in geoscientific papers: Insights from a series of studies with geoscientists and a reproduction study</a>, International Journal of Geographical Information Science, 1‚Äì22, doi:10.1080/13658816.2018.1508687, 2018.</li>
  <li><a name="markowetz"></a>Markowetz, F.: <a href="https://doi.org/10.1186/s13059-015-0850-7">Five selfish reasons to work reproducibly</a>, Genome Biology, 16(1), doi:10.1186/s13059-015-0850-7, 2015.</li>
  <li><a name="marwick"></a>Marwick, B., Boettiger, C. and Mullen, L.: <a href="https://doi.org/10.1080/00031305.2017.1375986">Packaging Data Analytical Work Reproducibly Using R (and Friends)</a>, The American Statistician, 72(1), 80‚Äì88, doi:10.1080/00031305.2017.1375986, 2017.</li>
  <li><a name="munafo"></a>Munaf√≤, M.¬†R., Nosek, B.¬†A., Bishop, D.¬†V.¬†M., Button, K.¬†S., Chambers, C.¬†D., Percie du Sert, N., Simonsohn, U., Wagenmakers, E.-J., Ware, J.¬†J. and Ioannidis, J.¬†P.¬†A.: <a href="https://doi.org/10.1038/s41562-016-0021">A manifesto for reproducible science, Nature Human Behaviour</a>, 1(1), 21, doi:10.1038/s41562-016-0021, 2017.</li>
  <li><a name="nuest"></a>N√ºst, D., Granell, C., Hofer, B., Konkol, M., Ostermann, F.¬†O., Sileryte, R. and Cerutti, V.: <a href="https://doi.org/10.7717/peerj.5072">Reproducible research and GIScience: an evaluation using AGILE conference papers</a>, PeerJ, 6, e5072, doi:10.7717/peerj.5072, 2018.</li>
  <li><a name="ostermann"></a>Ostermann, F.¬†O. and Granell, C.: <a href="https://doi.org/10.1111/tgis.12195">Advancing Science with VGI: Reproducibility and Replicability of Recent Studies using VGI</a>, Transactions in GIS, 21(2), 224‚Äì237, doi:10.1111/tgis.12195, 2016.</li>
  <li><a name="pearse"></a>Pearse, W.¬†D. and A Chamberlain, S.: <a href="https://doi.org/10.21105/joss.00721">Suppdata: Downloading Supplementary Data from Published Manuscripts</a>, Journal of Open Source Software, 3(25), 721, doi:10.21105/joss.00721, 2018.</li>
  <li><a name="repozip"></a><a href="https://osf.io/vc72z/">ReproZip: Computational Reproducibility With Ease</a>, F. Chirigati, R. Rampin, D. Shasha, and J. Freire. In Proceedings of the 2016 ACM SIGMOD International Conference on Management of Data (SIGMOD), pp. 2085-2088, 2016</li>
  <li><a name="sandve"></a>Sandve, G.¬†K., Nekrutenko, A., Taylor, J. and Hovig, E.: <a href="https://doi.org/10.1371/journal.pcbi.1003285">Ten Simple Rules for Reproducible Computational Research</a>, edited by P.¬†E. Bourne, PLoS Computational Biology, 9(10), e1003285, doi:10.1371/journal.pcbi.1003285, 2013.</li>
  <li><a name="stark"></a>Stark, P.¬†B.: <a href="https://doi.org/10.1038/d41586-018-05256-0">Before reproducibility must come preproducibility</a>, Nature, 557(7707), 613‚Äì613, doi:10.1038/d41586-018-05256-0, 2018.</li>
  <li><a name="toelch"></a>Toelch, U. and Ostwald, D.: <a href="https://doi.org/10.1371/journal.pbio.2006022">Digital open science‚ÄîTeaching digital tools for reproducible and transparent research</a>, PLOS Biology, 16(7), e2006022, doi:10.1371/journal.pbio.2006022, 2018.</li>
  <li><a name="jupyter"></a>Jupyter, P., Bussonnier, M., Forde, J., Freeman, J., Granger, B., Head, T., Holdgraf, C., Kelley, K., Nalvarte, G., Osheroff, A., Pacer, M., Panda, Y., Perez, F., Ragan-Kelley, B. and Willing, C.: <a href="http://conference.scipy.org/proceedings/scipy2018/pdfs/project_jupyter.pdf">Binder 2.0 - Reproducible, interactive, sharable environments for science at scale</a>, in Proceedings of the 17th Python in Science Conference, SciPy., 2018.</li>
  <li><a name="wilson"></a>Wilson, G., Bryan, J., Cranston, K., Kitzes, J., Nederbragt, L. and Teal, T.¬†K.: <a href="https://doi.org/10.1371/journal.pcbi.1005510">Good enough practices in scientific computing</a>, PLOS Computational Biology, 13(6), e1005510, doi:10.1371/journal.pcbi.1005510, 2017.</li>
  <li><a name="yates"></a>Yates, K.¬†K., Zawada, D.¬†G., Smiley, N.¬†A. and Tiling-Range, G.: <a href="https://doi.org/10.5194/bg-14-1739-201">Divergence of seafloor elevation and sea level rise in coral reef ecosystems</a>, Biogeosciences, 14(6), 1739‚Äì1772, doi:10.5194/bg-14-1739-2017, 2017.</li>
</ul>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2018/12/17/article-published/">New article published in International Journal of Geographical Information Science</a></h3>
<span class="post-date">17 Dec 2018 | By Markus Konkol, Daniel N√ºst</span>
<p><a href="https://doi.org/10.1080/13658816.2018.1508687"><img src="/public/images/2018-12_ijgis-screenshot.jpg" alt="IJGIS journal article screenshot" title="IJGIS journal article screenshot" width="300" class="img rightfloat" /></a></p>

<p>A few weeks ago, a new journal article written by o2r team member <a href="https://orcid.org/0000-0001-6651-0976">Markus</a> got published.
In <a href="/2018/07/13/peerj-article-published/">our last article</a>, we talked about the reproducibility of papers submitted to the AGILE conference.
We checked if the papers had materials attached and if these materials were complete.
The results were rather unfortunate.
In our newest article, we took one further step and tried to <em>re-run the analyses of articles</em> which had code and data in the supplements.</p>

<blockquote>
  <p><em>Markus Konkol, Christian Kray &amp; Max Pfeiffer (2019). <strong>Computational reproducibility in geoscientific papers: Insights from a series of studies with geoscientists and a reproduction study</strong>, International Journal of Geographical Information Science, 33:2, 408-429, DOI: <a href="https://doi.org/10.1080/13658816.2018.1508687">10.1080/13658816.2018.1508687</a></em></p>
</blockquote>

<p>The article builds upon <a href="/2018/08/14/demo-server-update/">our paper corpus for demonstrating the o2r platform</a>.
Feel free to distribute this piece of research to whoever might be interested.
Feedback is always welcome.</p>

<p>Here is a non-specialist summary:</p>

<blockquote>
  <p>Recreating scientific data analysis is hard, but important.
To learn more about the state of reproducibility in geosciences, we conducted several studies.
We contacted over 150 geoscientists who publish and read articles based on code and data.
We learned that as readers they often would like to have access to these materials, but as authors they often do not have the time or expertise to make them available.
We also collected articles which use computational analyses and tried to execute the attached code.
This was not as easy as it sounds! We describe these numerous issues in a structured way and our experiences in this publication.
Some issues were pretty easy to solve, such as installing a missing library.
Others were more demanding and required deep knowledge of the code which is, as you might imagine, highly time consuming.
Further issues were missing materials (code snippets, data subsets) and flawed functionalities.
In some cases, we contacted the original authors who were, and this was a positive outcome, mostly willing to help.
We also compared the figures we got out of the code with those contained in the original article.
Bad news: We found several differences related to the design of the figures and results that deviated from those described in the paper.
OK, this is interesting, but why is it important?
We argue, a key advantage of open reproducible research is that you can reuse existing materials.
Apparently, this is usually not possible without some significant effort. Our goal is not to blame authors.
We are very happy that they shared their materials.
But they did that with a specific purpose in mind, i.e. making code and data available and reusable for others to build upon that.
One incentive in this context is an increased number of citations, one of the main currencies for researchers.
To facilitate that, we suggest some guidelines to avoid the issues we encountered during our reproducibility study, such as using Executable Research Compendia (ever heard of them? :)).</p>
</blockquote>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2018/11/21/elife-sprint-integrating-stencila-and-binder/">elife sprint: Integrating Stencila and Binder</a></h3>
<span class="post-date">21 Nov 2018 | By Daniel N√ºst</span>
<p><em>This article reports on a project, integrating Stencila and Binder, which started at the eLife Innovation Sprint 2018. It has been cross-posted on multiple blogs (<a href="https://elifesciences.org/labs/d42fe2b9/integrating-binder-and-stencila-the-building-blocks-to-increased-open-communication-and-transparency">eLife Labs</a>, <a href="https://stenci.la/blog/2018-11-20-stencila-binder/">Stencila</a>, <a href="https://blog.jupyter.org/elife-sprint-integrating-stencila-and-binder-18834e9ad584">Jupyter</a>). We welcome comments and feedback on any of them!</em></p>

<p><a href="https://elifesciences.org/">eLife</a>, an open science journal published by the non-profit organisation eLife Sciences Publications from the UK, hosted the first <a href="https://elifesciences.org/labs/bdd4c9aa/elife-innovation-sprint-2018-project-roundup">eLife Innovation Sprint 2018</a> as part of their <a href="https://elifesciences.org/about/innovation">Innovation Initiative</a> in Cambridge, UK:
<em>‚Äú[..] a two-day gathering of 62 researchers, designers, developers, technologists, science communicators and more, with the goal of developing prototypes of innovations that bring cutting-edge technology to open research communication.‚Äù</em>
One of the <a href="https://elifesciences.org/labs/bdd4c9aa/elife-innovation-sprint-2018-project-roundup">13</a> projects at the <a href="https://elifesciences.org/inside-elife/b4ed92e1/innovation-collaboration-and-creativity-at-the-heart-of-the-elife-innovation-sprint-2018">excellently organised event</a> was an <strong>integration of <a href="https://mybinder.readthedocs.io/">Binder</a> and <a href="https://stenci.la/">Stencila</a></strong><!--more-->.</p>

<p>This article reports on the project‚Äôs inception, building blocks, achievements at the sprint weekend, and work conducted in the months following the sprint.
<strong>Today, Binder has first class Stencila support.</strong>
You can open Stencila documents from any online code repository on <a href="https://mybinder.org/">mybinder.org</a> with the click of a single button. Just try out the example below:</p>

<p><a href="https://mybinder.org/v2/gh/binder-examples/stencila-py/master?urlpath=stencila"><img src="https://mybinder.org/badge_logo.svg" alt="Binder" /></a></p>

<h4 id="the-idea-and-the-sprint-team">The idea and the sprint team</h4>

<p>The eLife Innovation Sprint started with brief <a href="https://docs.google.com/presentation/d/1gvyoGW-__7k41KFN4PLhZtpapHNr-4IoeMTIXMiFHDs/edit#">introductions by all participants</a>.
Some of them prepared pitches for projects ideas, which quickly got little group discussions going.
One table at the sprint attracted a few people with an interest in <a href="https://en.wikipedia.org/wiki/Operating-system-level_virtualization">containerisation technology</a> for research applications.
Many ideas were floated and a helpful exchange around existing solutions and tools took place.
When it was time to find a concrete task, two of the sprinters identified a worthwhile technological problem as their challenge for the next 1.5 days and the project ‚ÄúJupyter+DAR compatibility exploration‚Äù started.
<a href="https://github.com/minrk">Min</a> from the <a href="https://www.simula.no/people/benjaminrk">Simula Research Laboratory</a>, Norway, is a core developer of <a href="https://mybinder.readthedocs.io/en/latest/">Binder</a> and related tools.
He was interested to get to know the Stencila project and explore the possibilities of having alternative user interfaces on Jupyter Hub.
<a href="https://github.com/nuest">Daniel</a> from the <a href="https://o2r.info">o2r</a> project at the <a href="https://www.uni-muenster.de/Geoinformatics/">Institute for Geoinformatics</a>, Germany, works on reproducible computations in the geosciences and had a keen interest in learning more about the Binder platform.
They were joined remotely by <a href="https://github.com/nokome">Nokome</a>, the initiator and one of the developers of Stencila.</p>

<h4 id="the-building-blocks">The building blocks</h4>

<p><strong>Stencila Desktop</strong> is an <a href="https://elifesciences.org/labs/c496b8bb/stencila-an-office-suite-for-reproducible-research">office suite for reproducible research documents</a>.
It allows scientists to use languages like R and Python within familiar and intuitive word processor and spreadsheet user interfaces.
By doing so, it aims to lower the barriers to reproducible research for those with little or no software development skills. 
At the same time, Stencila aims to make it easy for researchers versed in software development to collaborate with their colleagues without having to switch from R or Python.
Stencila Desktop is built upon <a href="https://github.com/substance/texture/">Texture</a>, an editor for scientific content, which uses the <a href="https://github.com/substance/dar">Dar</a> file format. Dar is an extension of the JATS publishing format which has been designed for <a href="https://elifesciences.org/labs/7dbeb390/reproducible-document-stack-supporting-the-next-generation-research-article">reproducible research publications</a>. It aims to serve researchers using computational methods for data, and publishers using digital workflows for publication and preservation of scholarly journals.</p>

<p><strong>Binder</strong> makes it simple to generate reproducible computing environments from code repositories.
The online service <a href="https://mybinder.org/">mybinder.org</a> is the most prominent example for a platform based on the Binder project, a part of <a href="https://jupyter.org/">Project Jupyter</a>.
A user can run a <a href="https://en.wikipedia.org/wiki/Project_Jupyter#Jupyter_Notebook">Jupyter Notebook</a> and other environments for their research projects, which are published in online repositories (e.g. GitHub or GitLab, see <a href="https://github.com/binder-examples/">binder examples</a>).
In the <a href="https://en.wikipedia.org/wiki/Unix_philosophy">spirit of the Unix philosophy</a>, Binder combines several Open Source tools to achieve this goal: <a href="https://repo2docker.readthedocs.io/">repo2docker</a>, for generating <code class="highlighter-rouge">Dockerfile</code>s and building Docker images from software projects, <a href="https://z2jh.jupyter.org/">JupyterHub</a> for executing a Docker image and user-facing web portal in a cloud environment, and <a href="https://binderhub.readthedocs.org/">BinderHub</a> for gluing the above together.</p>

<p>A <strong><code class="highlighter-rouge">Dockerfile</code></strong> is a human- and machine-readable recipe for setting up a computational environment, which is just fancy words for saying ‚Äúinstalling and configuring software‚Äù.
<code class="highlighter-rouge">Dockerfile</code>s are used by the popular <a href="https://en.wikipedia.org/wiki/Docker_(software)">Docker</a> container software.
They can be built into an executable image, which is portable between host computers.
These properties make containers <a href="https://duckduckgo.com/?q=docker+reproducible+research">very interesting</a> for capturing and sharing research involving data and software.</p>

<p>While containers have become a commodity for developers, researchers still struggle to grasp and control the complexity of computational environments.
This is where the two building blocks join:
<strong>Running Stencila as part of a Binder helps researchers to communicate their work openly, to collaborate effectively with other scientists, and to ensure a high quality and transparency of their workflow and findings.</strong></p>

<h4 id="the-challenge">The challenge</h4>

<p>As Min and Daniel <a href="https://docs.google.com/document/d/1WPMY-Al7WMdjlepKvvLiIxFrQPHFbADMNuwszs8xMHk/edit">formulated their goals in the sprint project form</a>, the project was heavy with software titles:</p>

<p><em>‚ÄúCompatibility between Jupyter Notebooks / Binder and DAR / Texture / Stencila</em></p>

<p>Their goal was <em>‚Äú[..] to connect them so that users can edit reproducible documents (DAR files) as part of a Binder project‚Äù</em> with the following objectives: (i) understanding DAR [Dar Format], (ii) launching Stencila Editor on Binder (potentially not launching anything else, i.e. w/o the Jupyter Notebook start page), and (iii) repo2docker support for DAR files.
The project was also part of the <a href="https://mozilla.github.io/global-sprint/">Mozilla Global Sprint 2018</a>, see <a href="https://github.com/mozilla/global-sprint/issues/317">mozilla/global-sprint#317</a>.</p>

<h4 id="the-solution">The solution</h4>

<p>It took more than just the 1.5 days in Cambridge to really fulfil this challenge.
First we describe the crucial breakthroughs that were actually made at the sprint, then the updates that happened until today.</p>

<h5 id="sprint-breakthrough">Sprint breakthrough</h5>

<p>Min and Daniel started by taking a close look at an existing solution, namely the integration of RStudio based on <a href="https://github.com/jupyterhub/nbrsessionproxy"><code class="highlighter-rouge">nbrsessionproxy</code></a>, i.e. the ‚ÄúNotebook R session proxy‚Äù.
They learned two things:</p>

<ol>
  <li>a Jupyter notebook extension can be used to add a menu item to the Jupyter UI</li>
  <li>a component is needed to route the traffic between the browser-based user interface and the server-side software</li>
</ol>

<p>The first attempts utilised Binder‚Äôs feature of manually defining a bespoke <code class="highlighter-rouge">Dockerfile</code> (see <a href="https://github.com/minrk/nbstencilaproxy/commit/535900a934685bcfaf940956ba2571dddbb19009">a first attempt</a>) and later also a <a href="https://repo2docker.readthedocs.io/en/latest/config_files.html#postbuild-run-code-after-installing-the-environment"><code class="highlighter-rouge">postBuild</code> script</a> to install and configure all software.
It was Daniel‚Äôs first task to transfer the first finding for Stencila.
After setting up a local development environment and learning Jupyter/Binder, it just needed small adjustments to selected files from <code class="highlighter-rouge">nbrsessionproxy</code> to achieve this (see <a href="https://github.com/minrk/nbstencilaproxy/commit/8e8f3676cd6b4616c4b5cd1bca7a40c6fe399613">commit</a> from the second day):</p>

<p><a href="https://github.com/mozilla/global-sprint/issues/317#issuecomment-388363617"><img src="/public/images/2018-11_nbstencilaproxy-screenshot-button.png" alt="" /></a></p>

<p>Min took on the second task while at the same time figuring out what parts of Stencila we really needed, and how to glue them together.
He wrote a hard-wired proxy using <a href="https://github.com/minrk/nbstencilaproxy/commit/af8749b96188d0caada80cc3c35fdae9c53de613">Python</a> and added some <a href="https://github.com/minrk/nbstencilaproxy/commit/0bcbf63a6f47b5f67aace7f15d7bce89c9eff6d3">JavaScript/HTML files</a> to serve Dar files and the Stencila UI itself.</p>

<h4 id="connecting-stencila-to-jupyter-kernels">Connecting Stencila to Jupyter kernels</h4>

<p>Stencila has ‚Äúexecution contexts‚Äù (the equivalent of Jupyter‚Äôs ‚Äúkernels‚Äù) for R, Python, SQL, Javascript (in the browser), and Node.js. Execution contexts differ from kernels in a number of ways including code dependency analysis and returning execution results as data values. Both of these are necessary for the reactive, functional execution model of Stencila.</p>

<p>We could install these execution contexts in the Docker image.
However, Stencila also has a <code class="highlighter-rouge">JupyterContext</code> which acts as a bridge between Stencila‚Äôs API and Jupyter kernels.
So, since the base <code class="highlighter-rouge">jupyter/minimal-notebook</code> image already has a Jupyter kernel for Python installed, we decided to use that.
This did mean however, that some of the reactive aspects of the Stencila UI won‚Äôt work as expected.</p>

<p>We included the <a href="https://www.npmjs.com/package/stencila-node"><code class="highlighter-rouge">stencila-node</code></a> Node.js package in the Docker image which provides the <code class="highlighter-rouge">JupyterContext</code> as well as a <code class="highlighter-rouge">NodeContext</code> (for executing Javascript) and a <code class="highlighter-rouge">SqliteContext</code> (for executing SQL) .</p>

<p>We first used Stencila‚Äôs development build to run the JavaScript app using <code class="highlighter-rouge">node make -w -s -d /our/own/dir</code>, but struggled a bit to configure the file storage, i.e. the <code class="highlighter-rouge">dar-server</code>, to use the directory we want to, and to run it in a full path configured by us instead of <code class="highlighter-rouge">make.js</code> starting the <code class="highlighter-rouge">dar-server</code> relative to <code class="highlighter-rouge">__dirname</code>.
<em>Eventually</em> we ended up implementing our own minimal JavaScript module (i.e. an <a href="(https://npmjs.com/)">npm</a> package) that run (i) the <code class="highlighter-rouge">dar-server</code> and (ii) a static file server for the app using the distribution files (i.e. the <code class="highlighter-rouge">dist</code> directory).
This gave us control of the paths and let us get rid of complex development features (e.g. <code class="highlighter-rouge">substance-bundler</code>).</p>

<p>We also made our own version of <code class="highlighter-rouge">app.js</code>, removing the virtual file storage (<code class="highlighter-rouge">vfs</code>, used to seamlessly integrate examples) and instead defaulting to a file system (<code class="highlighter-rouge">fs</code>) storage, because that is what is needed for Jupyter.
In the same line, we built or own <code class="highlighter-rouge">index.html</code> (based on <code class="highlighter-rouge">example.html</code>) to serve as the entry page.
This allowed us to directly render a single Dar document instead of a listing of examples and to use our own <code class="highlighter-rouge">app.js</code>.
Relevant path configurations comprised the local storage path <em>as well as</em> the URLs used by the client, accessing the <code class="highlighter-rouge">dar-server</code> through the <code class="highlighter-rouge">nbserverproxy</code>.</p>

<p><strong>At the end of the first day</strong>, the wiring was all there so we could open a repository and the Stencila document was shown!
But the interactive execution of code cells did not work yet :-/.</p>

<p>Thanks to an international time-zone-difference-powered ‚Äúovernight‚Äù contribution, Min and Daniel got a big surprise on Friday morning:
Nokome <a href="https://github.com/minrk/nbstencilaproxy/pull/5">added the Stencila Node.js host for Jupyter execution context support</a>, so that Python cells could be executed by connecting to the Jupyter Kernel (which of course was already there in the container).
In doing so, he returned the ‚Äúsurprise‚Äù he had <a href="https://community.stenci.la/t/stencila-in-binder/142">when learning about the project</a>.
The added ‚Äúhost‚Äù provides the single gateway for code cell contents to be forwarded to the respective execution contexts.
Nokome showed everything works with the obligatory screenshot:</p>

<p><a href="https://github.com/minrk/nbstencilaproxy/pull/5"><img src="/public/images/2018-11_nbstencilaproxy-screenshot-pr5.png" alt="" /></a></p>

<p>Since you can run any commit in a Binder, you can also try out that particular state <a href="https://github.com/minrk/nbstencilaproxy/tree/d0df78cb4c37b53fd90088db8e36531a813898c1">from the repository</a> yourself:</p>

<p><a href="https://mybinder.org/v2/gh/minrk/nbstencilaproxy/d0df78cb4c37b53fd90088db8e36531a813898c1?urlpath=%2Fstencila%2F"><img src="https://mybinder.org/badge_logo.svg" alt="Binder" /></a></p>

<p><strong>The second day of the sprint</strong> involved many iterations of improvements, including changes to <code class="highlighter-rouge">repo2docker</code>.
These updates could not simply be thrown upon mybinder.org, so Min set up a test server for the demonstrations at the sprint‚Äôs final day.
Daniel continued his work on supporting R code cells, but albeit <a href="https://github.com/stencila/r/pull/22">small contributions</a> to the Stencila codebase, he could not complete this task in time.</p>

<p>The sprint ended with <a href="https://bit.ly/sprint-time-to-shine">presentations by all projects</a>, some of which are still continuing today, for example <a href="https://appstract.pub/">Appstract</a>, <a href="http://citationgecko.com/">Citation Gecko</a>, <a href="https://www.prereview.org/">PREreview</a>, or <a href="http://sciencepublishing.online/">Octopus</a>.
The results were truly awesome, ranging from ambitious concepts, case studies, design concepts, completely new tools with great UX design, to technical demonstrators.
It‚Äôs an easy guess where on the spectrum our project can be placed‚Ä¶
You‚Äôre invited to catch a glimpse of the sprint, its results, and the people behind all of it on Twitter under the hashtag <a href="https://twitter.com/hashtag/eLifeSprint?src=hash"><code class="highlighter-rouge">#eLifeSprint</code></a> and read the <a href="https://elifesciences.org/labs/bdd4c9aa/elife-innovation-sprint-2018-project-roundup">project roundup</a>.</p>

<p>The following screencast and Binder link show the <strong>status at the end of the sprint</strong>: a Stencila document could be opened on a bespoke Binder deployment and the contained Python code could be interactively edited.
The code is re-run on the server and the figure updated.</p>

<p><img src="/public/images/2018-11_nbstencilaproxy-end-of-sprint-video.gif" alt="" />
[<a href="https://www.youtube.com/watch?v=nK27j5DA5k0">Watch video on YouTube</a>]</p>

<p><a href="https://mybinder.org/v2/gh/minrk/nbstencilaproxy/d3271fe66951f15caf30a0cd90ca9dce9f626921"><img src="https://mybinder.org/badge_logo.svg" alt="Binder" /></a></p>

<!-- <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/nK27j5DA5k0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->

<p>You can view the Python example document by appending <code class="highlighter-rouge">?archive=py-jupyter</code> to the URL of Stencila in the Binder, e.g. <code class="highlighter-rouge">https://hub.mybinder.org/.../stencila/?archive=py-jupyter</code>.</p>

<h5 id="consolidation">Consolidation</h5>

<p>A couple of weeks after the sprint, a second less intensive development period started. Daniel continued his work on adding support for the R context, and also managed to get plain Python cells running (see pull requests <a href="https://github.com/minrk/nbstencilaproxy/pull/15">#15</a> and <a href="https://github.com/minrk/nbstencilaproxy/pull/16">#16</a>).
Min restructured the whole project and gave it the name it still bears: <code class="highlighter-rouge">nbstencilaproxy</code> - a Jupyter notebook server extension and proxy for Stencila.</p>

<p>The projects GitHub repository holds a <strong>Python module</strong> with the Jupyter notebook server and ‚Äúnon-server‚Äù extensions of the same name, and a <a href="https://github.com/minrk/nbstencilaproxy/commit/93dabbd890397aaad0d8efb316f7e1f2129e52f3">bundled</a> <strong>JavaScript module</strong> (of the same name).</p>

<p>The Python module allows proper versioned installation, dependency management, and installation from an established software repository.
It takes care of the plumbing between the user interface and the services in the background, so that the binder is viewable over one port in the browser, while the many different background components run on their own ports.
The ‚Äúno server‚Äù extension adds the ‚ÄúStencila session‚Äù menu entry and conveniently lives in the same directory structure as the server extension.</p>

<p>The JavaScript module manages the required JavaScript dependencies and provides an well-defined structure for the code files.
It serves the Dar document and provides access to the Stencila host (see above).</p>

<p>While complex at first sight, this modularity hopefully makes maintenance for future developments and new collaborators easier.
For now, the JavaScript module and its installation are bundled with the Python module instead of being published independently, because the code and configuration is very much specific to the Jupyter integration.</p>

<p>Min also extended <code class="highlighter-rouge">repo2docker</code> with <a href="https://github.com/jupyter/repo2docker/pull/309/commits/eaa29ef3343442419df8cdd022f3e91ae9262926">automatic detection of Dar documents</a> (as part of a ‚Äúbuild pack‚Äù), so that no configuration is required for most common use cases.
As with most Binder repositories, a user could simply open a Dar document on Binder and trust the required environment to provide all required software.</p>

<p>On July 20th the <code class="highlighter-rouge">nbstencilaproxy</code> <a href="https://pypi.org/project/nbstencilaproxy/#history">was published on PyPI</a> and on August 1st, the new developments <a href="https://github.com/jupyter/repo2docker/pull/309">made it into <code class="highlighter-rouge">repo2docker</code></a>.
Soon after Stencila was available for all users on mybinder.org, which was a great achievement for a little project started at a community sprint.
However, the big announcement was still not made, since some things were still hard-wired and, for example, to use R, the author of a repository <a href="https://repo2docker.readthedocs.io/en/latest/config_files.html">had to manually add a configuration file</a> although the information that R is needed is already part of the Stencila document.</p>

<h5 id="the-last-mile">The last mile</h5>

<p>In October, Daniel took on the final tasks of writing this blog post and fixing the R installation, including the automatic detection of the required execution contexts of a given Dar document.
This included some <a href="https://github.com/minrk/nbstencilaproxy/pull/18">housekeeping</a> in <code class="highlighter-rouge">nbstencilaproxy</code> and more importantly new <a href="https://github.com/jupyter/repo2docker/pull/457">contributions to <code class="highlighter-rouge">repo2docker</code></a> (thanks to <a href="https://github.com/betatim">Tim</a> for review and help) to (i) properly detect the languages used in a Stencila document, (ii) extend the R build pack to install R if it is used in a Stencila document, and (iii) add documentation and tests.
<code class="highlighter-rouge">repo2docker</code> now detects Dar documents based on their <code class="highlighter-rouge">manifest.xml</code> files and uses the location of the first discovered one as the base directory to start Stencila.
If a Dar manifest is found, then <code class="highlighter-rouge">nbstencilaproxy</code> is installed and the languages are extracted from code cells from the document.
Authors can install extra dependencies using the <a href="https://repo2docker.readthedocs.io/en/latest/config_files.html">repo2docker‚Äôs existing mechanisms</a>.</p>

<p>Daniel also created a few <strong>example repositories</strong> to provide a starting point for users.
Thankfully the binder team generously welcomed <a href="">the changes to mybinder.org</a> and and the examples to the <a href="https://github.com/binder-examples/">binder examples organisation</a> on GitHub.
The following repositories contain single or multiple Stencila documents with code chunks in different programming languages.</p>

<p><strong><a href="https://github.com/binder-examples/stencila-py">https://github.com/binder-examples/stencila-py</a></strong> contains Python code cells, using both the Jupyter and plain Python execution contexts:</p>

<p><a href="https://mybinder.org/v2/gh/binder-examples/stencila-py/master?urlpath=stencila"><img src="https://mybinder.org/badge_logo.svg" alt="Binder" /></a></p>

<p><img src="/public/images/2018-11_nbstencilaproxy-example-stencila-py.png" alt="Binder + Stencila screenshot: Python" /></p>

<p><strong><a href="https://github.com/binder-examples/stencila-r">https://github.com/binder-examples/stencila-r</a></strong> contains R code cells and two plots:</p>

<p><a href="https://mybinder.org/v2/gh/binder-examples/stencila-r/master?urlpath=stencila"><img src="https://mybinder.org/badge_logo.svg" alt="Binder" /></a></p>

<p><img src="/public/images/2018-11_nbstencilaproxy-example-stencila-r.png" alt="Binder + Stencila screenshot: R" /></p>

<p><strong><a href="https://github.com/binder-examples/stencila-multi">https://github.com/binder-examples/stencila-multi</a></strong> demonstrates how to access specific Dar projects if multiple are found within a repository.</p>

<p><a href="https://mybinder.org/v2/gh/binder-examples/stencila-multi/master?urlpath=stencila"><img src="https://mybinder.org/badge_logo.svg" alt="Binder" /></a></p>

<p>In each case you can see the available execution environments by clicking on the icon in the bottom right corner.</p>

<p>One of the cool features of Stencila are the reactive cells, as demonstrated in a tweet following the feature release:</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">Thanks to <a href="https://twitter.com/nordholmen?ref_src=twsrc%5Etfw">@nordholmen</a> working on <a href="https://twitter.com/stencila?ref_src=twsrc%5Etfw">@stencila</a> support for <a href="https://t.co/Zlj6FrYgBw">https://t.co/Zlj6FrYgBw</a> you now have reactive cells with Python code on <a href="https://twitter.com/mybinderteam?ref_src=twsrc%5Etfw">@mybinderteam</a>! Give it a go <a href="https://t.co/ToIuQPq0Fy">https://t.co/ToIuQPq0Fy</a> <a href="https://t.co/Wjyf1kiH9B">pic.twitter.com/Wjyf1kiH9B</a></p>&mdash; Tim Head (@betatim) <a href="https://twitter.com/betatim/status/1062004432806785024?ref_src=twsrc%5Etfw">12. November 2018</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<h4 id="summary-and-outlook">Summary and outlook</h4>

<p><em>Thanks for reading so far!</em>
This blog post is a <a href="https://github.com/minrk/nbstencilaproxy/issues/12">long planned</a> write-up of the history of the tool and decisions mostly relevant to developers, but also an demonstration of the power that the Open Source and Open Science community can foster.
Many people are working together on the (technological) challenges of science today towards full research transparency and reproducibility, even if we use computers to an unprecedented level.
Many small contributions on ‚Äúside projects‚Äù such as these can make a difference, and connecting these two great projects hopefully helps to solve some problem in science down the road.</p>

<p><em>What‚Äôs next?</em>
While there are no concrete plans, there are of course some ideas listed on the <a href="https://github.com/minrk/nbstencilaproxy/issues/">project‚Äôs issue tracker</a>, such as an automatic Jupyter notebook to Dar conversion when there is no Dar archive in a repository.
In any case you can keep an eye out on GitHub for projects being <a href="https://github.com/search?q=topic%3Abinder+topic%3Astencila+org&amp;type=Repositories">tagged <code class="highlighter-rouge">stencila</code> and <code class="highlighter-rouge">binder</code></a> and join the public <a href="https://gitter.im/stencila/stencila">Stencila</a> and <a href="https://gitter.im/jupyterhub/binder">binder</a> chats to stay in touch or get help.
We look forward to see scientists using <code class="highlighter-rouge">nbstencilaproxy</code> for communicating their work and new challenges that come with it.</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr"><a href="https://twitter.com/hashtag/eLifeSprint?src=hash&amp;ref_src=twsrc%5Etfw">#eLifeSprint</a>-ers <a href="https://twitter.com/minrk?ref_src=twsrc%5Etfw">@minrk</a> and <a href="https://twitter.com/nordholmen?ref_src=twsrc%5Etfw">@nordholmen</a> are working to connect <a href="https://twitter.com/hashtag/JupyterNotebooks?src=hash&amp;ref_src=twsrc%5Etfw">#JupyterNotebooks</a> / <a href="https://twitter.com/hashtag/Binder?src=hash&amp;ref_src=twsrc%5Etfw">#Binder</a> with DAR / <a href="https://twitter.com/hashtag/Texture?src=hash&amp;ref_src=twsrc%5Etfw">#Texture</a> / <a href="https://twitter.com/stencila?ref_src=twsrc%5Etfw">@Stencila</a>, so that users can edit reproducible documents as part of a Binder project <a href="https://t.co/2GoGNydsmX">https://t.co/2GoGNydsmX</a> (<a href="https://twitter.com/mybinderteam?ref_src=twsrc%5Etfw">@mybinderteam</a> <a href="https://twitter.com/ProjectJupyter?ref_src=twsrc%5Etfw">@ProjectJupyter</a> <a href="https://twitter.com/_substance?ref_src=twsrc%5Etfw">@_substance</a>) <a href="https://t.co/sZ8bbE9SsM">pic.twitter.com/sZ8bbE9SsM</a></p>&mdash; eLife Innovation (@eLifeInnovation) <a href="https://twitter.com/eLifeInnovation/status/994583390895697920?ref_src=twsrc%5Etfw">10. Mai 2018</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2018/08/14/demo-server-update/">Demo server update</a></h3>
<span class="post-date">14 Aug 2018 | By Daniel N√ºst</span>
<p>We‚Äôve been working on demonstrating our <a href="/results">reference-implementation</a> during spring an managed to create a number of example workspaces.
We now decided to publish these workspaces on <a href="https://o2r.uni-muenster.de/">our demo server</a>.</p>

<p><a href="https://o2r.uni-muenster.de/"><img src="/public/images/2018-08-14-demo/o2r-demo-listing.jpg" alt="o2r screenshot 1: listing of compendia" title="Screenshot 1: o2r reference implementation listing of published ERC" width="600" /></a></p>
<p class="attributionInlineImage">Screenshot 1: o2r reference implementation <em>listing of published Executable Research Compendia</em>. The right-hand side shows a metadata summary including original authors.</p>

<p>The papers were originally published in <!--more--> <a href="https://www.jstatsoft.org/">Journal of Statistical Software</a> or in a <a href="https://publications.copernicus.org/">Copernicus Publications</a> journal under open licenses.
We have created an R Markdown document for each paper based on the included data and code following the <a href="https://o2r.info/erc-spec/spec/">ERC specification</a> for naming core files, but only included data, an R Markdown document and a HTML display file.
The publication metadata, the runtime environment description (i.e. a <code class="highlighter-rouge">Dockerfile</code>), and the runtime image (i.e. a Docker image tarball) were all created during the ERC creation process without any human interaction (see the used <a href="https://github.com/o2r-project/erc-examples/blob/master/corpus/showcases.Rmd">R code for upload</a>), since required metadata were included in the R Markdown document‚Äôs front matter.</p>

<p>The documents include selected figures or in some cases the whole paper, if runtime is not extremely long.
While the paper‚Äôs authors are correctly linked in the workspace metadata (see right hand side in <em>Screenshot 1</em>), the ‚Äúo2r author‚Äù of all papers is o2r team member Daniel since he made the uploads.
You can find all publications on his author page (this is the link you definitely want to try out!):</p>

<p>‚ùó <strong><a href="https://o2r.uni-muenster.de/#!/author/0000-0002-0024-5046">https://o2r.uni-muenster.de/#!/author/0000-0002-0024-5046</a></strong> ‚ùó</p>

<p><img src="/public/images/2018-08-14-demo/o2r-demo-compendium.jpg" alt="o2r screenshot 2: example compendium view" title="Screenshot 2: o2r reference implementation display of a single ERC" width="600" /></p>
<p class="attributionInlineImage">Screenshot 2: o2r reference implementation <em>ERC detail page</em> for compendium [SLVlQ](https://o2r.uni-muenster.de/#!/erc/5LVlQ). The link "Article" in the top left corner leads to the original article, the "magnifying glass" button takes you to a core feature: the reproduction result.</p>

<p>You can get to the original publication by clicking the ‚ÄúArticle‚Äù button in the top left corner (see <em>Screenshot 2</em>).
The workspaces demonstrate a variety of issues and are a great source for future work on architecture and implementation.
Here are some examples of the power of a reproducible research service and publishing platform:</p>

<ul>
  <li>The <a href="https://o2r.uni-muenster.de/#!/erc/N4Jzp">ERC for ‚ÄúTidy Data‚Äù by Hadley Wickham</a> completes the reproduction successfully, so no differences between the uploaded and reproduced HTML file were found! You can even download the image tarball (just bear with our demo - not production - server it it takes some time).</li>
  <li>The <a href="https://o2r.uni-muenster.de/#!/erc/Z4Hci">ERC for ‚ÄúA question driven socio-hydrological modeling process‚Äù by Garcia et al.</a> ‚Äúfails‚Äù due to differences in the created figure. A human can now judge if these differences are minor, or the author can try to tweak rendering parameters to fix this. <bf></bf><img src="/public/images/2018-08-14-demo/o2r-demo-imagediff.jpg" alt="o2r screenshot 3: image difference example" title="Screenshot 3: image difference example of &quot;failed&quot; replication" width="400" /></li>
  <li>A <a href="https://o2r.uni-muenster.de/#!/erc/IKnWD">demo ERC with randomised output</a> shows how things can really go wrong. Feel free to click ‚ÄúRun Analysis‚Äù and see how the differences changes with each execution.</li>
</ul>

<p>If you want to go through the creation process yourself, register on the platform (this requires a short manual interaction by us) and upload one of selected workspaces, which you can find in our public demo share at <a href="https://uni-muenster.sciebo.de/s/G8vxQ1h50V4HpuA">https://uni-muenster.sciebo.de/s/G8vxQ1h50V4HpuA</a> (just look for zip files starting with <code class="highlighter-rouge">corpus_..</code>).
Please take care to choose appropriate licenses and be aware that we might remove compendia from the demo platform without prior notice.</p>

<p>We welcome <em>your feedback</em> <a href="https://twitter.com/o2r_project/status/1029293814756851712">on Twitter</a>, in the <a href="https://github.com/o2r-project/reference-implementation/issues/13">reference implementation GitHub project</a>, or in the comments below.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2018/07/13/peerj-article-published/">New article published in PeerJ</a></h3>
<span class="post-date">13 Jul 2018 | By Daniel N√ºst</span>
<p>Today a new journal article lead by o2r team member <a href="https://nordholmen.net/">Daniel</a> was published in the journal <a href="https://peerj.com/">PeerJ</a>:</p>

<p><img src="https://img.shields.io/badge/article-peer--reviewed-brightgreen.svg" alt="publication badge" class="publicationBadge" /><strong><a href="https://doi.org/10.7717/peerj.5072" title="CRIS entry of publication">Reproducible research and GIScience: an evaluation using AGILE conference papers</a></strong> by <i><a href="https://orcid.org/0000-0002-0024-5046">Daniel N√ºst</a>, <a href="https://orcid.org/0000-0003-1004-9695">Carlos Granell</a>, <a href="https://orcid.org/0000-0001-7078-3766">Barbara Hofer</a>, <a href="https://orcid.org/0000-0001-6651-0976">Markus Konkol</a>, <a href="https://orcid.org/0000-0002-9317-8291">Frank O. Ostermann</a>, <a href="https://orcid.org/0000-0002-8245-3016">Rusne Sileryte</a>, <a href="https://orcid.org/0000-0002-9612-1581">Valentina Cerutti</a></i>
<br />
<i class="editor">PeerJ. 2018.</i><strong>doi:¬†<a href="https://doi.org/10.7717/peerj.5072">10.7717/peerj.5072</a></strong></p>

<p>The article is an outcome of a collaboration around the AGILE conference, see <a href="https://o2r.info/reproducible-agile/">https://o2r.info/reproducible-agile/</a> for more information.
Please <a href="https://twitter.com/f_ostermann/status/1017673264334766080">retweet</a> and spread the word!
<a href="https://peerj.com/articles/5072/#questions">Your questions &amp; feedback</a> are most welcome.</p>

<p>Here is Daniel‚Äôs attempt at a <strong><a href="https://twitter.com/Protohedgehog/status/949315968903376896">non-specialist summary</a></strong>:</p>

<blockquote>
  <p>More and more research use data and algorithms to answer a question.
That makes it harder for researchers to understand a scientific publication, because you need more than just the text to understand what is really going on.
You need the software and the data to be able to tell if everything is done correctly, and to be able to re-use new and exciting methods.
We took a look at the existing guides for such research and created our own criteria for research in sciences using environmental observations and maps.
We used the criteria to test how reproducible a set of papers from the AGILE conference actually are.
The conference is quite established and the papers are of high quality because they were all suggested for the ‚Äúbest paper‚Äù awards at the conference.</p>

  <p>The results are quite bad!
We could not re-create any of the analyses.
Then we asked the authors of the papers we evaluated if they had considered that someone else might want to re-do their work.
While they all think the idea is great, many said they do not have the time for it.</p>

  <p>The only way for researchers to have the time and resources to work in a way that is transparent to others and reusable openly is either to convince them of the importance or to force them.
We came up with a list of suggestions to publishers and scientific conference organisers to create enough reasons for researchers to publish science in a re-creatable way.</p>
</blockquote>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2018/06/21/agile-2018-pre-conference-workshop-report/">AGILE 2018 pre-conference workshop report</a></h3>
<span class="post-date">21 Jun 2018 | By Daniel N√ºst</span>
<p>Last week o2r team member <a href="https://nordholmen.net/">Daniel</a> co-organised a workshop at the <a href="http://agile-online.org/index.php/conference/conference-2018">21st AGILE International Conference on Geographic Information Science</a> in Lund, Sweden.
The workshop went very well and Daniel together with his colleagues was able to spread the word about reproducible research and Open Science.
They are pretty sure they convinced some new scientists to reconsider their habits!</p>

<p>Daniel wrote a short report about the workshop: <strong><a href="https://o2r.info/reproducible-agile/2018/#workshop-report">https://o2r.info/reproducible-agile/2018/#workshop-report</a></strong></p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">We are ready for the 2nd workshop on <a href="https://twitter.com/hashtag/reproducibility?src=hash&amp;ref_src=twsrc%5Etfw">#reproducibility</a> <a href="https://twitter.com/hashtag/reproducibleresearch?src=hash&amp;ref_src=twsrc%5Etfw">#reproducibleresearch</a> at AGILE conference in Lund <a href="https://twitter.com/hashtag/agileconf2018?src=hash&amp;ref_src=twsrc%5Etfw">#agileconf2018</a> <a href="https://t.co/bbBok1SnRm">pic.twitter.com/bbBok1SnRm</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/1006512760220418049?ref_src=twsrc%5Etfw">12. Juni 2018</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>The workshop series will probably be continued at the next AGILE conference in Limassol, Cyprus.
For o2r participating in such a workshop is a great way to stay in touch with users of reproducibility tools and practices, and to give back to the communities not only with technology but with education.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2018/04/18/report-from-egu2018/">Report from EGU 2018</a></h3>
<span class="post-date">18 Apr 2018 | By Daniel N√ºst</span>
<p>Last week <a href="http://egu2018.eu/">EGU General Assembly (GA) 2018</a> took place in Vienna, Austria, and it was packed with interesting sessions and inspiring presentations.
The o2r team humbly tried to contribute to a massive conference: 15075 participants from <a href="https://egu2018.eu/#CountryStatistics">106</a> countries gave 17323 presentations in 666 sessions (it‚Äôs been reported the programme committee briefly discussed adding a session‚Ä¶), taught 68 short courses, and collaborated in 294 side events.
Let‚Äôs go through the events with o2r participation in chronological order.</p>

<p><img src="/public/images/egu2018-banner.png" alt="EGU 2018 conference banner" width="100%" /></p>
<p class="attributionInlineImage">Image courtesy of EGU website.</p>

<p>On <em>Monday</em>, <a href="https://orcid.org/0000-0002-0024-5046">Daniel</a> joined the first ever<!--more--> <strong><a href="http://eartharxiv.org/">EarthArXiv</a> <a href="https://meetingorganizer.copernicus.org/EGU2018/session/29063">townhall meeting</a></strong>.
He was happy to share <a href="https://www.generosity.com/community-fundraising/ten-thousand-eartharxiv-preprint-service-stickers">his stickers</a> with a small but engaged crowd and experienced an open-minded discussion about the young community-led EarthArXiv (already over 300 pre- and postprints after a little over 6 months), preprints, postprints, and the bigger picture of Open Access in the context of the two large conferences in the geosciences, EGU GA and the <a href="https://fallmeeting.agu.org">AGU Fall Meeting</a>. AGU‚Äôs cooperation with <a href="https://www.essoar.org/">ESSOAr</a> on abstracts and poster publications was presented at the meeting by <a href="https://orcid.org/0000-0001-6230-7145">Brooks Hanson</a>.
The event went really well and it was fun to meet fellow Open Science enthusiasts <a href="https://ethz.academia.edu/FriedrichHawemann">Friedrich Hawemann</a> and <a href="https://about.me/geo.fernandez-blanco">David Fernandez-Blanco</a> (the mastermind behind the gif-loaden entertaining tweets by <a href="https://twitter.com/EarthArXiv">@EarthArXiv</a>).</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">Friedrich Hawemann making the case for preprints at the <a href="https://twitter.com/EarthArXiv?ref_src=twsrc%5Etfw">@EarthArXiv</a> Townhall at <a href="https://twitter.com/hashtag/EGU18?src=hash&amp;ref_src=twsrc%5Etfw">#EGU18</a> <a href="https://twitter.com/hashtag/preprint?src=hash&amp;ref_src=twsrc%5Etfw">#preprint</a> <a href="https://twitter.com/hashtag/postprint?src=hash&amp;ref_src=twsrc%5Etfw">#postprint</a> <a href="https://twitter.com/hashtag/openaccess?src=hash&amp;ref_src=twsrc%5Etfw">#openaccess</a> <a href="https://t.co/TgfoPSVksD">pic.twitter.com/TgfoPSVksD</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/983392981834182657?ref_src=twsrc%5Etfw">9. April 2018</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>On <em>Tuesday</em> the evening events continued with the always enjoyable <strong><a href="http://osgeo.org/">OSGeo</a> <a href="https://meetingorganizer.copernicus.org/EGU2018/session/29320">townhall meeting</a></strong>.
Its theme was ‚ÄúOpen Science demystified‚Äù and organiser <a href="http://www.drloewe.eu/">Peter L√∂we</a> nicely connected the spirit and goals of an Open Source organisation with Open Science.
As usual, it did not take long until newcomers could be helped with concrete advise on software, development, and transformation to <a href="https://en.wikipedia.org/wiki/Foss">FOSS</a> for organisations by the attending mix of FOSS users, developers, contributors, and old-timers.</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">It&#39;s that time of year again: <a href="https://twitter.com/OSGeo?ref_src=twsrc%5Etfw">@OSGeo</a>  townhall meeting at <a href="https://twitter.com/hashtag/EGU18?src=hash&amp;ref_src=twsrc%5Etfw">#EGU18</a> <a href="https://twitter.com/EuroGeosciences?ref_src=twsrc%5Etfw">@EuroGeosciences</a><a href="https://twitter.com/drpeterloewe?ref_src=twsrc%5Etfw">@drpeterloewe</a> continous his tremendous outreach activity (4th time convening?) and connects <a href="https://twitter.com/hashtag/OpenScience?src=hash&amp;ref_src=twsrc%5Etfw">#OpenScience</a> with <a href="https://twitter.com/hashtag/OpenSource?src=hash&amp;ref_src=twsrc%5Etfw">#OpenSource</a> - OSGeo is not limited to the latter! <a href="https://t.co/UuFe0fAdxZ">pic.twitter.com/UuFe0fAdxZ</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/983753702803673089?ref_src=twsrc%5Etfw">10. April 2018</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>On <em>Wednesday</em> Daniel had to shift his attention to the early morning.
In the PICO session <a href="https://meetingorganizer.copernicus.org/EGU2018/session/27584">IE4.4</a>, <strong>‚ÄúR and the benefit of low-cost solutions - democratic participation to face challenges in Earth science‚Äù</strong>, he demonstrated the usefulness of <a href="https://www.rocker-project.org/images/"><code class="highlighter-rouge">rocker/geospatial</code></a> for science with a number of showcases in a PICO presentation slot packed with exciting projects and software presentation.</p>

<ul>
  <li>Abstract: <a href="https://meetingorganizer.copernicus.org/EGU2018/EGU2018-8500-1.pdf">https://meetingorganizer.copernicus.org/EGU2018/EGU2018-8500-1.pdf</a></li>
  <li>Slides: <a href="https://doi.org/10.5281/zenodo.1217911">https://doi.org/10.5281/zenodo.1217911</a></li>
  <li>Thanks: <a href="https://twitter.com/nordholmen/status/983730200373612544">showcase authors</a></li>
</ul>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">PICO uploaded! Don&#39;t get to bed too late today or you&#39;ll miss &quot;rocker/geospatial: a flexible runtime environment for geoscientific data analysis&quot; at <a href="https://twitter.com/hashtag/EGU18?src=hash&amp;ref_src=twsrc%5Etfw">#EGU18</a> - PICO spot 4 tomorrow at 08:30 hrs. I showcase the community work headed by <a href="https://twitter.com/cboettig?ref_src=twsrc%5Etfw">@cboettig</a> &amp; <a href="https://twitter.com/eddelbuettel?ref_src=twsrc%5Etfw">@eddelbuettel</a> for R in <a href="https://twitter.com/Docker?ref_src=twsrc%5Etfw">@Docker</a> <a href="https://t.co/F8KK453fFx">pic.twitter.com/F8KK453fFx</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/983712891755991040?ref_src=twsrc%5Etfw">10. April 2018</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>In the same session, <a href="http://orcid.org/0000-0001-8049-7069">Edzer</a> presented ‚ÄúR vector and raster data cubes for openEO‚Äù, his latest work to continue the evolution for spatial data handling in R and connecting it to <a href="http://openeo.org/">openEO</a>.
Both o2r team members could welcome many interested scientists at their PICO screens and had to stay until the very end answering questions and discussing the depths of the respective implementations.</p>

<ul>
  <li>Abstract: <a href="https://meetingorganizer.copernicus.org/EGU2018/EGU2018-8198.pdf">https://meetingorganizer.copernicus.org/EGU2018/EGU2018-8198.pdf</a></li>
  <li><code class="highlighter-rouge">stars</code> R package: <a href="https://r-spatial.github.io/stars/">https://r-spatial.github.io/stars/</a></li>
</ul>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">Steadily growing crowd gathering at <a href="https://twitter.com/hashtag/EGU18?src=hash&amp;ref_src=twsrc%5Etfw">#EGU18</a> session on <a href="https://twitter.com/hashtag/R?src=hash&amp;ref_src=twsrc%5Etfw">#R</a> and the benefit if low-cost solutions - democratic participation to face challenges in Earth sciences <a href="https://twitter.com/hashtag/rstats?src=hash&amp;ref_src=twsrc%5Etfw">#rstats</a> <a href="https://twitter.com/hashtag/PICO?src=hash&amp;ref_src=twsrc%5Etfw">#PICO</a> <a href="https://twitter.com/EuroGeosciences?ref_src=twsrc%5Etfw">@EuroGeosciences</a> <a href="https://twitter.com/hashtag/rspatial?src=hash&amp;ref_src=twsrc%5Etfw">#rspatial</a> <a href="https://t.co/MdgpJLnu4y">pic.twitter.com/MdgpJLnu4y</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/983957403581415424?ref_src=twsrc%5Etfw">11. April 2018</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>On <em>Thursday afternoon</em> Daniel was joined by <a href="https://orcid.org/0000-0001-6651-0976">Markus</a> and good friends of o2r from New York, <a href="https://vickysteeves.com/">Vicky</a> and <a href="http://remirampin.com/">Remi</a> from <a href="https://datascience.nyu.edu/">NYU Center for Data Science</a> and <a href="http://reprozip.org/">ReproZip</a>, to <a href="/2017/05/03/egu-short-course-recap/">continue the collaboration</a> on teaching tools for Open Science and Reproducible Research at EGU.
They welcomed a large audience (70+ people) to the <a href="http://meetingorganizer.copernicus.org/EGU2018/session/28650">short course</a> <strong>‚ÄúWriting reproducible geoscience papers using R Markdown, Docker, and GitLab‚Äù</strong>.
The course was hands-on, so participants worked with their own laptops.
Hopefully most of them arrived safely home with a working research environment for <a href="http://r-project.org/">R</a> and <a href="http://git-scm.com/">git</a>.
The course‚Äôs contents and speed are adjusted to accommodate the diverse previous knowledge from a multidisciplinary conference such as EGU.
Inspired by the great <a href="https://carpentries.org/">Carpentry courses</a>, but considerably shorter and more dense, all conveners/teachers were active at the same time to lead through the instructions and help fixing the many little issues during software installations.
We tried hard to leave no one hanging behind and albeit being confronted with an estimated number of 6 operating systems the <a href="https://www.rstudio.com/products/RStudio/">RStudio</a>-based instructions stood their ground excellently and we are glad to have received numerous positive feedbacks from participants.</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">Almost 70 people at our <a href="https://twitter.com/hashtag/egu18repro?src=hash&amp;ref_src=twsrc%5Etfw">#egu18repro</a> <a href="https://twitter.com/hashtag/egu18?src=hash&amp;ref_src=twsrc%5Etfw">#egu18</a> session!! So many folks eager to learn about best practices for reproducible research in geoscience! <a href="https://t.co/XSxc0s53uk">https://t.co/XSxc0s53uk</a></p>&mdash; Vicky Steeves (joinmastodon.org) (@VickySteeves) <a href="https://twitter.com/VickySteeves/status/984422094095208448?ref_src=twsrc%5Etfw">12. April 2018</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>The <em>course material</em> is available openly online at <a href="https://vickysteeves.gitlab.io/repro-papers/"><strong>https://vickysteeves.gitlab.io/repro-papers/</strong></a> and if you could not be there, be sure to try and check out the Twitter hashtag <a href="https://twitter.com/hashtag/egu18repro?src=hash"><strong>#egu18repro</strong></a> for some impressions.
The course is roughly split in two sessions √† 90 minutes:</p>

<ul>
  <li>Introduction to Open Science, using git and GitLab</li>
  <li>R Markdown for reproducible papers and rendering of R Markdown manuscripts with GitLab CI</li>
</ul>

<p>We sincerely thank the attendees for the useful questions and the positive atmosphere at the course!
People were helping each other and showed patience when little breaks had to be taken to solve individual issues.
We welcome comments, ideas and suggestions in the <a href="https://gitlab.com/VickySteeves/repro-papers">GitLab repository of the course</a>.
We hope it‚Äôs not the last time we can use the material ourselves but also invite everybody to use it.
It contains numerous links to more detailed courses and we thank the R and Open Science communities for the breadth of existing tutorials and the inspiration they provide.</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">Our short course on writing reproducible geoscience papers is DONE! <a href="https://twitter.com/hashtag/egu18repro?src=hash&amp;ref_src=twsrc%5Etfw">#egu18repro</a> <a href="https://twitter.com/hashtag/EGU18?src=hash&amp;ref_src=twsrc%5Etfw">#EGU18</a> <a href="https://t.co/V3vwojpk11">pic.twitter.com/V3vwojpk11</a></p>&mdash; Vicky Steeves (joinmastodon.org) (@VickySteeves) <a href="https://twitter.com/VickySteeves/status/984454491176136704?ref_src=twsrc%5Etfw">12. April 2018</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>The <em>evening</em> belonged to yet another townhall meeting: <strong><a href="http://meetingorganizer.copernicus.org/EGU2018/session/29539">‚ÄúResearch Software Engineers in the Geosciences‚Äù</a></strong>.
Daniel initiated this meeting to bring together researchers developing software, or software developers doing research, to get to know the existing national chapters and initiatives as well as each other.
A diverse group came together from different countries and <a href="https://www.egu.eu/structure/divisions/">scientific divisions</a> to share their experiences and to discuss how to improve the situation for RSEs in the geosciences (see <a href="http://www.de-rse.org/en/aims.html">de-RSE‚Äôs objectives</a>).
A more detailed report from the townhall will follow in due course on the <a href="http://www.de-rse.org/en/blog.html">de-RSE Blog</a>, until then see <a href="https://twitter.com/nordholmen/status/984484030031843328">Daniel‚Äôs full thread on Twitter</a>.</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">First research software engineers meeting at the EGU just started. Great to see people engaging with the role behind a crucial part of science. <a href="https://twitter.com/hashtag/rse?src=hash&amp;ref_src=twsrc%5Etfw">#rse</a> <a href="https://twitter.com/hashtag/RSEng?src=hash&amp;ref_src=twsrc%5Etfw">#RSEng</a> <a href="https://twitter.com/SoftwareSaved?ref_src=twsrc%5Etfw">@SoftwareSaved</a> <a href="https://twitter.com/RSE_de?ref_src=twsrc%5Etfw">@RSE_de</a> <a href="https://twitter.com/nordic_rse?ref_src=twsrc%5Etfw">@nordic_rse</a> <a href="https://twitter.com/nl_rse?ref_src=twsrc%5Etfw">@nl_rse</a> <a href="https://twitter.com/hashtag/EGU18?src=hash&amp;ref_src=twsrc%5Etfw">#EGU18</a> <a href="https://twitter.com/EGU_ESSI?ref_src=twsrc%5Etfw">@EGU_ESSI</a> <a href="https://t.co/Y0lDsAtaae">pic.twitter.com/Y0lDsAtaae</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/984479316699381760?ref_src=twsrc%5Etfw">12. April 2018</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>On <em>Friday</em> it was time for PICOs and posters. Daniel and Markus presented <a href="https://meetingorganizer.copernicus.org/EGU2018/EGU2018-17461.pdf">‚ÄúOpen Environmental Data Analysis‚Äù</a> and <a href="https://meetingorganizer.copernicus.org/EGU2018/EGU2018-19295-1.pdf">‚ÄúReproducible research bindings‚Äù</a> respectively in <a href="https://meetingorganizer.copernicus.org/EGU2018/session/28036">the session</a> <strong>‚ÄúOpen Data, Reproducible Research, and Open Science‚Äù</strong>.
Again we enjoyed fruitful discussions and missed out on the interesting other presentations as we were fortunate enough to be visited by interested people throughout the whole viewing time.</p>

<ul>
  <li>Daniel‚Äôs slides: <a href="https://doi.org/10.5281/zenodo.1217912"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.1217912.svg" alt="DOI" /></a></li>
</ul>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">Last day at <a href="https://twitter.com/hashtag/EGU18?src=hash&amp;ref_src=twsrc%5Etfw">#EGU18</a> and what a great week it has been so far <a href="https://twitter.com/EGU_ESSI?ref_src=twsrc%5Etfw">@EGU_ESSI</a> <a href="https://twitter.com/EuroGeosciences?ref_src=twsrc%5Etfw">@EuroGeosciences</a>. Now at PICO spot 1 in session <a href="https://twitter.com/hashtag/OpenData?src=hash&amp;ref_src=twsrc%5Etfw">#OpenData</a> <a href="https://twitter.com/hashtag/OpenScience?src=hash&amp;ref_src=twsrc%5Etfw">#OpenScience</a> and <a href="https://twitter.com/hashtag/ReproducibleResearch?src=hash&amp;ref_src=twsrc%5Etfw">#ReproducibleResearch</a> incl. presentation by <a href="https://twitter.com/thomas_barto?ref_src=twsrc%5Etfw">@thomas_barto</a> and me on open env. analysis w/ <a href="https://twitter.com/openSenseMap?ref_src=twsrc%5Etfw">@openSenseMap</a> &amp; <a href="https://twitter.com/SenseBox_De?ref_src=twsrc%5Etfw">@SenseBox_De</a> <a href="https://t.co/tRglBkhiMv">pic.twitter.com/tRglBkhiMv</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/984680761549901825?ref_src=twsrc%5Etfw">13. April 2018</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr"><a href="https://twitter.com/MarkusKonkol?ref_src=twsrc%5Etfw">@MarkusKonkol</a> presents results from <a href="https://twitter.com/o2r_project?ref_src=twsrc%5Etfw">@o2r_project</a> : reproducible research bindings, increasing research transparency and understanding. <a href="https://twitter.com/hashtag/OpenScience?src=hash&amp;ref_src=twsrc%5Etfw">#OpenScience</a> <a href="https://twitter.com/hashtag/reproducibleresearch?src=hash&amp;ref_src=twsrc%5Etfw">#reproducibleresearch</a> <a href="https://twitter.com/hashtag/EGU18?src=hash&amp;ref_src=twsrc%5Etfw">#EGU18</a> <a href="https://twitter.com/hashtag/EGU18ESSI?src=hash&amp;ref_src=twsrc%5Etfw">#EGU18ESSI</a> <a href="https://t.co/UY7PqU4sA2">pic.twitter.com/UY7PqU4sA2</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/984689770474426368?ref_src=twsrc%5Etfw">13. April 2018</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Later that morning Edzer presented a poster on ‚ÄúopenEO: an open API for cloud-based big Earth Observation processing platforms‚Äù (<a href="https://meetingorganizer.copernicus.org/EGU2018/EGU2018-8198.pdf">abstract</a>) in the session <a href="https://meetingorganizer.copernicus.org/EGU2018/session/28035">‚ÄúData cubes of Big Earth Data - a new paradigm for accessing and processing Earth Science Data‚Äù</a>.</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">Drawing a big crowd at <a href="https://twitter.com/EGU_ESSI?ref_src=twsrc%5Etfw">@EGU_ESSI</a> poster session: <a href="https://twitter.com/edzerpebesma?ref_src=twsrc%5Etfw">@edzerpebesma</a> presenting <a href="https://twitter.com/open_EO?ref_src=twsrc%5Etfw">@open_EO</a> project, an open API for Earth observation data and processing. <a href="https://twitter.com/hashtag/EGU18?src=hash&amp;ref_src=twsrc%5Etfw">#EGU18</a> <a href="https://twitter.com/hashtag/DataCubes?src=hash&amp;ref_src=twsrc%5Etfw">#DataCubes</a> <a href="https://twitter.com/hashtag/opensource?src=hash&amp;ref_src=twsrc%5Etfw">#opensource</a> <a href="https://t.co/1rDoexZgPJ">pic.twitter.com/1rDoexZgPJ</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/984725790133751808?ref_src=twsrc%5Etfw">13. April 2018</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>We are happy to thank the great people from <a href="https://meetings.copernicus.org/">Copernicus</a>, the organisers of the conference and a great supporter of Open Science as well as a <a href="/about">partner of o2r</a>, who we got to meet and catch up with.
The conference has been great and here we only scratch the surface of fun, entertaining and educational experiences where o2r team members presented or convened and lack the many times we met <a href="https://twitter.com/nordholmen/status/984768359244890117">new people and communities</a>, colleagues, and friends to talk science.</p>

<p><em>Thanks for reading!</em></p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2018/02/27/digitisation-of-science/">Digitisation of Science @ WWU</a></h3>
<span class="post-date">27 Feb 2018 | By Daniel N√ºst</span>
<p>o2r Team member <a href="htts://nordholmen.net">Daniel</a> was invited by the university‚Äôs press office to participate in a <a href="https://www.uni-muenster.de/news/index.php?mod=archive&amp;rubrik=pr-digitalisierung&amp;lang=en">series of interviews and articles on digitisation or ‚Äúdigitalisation‚Äù at the WWU M√ºnster</a>:</p>

<p>The video is now <a href="https://www.uni-muenster.de/news/view.php?cmdid=9388">available online in German</a> (embedded below) and <a href="https://www.uni-muenster.de/news/view.php?cmdid=9395">with English subtitles</a>.
You can also watch it <a href="https://www.facebook.com/wwumuenster/videos/10156084978130350/">on Facebook</a> or in the <a href="https://www.uni-muenster.de/videoportal/digitalisierung.html#nuest">WWU video portal</a>.</p>

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/07qp9xHYknY" frameborder="0" allow="encrypted-media" allowfullscreen=""></iframe>

<p>Daniel wrote a brief summary for our blog and shares his experience:</p>

<p><strong>Interview summary</strong></p>

<blockquote>
  <p>First we talked about how digitisation is a familiar topic for computer scientists professionally (digital data, algorithms), but also something we encounter as citizens.<!--more-->
Next I explained the importance of reproducibility in science and when asked if that was not the case in the past, I outlined the new challenges of a completely digital research workflow.
I summarise the idea of the o2r project and use the term <em>‚Äúdigital laboratory‚Äù</em> as a metaphor for our Executable Research Compendium, which collects all research artefacts and opens them up in a transparent way and allows collaboration.
We then briefly touch on the fact that the concepts and ideas are relevant for all sciences, but how o2r (and geoinformatics) focuses on geoscience applications.
Looking ahead I mention our plans to bring our idea of a reproducible article into the publishing workflow of regular scientists.
Is digitisation a blessing or a curse? It‚Äôs both, because it creates new challenges and exciting applications in geoinformatics, but the amount of information in large datasets is not always clear and requires critical dealing.</p>
</blockquote>

<p><a href="https://www.uni-muenster.de/news/view.php?cmdid=9395"><img src="/public/images/2018-02_cover-video-en.jpg" alt="screenshot of video with English subtitles" /></a></p>

<p><strong>What was it like?</strong></p>

<blockquote>
  <p>Shooting the interview was fun and a great experience.
Having two cameras pointed at you and 4 people standing critically observing in the background could have been intimidating, but it wasn‚Äôt - big thanks to the team!</p>

  <p>The film shooting took only about 40 minutes (some technical preparations, two full takes, a little break and small talk) and was prepared with a one-hour conversation some weeks ahead.
I wrote down answers to some questions I expected - but the actual questions were not shared, for the better I think because the spontaneity makes it a conversation and less of a lecture.
The video published online is from the second, shorter take.
I wish they would have used the first one, because it was longer (around 10 minutes, so double the target time) and I could make more good points and feel like I got the message across better.
Researchers can go on for hours about topics they care about, and I hope my enthusiasm about Open Science and Reproducible Research does come across.
Though I am partly unhappy with the content, I hope the brevity spikes interest by fellow researchers and students at University of M√ºnster.
Next time you feel like cutting down your paper from 6000 to 5000 words is hard, try bringing it down to 2 minutes of talking to a non-expert :-).
A worthwhile excercise by the way.</p>

  <p>Although in this case, a non-expert could very well be an experienced scientists!
The lack of a common terminology for reproducible/replicable etc. became very apparent during the preparations.
For the next video I‚Äôll make every spectator read <a href="https://arxiv.org/abs/1802.03311">‚ÄúTerminologies for Reproducible Research‚Äù</a> first ‚Ä¶</p>

  <p><a href="https://de.wikipedia.org/wiki/Digitalisierung">‚ÄúDigitalisierung‚Äù</a> is a very hot topic in Germany, both in <a href="https://www.cnbc.com/2018/01/24/germanys-needs-to-modernize-and-embrace-digitization-merkel-says.html">politics</a> and <a href="https://www.politico.eu/article/5-questions-for-germanys-digital-future/">economy</a>. It regularly makes it into national news and more and more also into small talk.
There is so much connected with digitisation I did not touch on, like artificial intelligence (AI). How can we ensure research transparency and reproducibility when we don‚Äôt even know how something works?
<em>The one thing I regret</em> not saying in the interview is the fact that having studied computer science, I rarely grasp the difficulties non-programmers must have with digitisation.
While I do sometimes have to ‚Äúexplain computers‚Äù to friends and family, I don‚Äôt do it often enough, and must show more patience when I get the chance.
AI, web services, cloud computing - it is complex stuff!
Let‚Äôs help non-techies close to us more in understanding them (reading recommendation: <a href="https://www.amazon.com/Tubes-Journey-Internet-Andrew-Blum/dp/0061994952">‚ÄúTubes: A Journey to the Center of the Internet‚Äù by Andrew Blum</a>) !</p>

  <p>Formulating my view on digitisation in research and its impact on research reproducibility in ‚Äúplain language‚Äù was a worthwhile challenge and I can only recommend every researcher to participate in public relations workshops et cetera to try it out.
You got to take every chance you can get to reach out to non-scientists (research resolution: <a href="https://twitter.com/Protohedgehog/status/949315968903376896?s=09">Make sure all papers have non-specialist summaries</a>).
I applaud all bloggers and podcasters out there who do!</p>
</blockquote>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2018/01/12/sensebox-binder/">Open environmental data analysis</a></h3>
<span class="post-date">12 Jan 2018 | By Daniel N√ºst</span>
<p><em>This article is cross-posted in German on the <a href="https://sensebox.de/blog/2018-01-12-Offene-Forschung">senseBox blog</a>.</em></p>

<p>It‚Äôs the time of the year to make resolutions and to see beyond one‚Äôs own nose.
For o2r team member Daniel, this meant to explore what he could do with his brand new <em><a href="https://sensebox.de/de/products">senseBox:home</a></em> and the awesome <em><a href="https://binderhub.readthedocs.io">BinderHub</a></em> instead of putting it on the back burner.</p>

<p><a href="https://media.giphy.com/media/l49JRjO65S0WQ1Kyk/giphy.gif"><img src="https://media.giphy.com/media/l49JRjO65S0WQ1Kyk/giphy.gif" alt="screencast of senseBox-Binder analysis in RStudio running on mybinder.org" /></a></p>

<p><a href="http://mybinder.org/v2/gh/nuest/sensebox-binder/master"><img src="http://mybinder.org/badge.svg" alt="Binder" /></a></p>

<p>Building on a deep stack of Open Hardware, Free and Open Source Software, and Open Data, he created <!--more-->a fully open analysis of particulate measurements at New Year‚Äôs Eve in M√ºnster.
With just a few clicks you can open the exact computational environment which he utilized to retrieve historic sensor data from the openSenseMap API, and to analyse and visualise it with R.
And all that without installing any software to your computer, all you need is a web browser.</p>

<p>The following screenshots show the RStudio and Jupyter Notebook renderings of the workflow.</p>

<p><a href="/public/images/2018-01_sensebox-binder-rstudio-screenshot.png"><img src="/public/images/2018-01_sensebox-binder-rstudio-screenshot.png" alt="screenshot of senseBox-Binder analysis in RStudio" /></a></p>

<p><a href="/public/images/2018-01_sensebox-binder-jupyter-screenshot.png"><img src="/public/images/2018-01_sensebox-binder-jupyter-screenshot.png" alt="screenshot of senseBox-Binder analysis in Jupyter Notebook" /></a></p>

<p>And of course he worried about reproducibility and put in several layers of backup! Learn all about it at the GitHub repository:</p>

<p><strong><a href="https://github.com/nuest/sensebox-binder/">https://github.com/nuest/sensebox-binder/</a></strong></p>

<p>Or get a peak at the output of the analysis here: <a href="https://nuest.github.io/sensebox-binder/sensebox-analysis.html">https://nuest.github.io/sensebox-binder/sensebox-analysis.html</a></p>

<p>And we were not the only ones taking a look at particulate matter in Germany using R.
<a href="https://johannesfriedrich.github.io/">Johannes Friedrich</a>, researcher at <a href="http://www.lumi.uni-bayreuth.de/">University of Bayreuth</a>, used his R package <a href="https://github.com/JohannesFriedrich/senseBox">senseBox</a> to download and plot data of over 400 senseBoxes. See <a href="https://johannesfriedrich.github.io/2018-01-11-particular-matter-new-year/">his blog</a> for his findings.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2018/01/05/events-2018/">Events in 2018: Call for participation</a></h3>
<span class="post-date">05 Jan 2018 | By Daniel N√ºst</span>
<p>As everyone is slowly coming back to work, the o2r team wishes <em>Happy New Year</em>. What better way to start the year with planning some fun trips? Here are our recommendations for upcoming events:</p>

<ul>
  <li><a href="/2018/01/05/events-2018/#open-science-r-and-foss-sessions-at-egu-general-assembly-2018">EGU sessions on Reproducible Research, R, and FOSS</a></li>
  <li><a href="/2018/01/05/events-2018/#short-course-on-reproducible-papers-at-egu-general-assembly-2018">EGU short course ‚ÄúWriting reproducible geoscience papers‚Äù</a></li>
  <li><a href="/2018/01/05/events-2018/#reproducible-research-publications-at-agile-2018">AGILE pre-conference workshop ‚ÄúReproducible Research Publications‚Äù</a></li>
</ul>

<p><em>Please share this information with potentially interested parties (and <a href="https://twitter.com/o2r_project/status/949296239589449729">retweet</a>).</em>
<!--more--> <em>Thanks!</em></p>

<p><strong>Update!</strong> Added two more sessions and the OSGeo Townhall.</p>

<p><img src="/public/images/egu2018-banner.png" alt="EGU 2018 conference banner" width="100%" /></p>
<p class="attributionInlineImage">Image courtesy of EGU website.</p>

<h4 id="open-science-r-and-foss-sessions-at-egu-general-assembly-2018">Open Science, R, and FOSS sessions at EGU General Assembly 2018</h4>

<p>The European Geophysical Union‚Äôs General Assembly (EGU GA) takes place once more in April in Vienna - <a href="https://twitter.com/search?q=%23egu18">#EGU18</a>.
The deadline for abstracts is 10 Jan 2018, 13:00 CET, so don‚Äôt delay, <strong><a href="https://egu2018.eu/information/deadlines_and_milestones.html">submit your abstract today</a></strong> to one of the following sessions:</p>

<ul>
  <li><a href="http://meetingorganizer.copernicus.org/EGU2018/session/28036">Open Data, Reproducible Research, and Open Science</a> (ESSI3.5)</li>
  <li><a href="http://meetingorganizer.copernicus.org/EGU2018/session/27584">R‚Äôs deliberate role in Earth sciences (PICO Session)</a> (IE4.4/GM2.8/AS5.8/BG1.17/CL5.28/GD10.10/GMPV10.5/HS3.5/SSS13.77/TS11.12)</li>
  <li><a href="http://meetingorganizer.copernicus.org/EGU2018/session/26511">Free and Open Source Software (FOSS) for Geoinformatics and Geosciences</a> (PICO Session, ESSI3.1)</li>
</ul>

<p>Other sessions without o2r team members convening, but looking very interesting are</p>

<ul>
  <li><a href="http://meetingorganizer.copernicus.org/EGU2018/session/28043">Leveraging data-driven workflows to accelerate Earth Science research</a> (ESSI3.3)</li>
  <li><a href="http://meetingorganizer.copernicus.org/EGU2018/session/28030">Data science, Analytics and Visualization: The challenges and opportunities for Earth and Space Science</a> (ESSI4.3)</li>
  <li><a href="http://meetingorganizer.copernicus.org/EGU2018/session/26942">Future of (hydrological) publishing (PICO session)</a> (HS1.16)</li>
  <li><a href="http://meetingorganizer.copernicus.org/EGU2018/session/28034">Web-based Exchange and Processing of Environmental Data</a> (ESSI2.6)</li>
  <li><a href="http://meetingorganizer.copernicus.org/EGU2018/session/28668">Emerging Computational Technology</a> (PICO session, IE4.2/AS5.5/BG1.32/CL5.17)</li>
  <li><a href="http://meetingorganizer.copernicus.org/EGU2018/session/26510">Virtual Research Environments: creating online collaborative environments to support research in the Earth Sciences and beyond</a> (co-organised with American Geophysical Union, ESSI2.4)</li>
</ul>

<p>After our <a href="/2016/05/02/egu-review/">previous</a> <a href="/2017/05/04/o2r-at-EGU/">participations</a> we look forward to yet another event with interesting presentations and great conversations.
If you‚Äôre going, too, make sure to join the <a href="http://meetingorganizer.copernicus.org/EGU2018/session/29320"><strong>OSGeo Townhall</strong>: Open Science demystified</a> (TM8, on Tuesday) and the townhall meetings <a href="http://meetingorganizer.copernicus.org/EGU2018/session/29539"><strong>‚ÄúResearch Software Engineers in the Geosciences‚Äù</strong></a> (TM13, room L8 on Thursday) and <a href="http://meetingorganizer.copernicus.org/EGU2018/session/29063"><strong>‚ÄúEarthArXiv - a preprint server for the Earth Sciences‚Äù</strong></a> (TM4, room L2 on Monday).</p>

<p><em>See you at EGU!</em></p>

<h4 id="short-course-on-reproducible-papers-at-egu-general-assembly-2018">Short course on reproducible papers at EGU General Assembly 2018</h4>

<p>After organising a <a href="/2017/05/03/egu-short-course-recap/">workshop on reproducible computational research in the publication cycle</a> last year, o2r is teaming up again with <a href="https://reprozip.org/">ReproZip</a> to help geoscientists tackling the challenges of reproducible papers.
This year we organise the short course <a href="http://meetingorganizer.copernicus.org/EGU2018/session/28650"><em>SC1.13 - Writing reproducible geoscience papers using R Markdown, Docker, and GitLab</em></a>.
We plan to go guide participants through the steps of writing an Open Science publication and managing its rendering, publication, and archival by using free and open online platforms.</p>

<p>Let us know you‚Äôre interested to join with only two clicks: <strong><a href="https://doodle.com/poll/ngn9fqvhfkp3haui">https://doodle.com/poll/ngn9fqvhfkp3haui</a></strong></p>

<p>Other short courses without o2r participation, but looking promising (they both use <strong>R</strong>!), are</p>

<ul>
  <li>SC1.34 - <a href="http://meetingorganizer.copernicus.org/EGU2018/session/29054">Improving statistical evaluations in the geosciences</a></li>
  <li>SC1.17 - <a href="http://meetingorganizer.copernicus.org/EGU2018/session/28648">Using R for natural hazard risk modelling, with applications to wildfire risk forecasting</a></li>
</ul>

<h4 id="reproducible-research-publications-at-agile-2018">Reproducible Research Publications at AGILE 2018</h4>

<p>We are happy to announce another <a href="/2017/05/10/o2r-at-AGILE/">continuation</a>, a pre-conference workshop at the <a href="http://agile-online.org/index.php/conference/conference-2018">21st AGILE International Conference on Geographic Information Science</a> in Lund, Sweden: <strong><a href="https://o2r.info/reproducible-agile/">‚ÄúReproducible Research Publications‚Äù</a></strong></p>

<blockquote>
  <p>The half day workshop attempts to provides a hands-on introduction to reproducible research by reproducing a provided real-world publication. Together with the instructors they create a reproducible document from text, code, and data of a scholarly publication and publish it in a data repository.</p>
</blockquote>

<p>The workshop is accepted and will be announced <a href="https://agile-online.org/index.php/programme-2018/agile-workshops-2018">on the conference website</a> soon.
Please also check the <a href="https://o2r.info/reproducible-agile/">workshop website</a> for detailed information on registration and scheduling.</p>

<p><img src="https://agile-online.org/images/conference_2018/images/slogan-agile18-7.jpg" alt="agile conference banner" /></p>
<p class="attributionInlineImage">Image courtesy of AGILE website.</p>

<p>Submit your registration <em>both</em> at the <a href="https://agile-online.org/index.php/registration-2018">conference website</a> (will open soon!) and the workshop repository (see <a href="https://o2r.info/reproducible-agile/#registration">instructions</a>): <a href="https://github.com/o2r-project/reproducible-agile/issues/new">https://github.com/o2r-project/reproducible-agile/issues/new</a></p>

<p>The workshop is co-organized by o2r team members and Frank Osterman (ITC, Enschede), Barbara Hofer (Z_GIS), Carlos Granell (Jaume I), Valentina Cerutti (ITC), and Rusne Sileryte (OTB, TU Delft).
<em>We look forward to your registration!</em></p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2017/10/31/reference-implementation/">Reference Implementation - Try it out!</a></h3>
<span class="post-date">31 Oct 2017 | By Daniel N√ºst</span>
<p><em>Post updated on March 15 2018 to reflect simplified run commands.</em></p>

<p>Our project is going into its final phase. We are <a href="https://github.com/o2r-project/erc-spec/pull/48">working on</a> integrating our latest experiences and discussions into the <a href="https://o2r.info/erc-spec">ERC specification</a> and constantly add new features to the <a href="https://github.com/o2r-project">implementation of the reproducibility service</a>.</p>

<p>We also try to keep our <a href="/results/#implementation--demo">demo server</a> up to date.
<em>But what good is a reproducibility platform, when you can only try it online?</em></p>

<p>Inspired by the just passed <a href="http://www.openaccessweek.org/">Open Access Week</a> (<a href="https://twitter.com/hashtag/OAWeek?src=hash">#oaweek</a>), we‚Äôve started <a href="https://github.com/o2r-project/reference-implementation/issues">a new repository <code class="highlighter-rouge">reference-implementation</code></a> to expose our developments, which have been open source from the start, to the interested public.</p>

<p><img src="/public/images/2017-10-31-refimpl/o2r-refimpl-ubuntu.jpg" alt="o2r screenshot: Ubuntu" title="Screenshot: o2r reference implementation on Ubuntu" width="600" /></p>
<p class="attributionInlineImage">Screenshot: o2r reference implementation on <em>Ubuntu</em>.</p>

<p>It comprises documentation for <!--more-->run o2r software on a completely new machine:</p>

<ul>
  <li><a href="https://github.com/o2r-project/reference-implementation#download-images-and-run">Run o2r locally with pre-build Docker images</a> (the regular approach, let‚Äôs you easily update to later versions)</li>
  <li><a href="https://github.com/o2r-project/reference-implementation#build-images-from-source-and-run">Download all source code, build Docker images, and then run o2r locally</a> (the investigative approach)</li>
  <li>Upload a <a href="https://github.com/o2r-project/erc-examples">demo workspace or ERC</a></li>
</ul>

<p>The only efforts besides a few commands on your computer is <a href="https://support.orcid.org/knowledgebase/articles/343182-register-a-public-api-client-application">registering a client application with ORCID</a> to be able to log in, because there is no other way to authenticate within the o2r platform and microservices.
You may also <a href="https://zenodo.org/login/?next=%2Faccount%2Fsettings%2Fapplications%2Ftokens%2Fnew%2F">get an access token from Zenodo</a> to ‚Äúship‚Äù your completed ERC.
Eventually this repository will be the basis for a citable package of our software.</p>

<p><img src="/public/images/2017-10-31-refimpl/o2r-refimpl-macos-x.jpg" alt="o2r screenshot: OS X" title="Screenshot: o2r reference implementation on Mac OS X" width="600" /></p>
<p class="attributionInlineImage">Screenshot: o2r reference implementation on <em>OS X</em>.</p>

<p>We look forward to <a href="https://github.com/o2r-project/reference-implementation/issues">your feedback</a>!</p>

<h4 id="tldr"><code class="highlighter-rouge">tl;dr</code></h4>

<ol>
  <li>Install <a href="https://www.docker.com/get-docker">Docker</a> and <a href="https://docs.docker.com/compose/">docker-compose</a></li>
  <li>Download the o2r reference implementation repository and run it with with <br />
    <ul>
      <li><code class="highlighter-rouge">git clone https://github.com/o2r-project/reference-implementation</code></li>
      <li><code class="highlighter-rouge">docker-compose up</code></li>
    </ul>
  </li>
</ol>

<p><img src="/public/images/2017-10-31-refimpl/o2r-refimpl-windows10.jpg" alt="o2r screenshot: Windows 10" title="Screenshot: o2r reference implementation on Windows 10" width="600" /></p>
<p class="attributionInlineImage">Screenshot: o2r reference implementation on <em>Windows 10</em>.</p>

<p><img src="/public/images/2017-10-31-refimpl/o2r-refimpl-windows10-toolbox.jpg" alt="o2r screenshot: Windows 10 with Docker Toolbox" title="Screenshot: o2r reference implementation on Windows 10 with Docker Toolbox" width="600" /></p>
<p class="attributionInlineImage">Screenshot: o2r reference implementation on <em>Windows 10</em> (Docker Toolbox), contributed by Antonia - Thanks!</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2017/09/12/reproducible-research-badges/">Reproducible Research Badges</a></h3>
<span class="post-date">12 Sep 2017 | By Lukas Lohoff, Daniel N√ºst</span>
<p><em>This blog post presents work based on the study project <a href="https://zivgitlab.uni-muenster.de/geocontainer-badges">Badges for computational geoscience containers</a> at <a href="https://www.uni-muenster.de/Geoinformatics/">ifgi</a>. We thank the <a href="https://github.com/o2r-project/o2r-badger#contributors">project team</a> for their valuable contributions!</em></p>

<div style="padding: 1em; border: 2px solid #008643; background: #f3f5f7;">
This blog post was extended and presented and published as a peer-reviewed short paper at the <a href="https://agile-online.org//conference-2019">AGILE Conference 2019</a>. <b>Find the article <a title="article on EarthArXiv" href="https://eartharxiv.org/xtsqh/">here on EarthArXiv</a> and the presentation <a title="paper presentation slides" href="https://osf.io/549a6/">here on OSF</a></b>. The citation is

<pre>N√ºst, Daniel, Lukas Lohoff, Lasse Einfeldt, Nimrod Gavish, Marlena G√∂tza, Shahzeib T. Jaswal, Salman Khalid, et al. 2019. ‚ÄúGuerrilla Badges for Reproducible Geospatial Data Science (AGILE 2019 Short Paper).‚Äù EarthArXiv. June 19. doi:10.31223/osf.io/xtsqh.</pre>
</div>

<h4 id="introduction">Introduction</h4>

<p>Today badges are widely used in open source software repositories. They have a high recognition value and consequently provide an easy and efficient way to convey up-to-date metadata. Version numbers, download counts, test coverage or container image size are just a few examples. The website <a href="https://shields.io">Shields.io</a> provides many types of such badges. It also has an API to generate custom ones.</p>

<p>Now imagine similar badges, i.e. succinct, up-to-date information, not for software projects <!--more-->but for modern research publications. It answers questions such as:</p>

<ul>
  <li>When was a research paper published?</li>
  <li>Is the paper openly accessible?</li>
  <li>Was the paper published in a peer reviewed journal?</li>
  <li>What is the research‚Äôs area of interest?</li>
  <li>Are the results reproducible?</li>
</ul>

<p>These questions cover basic information for publications (date, open access, peer review) but also advanced concepts: the <em>research location</em> describes the location a study is focusing on. A publication with <em>reproducible results</em> contains a computation or analysis and the means to rerun it - ideally getting the same results again.</p>

<p>We developed a back-end service providing badges for reproducible research papers.</p>

<h4 id="overview-of-badges-for-research">Overview of badges for research</h4>

<p>We are however not the first nor the only ones to do this: <a href="https://www.scienceopen.com/">ScienceOpen</a> is a search engine for scientific publications. It has badges for open access publications, content type, views, comments and the <a href="https://www.altmetric.com/">Altmetric</a> score as displayed in Figure 1.</p>

<p><img src="/public/images/2017-09-12-badges/scienceOpen.png" alt="scienceopen badges" title="Figure 1: ScienceOpen badges" /></p>
<p class="attributionInlineImage">Figure 1: <em>ScienceOpen</em> badges in a search result listing.</p>

<p>These are helpful when using the ScienceOpen website, but they are not available for other websites. Additional issues are the inconsistent style and missing information relevant for reproducible geosciences, e.g. reproducibility status or the research location.</p>

<p>Badges are also used directly on publications, without the search portal ‚Äúmiddleman‚Äù. The published document, poster or presentation contains a badge along with the information needed to access the data or code.
The <a href="https://cos.io/">Center for Open Science</a> <a href="https://osf.io/tvyxz/wiki/home/">designed badges</a> for acknowledging open practices in scientific articles accompanied by guidelines for <a href="https://osf.io/tvyxz/wiki/3.%20Incorporating%20Badges%20into%20Publication%20Workflow/">incorporating them into journals‚Äô peer review workflows</a> and <a href="https://osf.io/tvyxz/wiki/4.%20Incorporating%20Badge%20Visualization%20into%20Publications/">adding them to published documents</a>, including large colored and small black-and-white variants. The badges are for <em>Open Data</em>, <em>Open Materials</em>, and <em>Preregistration</em> of studies (see Figure 2) and are adopted by over a dozen of journals to date (cf. <a href="https://osf.io/tvyxz/wiki/5.%20Adoptions%20and%20Endorsements/">Adoptions and Endorsements</a>).</p>

<p><img src="/public/images/2017-09-12-badges/cos.png" alt="COS badges" title="Figure 2: COS badges" width="400" /></p>
<p class="attributionInlineImage">Figure 2: <em>COS</em> badges.</p>

<p>University of Washington‚Äôs <a href="http://escience.washington.edu/">eScience Institute</a> created a peer-review process for open data and open materials badges <a href="https://github.com/uwescience-open-badges/about">https://github.com/uwescience-open-badges/about</a> based on the COS badges. The service is meant for faculty members and students at the University of Washington, but external researchers can also apply. The initiative also has a list of relevant <a href="https://github.com/uwescience-open-badges/about#where-can-i-read-more-about-this">publications on the topic</a>.</p>

<p>A study by Kidwell et al. [<a href="#kidwell">1</a>] demonstrates a positive effect by the introduction of open data badges in the journal <em>Psychological Science</em>: After the journal started awarding badges for open data, more articles stating open data availability actually published data (cf. [<a href="#baker">2</a>]). They see badges as a simple yet effective way to promote data publishing. The argument is very well summarized in the tweet below:</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">Simple rewards are sufficient to see the change we want to occur <a href="https://twitter.com/hashtag/SSP2017?src=hash">#SSP2017</a> <a href="https://t.co/P1H4hpQeqN">pic.twitter.com/P1H4hpQeqN</a></p>&mdash; David Mellor (@EvoMellor) <a href="https://twitter.com/EvoMellor/status/870409694367666176">1. Juni 2017</a></blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Peng [<a href="#peng1">3</a>, <a href="#peng2">4</a>] reports on the efforts the journal <em>Biostatistics</em> is taking to promote reproducible research, including a set of <em>‚Äúkite marks‚Äù</em>, which can easily be seen as minimalistic yet effective badges. <em><strong>D</strong></em> and <em><strong>C</strong></em> if data respectively code is provided, and <em><strong>R</strong></em> if results were successfully reproduced during the review process (implying D and C). Figure 3 shows the usage of <strong>R</strong> on an article‚Äôs title page (cf. [<a href="#lee">5</a>]).</p>

<p><img src="/public/images/2017-09-12-badges/biostatistics-kitemark.png" alt="Biostatistics badges" title="Figure 3: Biostatistics kite marks" width="400" /></p>
<p class="attributionInlineImage">Figure 3: <em>Biostatistics</em> kite mark <b>R</b> rendering in the PDF version of the paper.</p>

<p>The Association for Computing Machinery (<a href="https://www.acm.org/">ACM</a>) provides a common terminology and standards for artifact review processes for its conferences and journals, see their policies website section on <a href="https://www.acm.org/publications/policies/artifact-review-badging">Artifact Review Badging</a>. The have a system of three badges with several levels accompanied by specific criteria. They can be independently awarded:</p>

<ul>
  <li><em>Artifacts Evaluated</em> means artifacts were made available to reviewers and awarded the level <em>Functional</em> or <em>Reusable</em></li>
  <li><em>Artifacts Available</em> means a deposition in a repository ensures permanent and open availability (no evaluation)</li>
  <li><em>Results Validated</em> means a third party successfully obtained the same results as the author at the levels <em>Results Replicated</em> (using, in part, artifacts provided by the author) or <em>Results Reproduced</em> (without author-supplied artifacts)</li>
</ul>

<p>Figure 4 shows a rendering of the ACM badges.</p>

<p><img src="/public/images/2017-09-12-badges/acm.png" alt="ACM badges" title="Figure 4: ACM badges" width="500" /></p>
<p class="attributionInlineImage">Figure 4: <em>ACM</em> badges, from left to right: Artifacts Evaluated ‚Äì Functional, Artifacts Evaluated ‚Äì Reusable, Artifacts Available, Results Replicated, and Results Reproduced. (Copyright &copy; 2017, ACM, Inc)</p>

<p>Although these examples are limited to a specific journal, publisher, or institution, they show the potential of badges. They also show the diversity, limitations, and challenges in describing and awarding these badges.</p>

<p>For this reason, our goal is to explore sophisticated and novel badge types (concerning an article‚Äôs reproducibility, research location, etc.) and to find out how to provide them independently from a specific journal, conference, or website.</p>

<h4 id="an-independent-api-for-research-badges">An independent API for research badges</h4>

<p>Advanced badges to answer the above questions are useful for literature research, because they open new ways of exploring research by allowing to quickly judge the relevance of a publication, and they can motivate efforts towards openness and reproducibility. Three questions remain: How can the required data for the badges be found, ideally automatically? How can the information be communicated? How can it be integrated across independent, even competitive, websites?</p>

<p>Some questions on the data, such as the publication date, the peer review status and the open access status can already be answered by online research library APIs, for example those provided by <a href="https://www.crossref.org/">Crossref</a> or <a href="https://doaj.org/">DOAJ</a>.
The <a href="https://o2r.info/api/">o2r API</a> can answer the remaining questions about reproducibility and location: Knowing if a publication is reproducible is a core part of the o2r project. Furthermore, the location on which a research paper focuses can be extracted from spatial files published with an Executable Research Compendium [<a href="#nuest">6</a>]. The metadata extraction tool <a href="https://github.com/o2r-project/o2r-meta">o2r-meta</a> provides the latter feature, while the <a href="https://o2r.info/erc-spec">ERC specification</a> and <a href="https://github.com/o2r-project/o2r-muncher">o2r-muncher</a> micro service enable the former.</p>

<p><em>How can we integrate data from these different sources?</em></p>

<p><a href="https://github.com/o2r-project/o2r-badger">o2r-badger</a> is a <em>Node.js</em> application based on the <a href="https://expressjs.com/">Express</a> web application framework. It provides an API endpoint to serve badges for reproducible research integrating multiple online services into informative badges on scientific publications. Its <a href="https://github.com/o2r-project/o2r-badger#api-documentation-version-02">RESTful API</a> has routes for five different badge types:</p>

<ul>
  <li><em>executable</em>: Information about executability and reproducibility of a publication</li>
  <li><em>licence</em>: licensing information</li>
  <li><em>spatial</em>: a publication‚Äôs area of interest</li>
  <li><em>releasetime</em>: publication date</li>
  <li><em>peerreview</em>: if and by which process the publication was peer reviewed</li>
</ul>

<p>The API can be queried with URLs following the pattern <code class="highlighter-rouge">/api/1.0/badge/:type/:doi</code>. <code class="highlighter-rouge">:type</code> is one of the aforementioned types, and <code class="highlighter-rouge">:doi</code> is a publication‚Äôs <a href="https://en.wikipedia.org/wiki/Digital_object_identifier">Digital object identifier</a> (DOI).</p>

<p>The badger currently provides badges using two methods: internally created SVG-based badges, and redirects to <a href="https://shields.io/">shields.io</a>.
The redirects construct a simple shields.io URL.
The SVG-based badges are called <em>extended</em> badges and contain more detailed information: the extended <em>license</em> badge for example has three categories (<em>code</em>, <em>data</em> and <em>text</em>, see Figure 5), which are <a href="https://github.com/o2r-project/o2r-badger/blob/master/controllers/license/license.js#L312">aggregated</a> to single values (open, partially open, mostly open, closed) for the shields.io badge (see Figure 6).</p>

<p><img src="/public/images/2017-09-12-badges/license_extended.svg" alt="license badge" title="Figure 4: An extended *licence* badge reporting open data, text and code" /></p>
<p class="attributionInlineImage">Figure 5: An extended licence badge reporting open data, text and code.</p>

<p>Extended badges are meant for websites or print publications of a single publication, e.g. an article‚Äôs title page. They can be resized and alternatively provided pre-rendered as a PNG image. In contrast, the standard shields.io badges are smaller, text based badges. They still communicate the most important piece of information:</p>

<p><img src="https://img.shields.io/badge/licence-open-44cc11.svg" alt="shields.io badge" /></p>
<p class="attributionInlineImage">Figure 6: An shields.io based small badge, based on the URL <a href="https://img.shields.io/badge/licence-open-44cc11.svg">https://img.shields.io/badge/licence-open-44cc11.svg</a>.</p>

<p>They excel at applications where space is important, for example search engines listing many research articles. They are generated on the fly when a URL is requested (e.g. <code class="highlighter-rouge">https://img.shields.io/badge/licence-open-44cc11.svg</code>) which specifies the text (e.g. <code class="highlighter-rouge">licence</code> and <code class="highlighter-rouge">open</code>) and the color (<code class="highlighter-rouge">44cc11</code> is a <a href="http://html-color-codes.info/">HTML color code</a> for green).</p>

<p>Let‚Äôs look at another example of an <em>executable</em> badge and how it is created.
The badge below is requested from the badger demo instance on the o2r server by providing the DOI of the publication for the <code class="highlighter-rouge">:doi</code> element in the above routes:</p>

<p><a href="https://o2r.uni-muenster.de/api/1.0/badge/executable/10.1126%2Fscience.1092666"><code class="highlighter-rouge">https://o2r.uni-muenster.de/api/1.0/badge/executable/10.1126%2Fscience.1092666</code></a></p>

<p>This URL requests a badge for the reproducibility status of the paper ‚ÄúGlobal Air Quality and Pollution‚Äù from <em><a href="http://science.sciencemag.org/">Science</a></em> magazine identified by the DOI <a href="https://doi.org/10.1126/science.1092666"><code class="highlighter-rouge">10.1126/science.1092666</code></a>. When the request is sent, the following steps happen in o2r-badger:</p>

<ol>
  <li>The badger tries to find a reproducible research paper (called Executable Research Compendium (<a href="https://o2r.info/erc-spec/spec/">ERC</a>) via the o2r API. Internally this searches the database for ERC connected to the given DOI.</li>
  <li>If if finds an ERC, it looks for a matching <em><a href="https://o2r.info/api/job/">job</a></em>, a report of a reproduction analysis.</li>
  <li>Depending on the reproduction result (<code class="highlighter-rouge">success</code>, <code class="highlighter-rouge">running</code>, or <code class="highlighter-rouge">failure</code>) specified in the job, the badger generates a green, yellow or red badge. The badge also contains text indicating the reproducibility of the specified research publication.</li>
  <li>The request is redirected to a <a href="https://shields.io/">shields.io</a> URL link containing the color and textual information..</li>
</ol>

<p>The returned image contains the requested information, which is in this case a successful reproduction:</p>

<p>URL: <a href="https://img.shields.io/badge/executable-yes-44cc11.svg">https://img.shields.io/badge/executable-yes-44cc11.svg</a></p>

<p>Badge: <img src="https://img.shields.io/badge/executable-yes-44cc11.svg" alt="shields.io badge executable" /></p>

<p>If an extended badge is requested, the badger itself generates an SVG graphic instead.</p>

<p>Badges for reproducibility, peer review status and license are color coded to provide visual aids. They indicate for example (un)successful reproduction, a public peer review process, or different levels of open licenses.
These badges get their information from their respective external sources: the information for peer review badges is requested from the external service <em>DOAJ</em>, a community-based website for open access publications. The <em>Crossref</em> API provides the dates for the releasetime badges. The spatial badge also uses the o2r services. The badger service converts the spatial information provided as coordinates into textual information, i.e. place names, using the <a href="http://www.geonames.org/export/web-services.html">Geonames API</a>.</p>

<h4 id="spread-badges-over-the-web">Spread badges over the web</h4>

<p>There is a great badge server, and databases providing manifold badge information, but how to get them displayed online? The sustainable way would be for research website operators to agree on a common badge system and design, and then incorporate these badges on their platforms. But we know it is unrealistic this ever happens.
So instead of waiting, or instead of engaging in a lengthy discourse with all stakeholders, we decided to create a <a href="https://developer.chrome.com/extensions">Chrome extension</a> and augment common research websites. The <a href="https://github.com/o2r-project/o2r-extender">o2r-extender</a> automatically inserts badges into search results or publication pages using client-side browser scripting. It is <a href="https://chrome.google.com/webstore/detail/opening-reproducible-rese/fhhfncpkfohlhphlcgpkbpialfhkmbil">available in the Chrome Web Store</a> and ready to be tried out.</p>

<p>The extender currently supports the following research websites:</p>

<ul>
  <li>Google Scholar <a href="https://scholar.google.de/">https://scholar.google.de/</a></li>
  <li>DOAJ.org <a href="https://doaj.org/">https://doaj.org/</a></li>
  <li>ScienceDirect.com <a href="http://www.sciencedirect.com/">http://www.sciencedirect.com/</a></li>
  <li>ScienceOpen.com <a href="https://scienceopen.com/">https://scienceopen.com/</a></li>
  <li>PLOS.org <a href="https://www.plos.org/">https://www.plos.org/</a></li>
  <li>Microsoft Academic <a href="https://academic.microsoft.com/">https://academic.microsoft.com/</a></li>
  <li>Mendeley <a href="https://www.mendeley.com/">https://www.mendeley.com/</a></li>
</ul>

<p>For each article display on these websites, the extender requests a set of badges from the badger server. These are then inserted into the page‚Äôs HTML code after rendering the regular website as shown exemplary in the screenshot in Figure 7.</p>

<p><img src="/public/images/2017-09-12-badges/google_scholar_badges.png" alt="google scholar badges" title="Figure 7: Badges integrated into Google Scholar search results" /></p>
<p class="attributionInlineImage">Figure 7: Badges integrated into <em>Google Scholar</em> search results (partial screenshot).</p>

<p>When the badger does not find information for a certain DOI, it returns a grey ‚Äúnot available‚Äù - badge instead. This is shown in the screenshot above for the outermost license and peer review badges.</p>

<p>The extender consists of a content script, similar to a <a href="http://techsupportguides.com/what-is-a-userscript/">userscript</a>, adjusted to each target website. The content scripts insert badges at suitable positions in the view. A set of common functions defined in the Chrome extension for generating HTML, getting metadata based on DOIs, and inserting badges are used for the specific insertions. A good part of the extender code is used to extract the respetive DOIs from the information included in the page, which is a lot trickier than interacting with an API. Take a look at the source code <a href="https://github.com/o2r-project/o2r-extender/tree/master/extension">on GitHub</a> for details.</p>

<p>But the extender is not limited to inserting static information. The results of searches can also be filtered based on badge value and selected badge types can be turned on or off directly from the website with controls inserted into the pages‚Äô navigation menus (see left hand side of Figure 8).</p>

<p><img src="/public/images/2017-09-12-badges/doaj_badges.png" alt="doaj filtering" title="Figure 8: Filtering search results on DOAJ" /></p>
<p class="attributionInlineImage">Figure 8: Filtering search results on <em>DOAJ</em>. Results not matching the filter or articles where the DOI could not be detected are greyed out.</p>

<p>The extender is easily configurable: it can be enabled and disabled with a click on the icon in the browser toolbar. You can select the badge types to be displayed in the extension settings. Additionally it contains links to local info pages (‚ÄúHelp‚Äù and ‚ÄúAbout‚Äù, see Figure 9).</p>

<p><img src="/public/images/2017-09-12-badges/extender_configuration.png" alt="extender config" title="Figure 9: *o2r-extender* configuration" /></p>
<p class="attributionInlineImage">Figure 9: extender configuration.</p>

<h4 id="outlook-action-integrations">Outlook: Action integrations</h4>

<p>The <em>extender</em> also has a feature unrelated to badges. In the context of open science and reproducible research, the reproducibility service connects to other services in a larger context as described in the <a href="https://o2r.info/architecture/">o2r architecture</a> (see section Business context).</p>

<p>Two core connections are loading research workspaces from cloud storage and connecting to suitable data repositories for actual storage of ERCs.
To facilitate these for users, the extender can also augment the user interfaces of the non-commercial cloud storage service <a href="http://sciebo.de/">Sciebo</a> and the scientific data repository <a href="https://zenodo.org/">Zenodo</a> with reproducibility service functionality.</p>

<p>When using <em>Sciebo</em>, a button is added to a file‚Äôs or directory‚Äôs context menu. It allows direct interaction with the o2r platform to upload a new reproducible research paper (ERC) from the current file or directory as shown in Figure 10.</p>

<p><img src="/public/images/2017-09-12-badges/sciebo_integration.png" alt="sciebo integration" title="Figure 10: *Sciebo* upload integration" /></p>
<p class="attributionInlineImage">Figure 10: <em>Sciebo</em> upload integration.</p>

<p>When you are viewing an <em>Executable Research Compendium</em> on <em>Zenodo</em>, a small badge links directly to the corresponding inspection view in the o2r platform (see Figure 11):</p>

<p><img src="/public/images/2017-09-12-badges/zenodo_integration.png" alt="zenodo integration" title="Figure 11: Zenodo inspection integration" /></p>
<p class="attributionInlineImage">Figure 11: Link to inspection view and tag "ERC" on <em>Zenodo</em>.</p>

<h4 id="discussion">Discussion</h4>

<p>The study project <a href="https://zivgitlab.uni-muenster.de/geocontainer-badges">Badges for computational geoscience containers</a> initially implemented eight microservices responsible for six different badges types, badge scaling and testing. A microservice architecture using Docker containers was not chosen because of the need for immense scaling capabilities, but for another reason: developing independent microservices makes work organization much easier. This is especially true for a study project where students prefer different programming languages and have different skill sets.</p>

<p>However, for o2r the microservices were integrated into a single microservice for easier maintainability. This required refactoring, rewriting and bug fixing.
Now, when a badge is requested, a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/then">promise chain</a> is executed (see <a href="https://github.com/o2r-project/o2r-badger/blob/master/controllers/executability/executability.js#L83">source code example</a>). The chain reuses functions across all badges where possible, which were refactored from the study project code into small chunks to avoid <a href="http://callbackhell.com/">callback hell</a>.</p>

<p>A critical feature of extender is the detection of the DOI from the website‚Äôs markup. For some websites, such as <em>DOAJ.org</em> or <em>ScienceOpen.com</em>, this is not hard because they provide the DOI directly for each entry.
When the DOI is not directly provided, the extender tries to retrieve the DOI from a request to <em>CrossRef.org</em> using the paper title (see <a href="https://github.com/o2r-project/o2r-extender/blob/master/extension/BaseImplementation.js#L447">source code for the DOI detection</a>). This is not always successful or may find incorrect results.</p>

<p>The Chrome extension supports nine different websites. If there are changes to one of these, the extender has to be updated as well. For example, <a href="http://sciebo.de/">Sciebo</a> (based on <a href="https://owncloud.org/">ownCloud</a>) recently changed their URLs to include a ‚Äúfileid‚Äù parameter which resulted in an error when parsing the current folder path.</p>

<p>As discussed above, in an ideal world the Chrome extension would not be necessary. While there are a few tricky parts with a workaround like this, it nevertheless allows o2r as a research project to easily demonstrate ideas and prototypes stretching beyond the project‚Äôs own code to even third party websites.
Moreover, the combination of extender client and badger service is suitable for embedding a common science badge across multiple online platforms. It demonstrates a technical solution how the scientific community can create and maintain a cross-publisher, cross-provider solution for research badges. What it clearly lacks is a well-designed and transparent workflow for awarding and scrutinizing badges.</p>

<h4 id="future-work">Future Work</h4>

<p>One of the biggest source of issues for <em>badger</em> currently is the dependence on external services such as <em>Crossref</em> and <em>DOAJ</em>. While this cannot be directly resolved, it can be mitigated by requesting multiple alternative back-end services, which can provide the same information (e.g. <em>DOAJ</em> for example also offers licence information at least for publications), or even by caching.
Furthermore, the newness of the o2r platform itself is another issue: <em>licence</em>, <em>executable</em>, and <em>spatial</em> badges are dependent on an existing ERC, which must be linked via DOI to a publication. If a research paper has not been made available as an ERC then a users will get a lot of ‚Äún/a‚Äù badges.</p>

<p>The <em>extender</em> is only available for Google Chrome and Chromium. But since Firefox is switching to <a href="https://developer.mozilla.org/en-US/Add-ons/WebExtensions">WebExtensions</a> and moving away from their old ‚Äúadd-ons‚Äù completely with <a href="https://developer.mozilla.org/en-US/Add-ons/Overlay_Extensions/Firefox_addons_developer_guide">Firefox 57</a>, a port from a Chrome Extension to the open <em>WebExtensions</em> makes the extender available for more users. The port should be possible with a few changes due to only minor differences between the two types of extensions.</p>

<p>Other ideas for further development and next steps include:</p>

<ul>
  <li>Interactive badges can provide additional information when hovering over them or when the badges are clicked, most importantly why and by who the badge was assigned.</li>
  <li>Provide the information behind the badges via an API.</li>
  <li>Create a common design for extended badges.</li>
  <li>Conduct a user study on extended and basic badges within a discovery scenario.</li>
  <li>Evaluating usage of badges in print applications and for visually impaired people (cf. COS badges)</li>
</ul>

<p>For more see the GitHub issues pages of <a href="https://github.com/o2r-project/o2r-badger/issues">o2r-badger</a> and <a href="https://github.com/o2r-project/o2r-extender/issues">o2r-extender</a>. Any feedback and ideas are appreciated, either on the GitHub repositories or in <a href="https://groups.google.com/d/topic/reproducible-research/AP0k_xi69AA/discussion">this discussion thread</a> in the Google Group <a href="https://groups.google.com/forum/#!forum/reproducible-research"><em>Scientists for Reproducible Research</em></a>. We thank the group members for pointing to some of the resources referenced in this post.</p>

<h4 id="references">References</h4>

<p><a name="kidwell"></a>[1] Kidwell, Mallory C., et al. 2016. Badges to Acknowledge Open Practices: A Simple, Low-Cost, Effective Method for Increasing Transparency. <em>PLOS Biology</em> 14(5):e1002456. doi:<a href="https://doi.org/10.1371/journal.pbio.1002456">https://doi.org/10.1371/journal.pbio.1002456</a>.</p>

<p><a name="baker"></a>[2] Baker, Monya, 2016. Digital badges motivate scientists to share data. <em>Nature News</em>. doi:<a href="https://doi.org/10.1038/nature.2016.19907">10.1038/nature.2016.19907</a>.
<!-- https://www.nature.com/news/digital-badges-motivate-scientists-to-share-data-1.19907 --></p>

<p><a name="peng1"></a>[3] Peng, Roger D. 2009. Reproducible research and Biostatistics. Biostatistics, Volume 10, Issue 3, Pages 405‚Äì408. doi:<a href="https://doi.org/10.1093/biostatistics/kxp014">10.1093/biostatistics/kxp014</a>.</p>

<p><a name="peng2"></a>[4] Peng, Roger D. 2011. Reproducible Research in Computational Science. Science 334 (6060): 1226‚Äì27. doi:<a href="https://doi.org/10.1126/science.1213847">10.1126/science.1213847</a>.</p>

<p><a name="lee"></a>[5] Lee, Duncan, Ferguson, Claire, and Mitchell, Richard. 2009. Air pollution and health in Scotland: a multicity study. Biostatistics, Volume 10, Issue 3, Pages 409‚Äì423, doi:<a href="https://doi.org/10.1093/biostatistics/kxp010">10.1093/biostatistics/kxp010</a>.</p>

<p><a name="nuest"></a>[6] N√ºst, D., Konkol, M., Pebesma, E., Kray, C., Schutzeichel, M., Przibytzin, H., and Lorenz, J. Opening the Publication Process with Executable Research Compendia. D-Lib Magazine. 2017. doi:<a href="https://doi.org/10.1045/january2017-nuest">10.1045/january2017-nuest</a>.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2017/07/07/useR2017/">useR!2017</a></h3>
<span class="post-date">07 Jul 2017 | By Daniel N√ºst</span>
<p><img src="https://user2017.brussels/images/logo.jpg" alt="useR!2017 conference logo" title="conference logo" width="400" /></p>

<p>This o2r team members <a href="https://orcid.org/0000-0002-0024-5046">Daniel</a> and <a href="https://orcid.org/0000-0001-8049-7069">Edzer</a> had the pleasure to participate in the largest conference of R developers and users, <a href="https://ser2017.brussels/">useR!2017</a> in Br√ºssels, Belgium.</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">Daniel N√ºst <a href="https://twitter.com/nordholmen">@nordholmen</a> presenting containerit, creates a docker img from an R session to archive reproducibly <a href="https://twitter.com/o2r_project">@o2r_project</a> <a href="https://twitter.com/cboettig">@cboettig</a> <a href="https://t.co/o65O8s8jXY">pic.twitter.com/o65O8s8jXY</a></p>&mdash; Edzer Pebesma (@edzerpebesma) <a href="https://twitter.com/edzerpebesma/status/882909374951424001">6. Juli 2017</a></blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Daniel presented a new R extension package, <a href="https://github.com/o2r-project/containerit/"><code>containerit</code></a>, in the <em>Data reproducibility</em> session.
It can <!--more-->automatically create a container manifest, i.e. a Dockerfile, from different sources, such as sessions or scripts.</p>

<p>If you want to learn more about <code>containerit</code>, read <a href="/2017/05/30/containerit-package/">this blog post</a> and take a look at Daniel‚Äôs presentation (also on <a href="https://doi.org/10.5281/zenodo.824006">Zenodo</a>).</p>

<iframe src="//www.slideshare.net/slideshow/embed_code/key/fA7jwdlV83YqZe" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""> </iframe>
<div style="margin-bottom:5px; font-size: 75%;"> <strong> <a href="//www.slideshare.net/nuest/containerit-at-user2017-conference-brussels" title="containerit at useR!2017 conference, Brussels" target="_blank">containerit at useR!2017 conference, Brussels</a> </strong> from <strong><a target="_blank" href="https://www.slideshare.net/nuest">Daniel N√ºst</a></strong> </div>

<p>Fortunately the presentation was very well-attended and assured our understanding that the importance of reproducibility is wide-spread in the R community.
The interest in using containers for this challenge is growing, as shown by the numerous questions Daniel received after the session and the remainder of the conference.</p>

<p><code>containerit</code> is Open Source Software and we invite you to <a href="https://github.com/o2r-project/containerit/blob/master/README.md">try it out</a>, <a href="https://github.com/o2r-project/containerit/issues/new">inform us about bugs</a>,and even <a href="https://github.com/o2r-project/containerit/projects/1">participate in the development</a>.
In the near future, we will use the package to automatically create <a href="https://doi.org/10.1045/january2017-nuest">Executable Research Compendia</a> in our <a href="https://o2r.info/architecture">reproducibility service</a>, but the package also has an <a href="https://github.com/o2r-project/containerit/projects/1">independent roadmap</a> and it hopefully proves useful for many useRs outside of our project.</p>

<p>The workshop presentations were recorded and are published <a href="https://channel9.msdn.com/Events/useR-international-R-User-conferences/useR-International-R-User-2017-Conference">on Channel 9</a>, including <a href="https://channel9.msdn.com/Events/useR-international-R-User-conferences/useR-International-R-User-2017-Conference/Automatically-archiving-reproducible-studies-with-Docker">Daniel‚Äôs talk</a>:</p>

<iframe src="https://channel9.msdn.com/Events/useR-international-R-User-conferences/useR-International-R-User-2017-Conference/Automatically-archiving-reproducible-studies-with-Docker/player?format=html5" width="560" height="315" allowfullscreen="" frameborder="0"></iframe>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2017/06/28/o2r-at-C4RR/">C4RR workshop in Cambridge</a></h3>
<span class="post-date">28 Jun 2017 | By Daniel N√ºst</span>
<p>Today o2r team member <a href="https://orcid.org/0000-0002-0024-5046">Daniel</a> had the pleasure to present work from the o2r project at the two day <a href="https://www.software.ac.uk/c4rr">Docker Containers for Reproducible Research Workshop</a> held in Cambridge, UK.</p>

<p>It was a full packed <a href="https://www.software.ac.uk/c4rr/agenda">two days of talks and demos</a> (see also <a href="https://twitter.com/hashtag/C4RR?src=hash">#C4RR</a>).
People from a large <a href="https://www.software.ac.uk/c4rr/talks">variety of disciplines</a> shared how they use containers for making research transparent, scalable, transferable, and reproducible.</p>

<blockquote class="twitter-tweet" data-lang="de"><p lang="en" dir="ltr">Getting ready for two exciting days at <a href="https://twitter.com/hashtag/C4RR?src=hash">#C4RR</a> workshop in Cambridge. <a href="https://twitter.com/nordholmen">@nordholmen</a> presenting o2r tomorrow afternoon. <a href="https://twitter.com/SoftwareSaved">@SoftwareSaved</a> <a href="https://t.co/IhYqmjddPD">pic.twitter.com/IhYqmjddPD</a></p>&mdash; o2r (@o2r_project) <a href="https://twitter.com/o2r_project/status/879632038126661632">27. Juni 2017</a></blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Unlike the workshop‚Äôs title, Docker was not the only container solution. <a href="http://singularity.lbl.gov/">Singularity</a> made some important appearances, especially with the different groups working with clusters of thousands of nodes in HPC (high performance computing) and GPGPUs (general processing on graphical processing units). Further topics included deep learning, statistical reports by governments, using containers for teaching, scientific workflows in the cloud, virtual clusters and ‚Äúbest before‚Äù dates for software.</p>

<p>Daniel had the hard job of giving the final presentation. After all the previous talks, which comprises many different aspects of reproducible research also somehow part of o2r, this was a threatening task and felt a bit like like ‚Äúimposters syndrome‚Äù. However, the commonalities in motivation, challenges, and ideas are also a sign of the increasing popularity for using containers across <a href="https://www.software.ac.uk/c4rr/who-is-attending">diverse domains</a>. Eventually it is a very positive fact an event such as C4RR took place in Europe and had more than 50 people in attendance!</p>

<p>Take a look and Daniel‚Äôs slides and a video recording below.</p>

<iframe src="//www.slideshare.net/slideshow/embed_code/key/qYhO5hTorgqPcu" width="425" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen="">
</iframe>
<div style="margin-bottom: 10px; font-size: 80%;"> <strong> <a href="//www.slideshare.net/nuest/creating-executable-research-compendia-to-improve-reproducibility-in-the-geosciences" title="Creating Executable Research Compendia to Improve Reproducibility in the Geosciences" target="_blank">Creating Executable Research Compendia to Improve Reproducibility in the Geosciences</a> </strong> from <strong><a target="_blank" href="//www.slideshare.net/nuest">Daniel N√ºst</a></strong>
</div>

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/cJ1Vehh5J88?rel=0" frameborder="0" allowfullscreen=""></iframe>

<p>The workshop was a great experience and very well organized by the <a href="https://www.software.ac.uk/">Software Sustainability Institute</a>. We learned about both related and quite similar projects, but also acknowledged that o2r‚Äôs focus on ‚ÄúDesktop-sized‚Äù data and computing as well as supporting the geosciences domain does set us apart.</p>

<blockquote class="twitter-tweet" data-conversation="none" data-lang="de"><p lang="en" dir="ltr">Thanks for a great workshop to <a href="https://twitter.com/SoftwareSaved">@SoftwareSaved</a>  <a href="https://twitter.com/rgaiacs">@rgaiacs</a> <a href="https://twitter.com/StephenEglen">@StephenEglen</a> Taking home stickers and many new ideas <a href="https://twitter.com/hashtag/C4RR?src=hash">#C4RR</a> <a href="https://twitter.com/hashtag/reproducibleresearch?src=hash">#reproducibleresearch</a> <a href="https://t.co/tEMG34drgp">pic.twitter.com/tEMG34drgp</a></p>&mdash; o2r (@o2r_project) <a href="https://twitter.com/o2r_project/status/880115594116440067">28. Juni 2017</a></blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>


</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2017/05/30/containerit-package/">Generating Dockerfiles for reproducible research with R</a></h3>
<span class="post-date">30 May 2017 | By Daniel N√ºst, Matthias Hinz</span>
<p><em>This post is the draft of the vignette for a new R package by o2r team members <a href="https://github.com/MatthiasHinz">Matthias</a> and <a href="https://github.com/nuest">Daniel</a>. Find the original file <a href="https://github.com/o2r-project/containerit/blob/master/vignettes/containerit.Rmd">in the package repository on GitHub</a>.</em></p>

<ul>
  <li><a href="#introduction">1. Introduction</a></li>
  <li><a href="#creating-a-dockerfile">2. Creating a Dockerfile</a></li>
  <li><a href="#including-resources">3. Including resources</a></li>
  <li><a href="#image-metadata">4. Image metadata</a></li>
  <li><a href="#further-customization">5. Further customization</a></li>
  <li><a href="#cli">6. CLI</a></li>
  <li><a href="#challenges">7. Challenges</a></li>
  <li><a href="#conclusions-and-future-work">8. Conclusions and future work</a></li>
  <li><a href="#metadata">Metadata</a></li>
</ul>

<h4 id="1-introduction">1. Introduction</h4>

<p>Even though R is designed for open and reproducible research, users who
want to share their work with others are facing challenges. Sharing
merely the R script or R Markdown document should warrant
reproducibility, but many analyses rely on additional resources and
specific third party software as well. An R script may <!--more-->produce
unexpected results or errors when executed under a different version of
R or another platform. Reproduciblility is only assured by providing
complete setup instructions and resources. Long-term reproducibility can
be achieved by either regular maintenance of the code, i.e. keeping it
always working with the latest package versions from CRAN. It can be
supported by packages such as
<a href="https://rstudio.github.io/packrat/">packrat</a> and platforms such as
<a href="https://mran.microsoft.com/">MRAN</a>, which provide means to capture a
specific combination of R packages. An alternative to updating or
managing packages explicitly is providing the full runtime environment
in its original state, using <a href="https://en.wikipedia.org/wiki/Virtual_machine">virtual
machines</a> or <a href="https://en.wikipedia.org/wiki/Operating-system-level_virtualization">software
containers</a>.</p>

<p>The R extension package <code class="highlighter-rouge">containerit</code> aims to facilitate the latter
approach by making reproducible and archivable research with containers
easier. The development is supported by the DFG-funded project Opening
Reproducible Research (o2r, <a href="https://o2r.info">https://o2r.info</a>). <code class="highlighter-rouge">containerit</code> relies on
<a href="http://docker.com/">Docker</a> and automatically generates a container
manifest, or ‚Äúrecipe‚Äù, with setup instructions to recreate a runtime
environment based on a given R session, R script, R Markdown file or
workspace directory. The resulting
<a href="https://docs.docker.com/engine/reference/builder/"><code class="highlighter-rouge">Dockerfile</code></a> can
not only be read and understood by humans, but also be interpreted by
the Docker engine to create a software container containing all the R
packages and their system dependencies. This way all requirements of an
R workflow are packaged in an executable format.</p>

<p>The created Dockerfiles are based on the
<a href="https://github.com/rocker-org/rocker">Rocker</a> project (<a href="https://hub.docker.com/u/rocker/">Rocker on
Docker Hub</a>,
<a href="http://dirk.eddelbuettel.com/blog/2014/10/23/#introducing_rocker">introduction</a>).
Using the stack of version-stable Rocker images, it is possible to match
the container‚Äôs R version with the local R installation or any R version
the user requires. <code class="highlighter-rouge">containerit</code> executes the provided input workspace
or file first locally on the host machine in order to detect all
dependencies. For determining external software dependencies of attached
packages, <code class="highlighter-rouge">containerit</code> relies (a) on the <a href="https://sysreqs.r-hub.io/">sysreqs
database</a> and makes use of the corresponding
web API and R package, and (b) on internally defined rule sets for
challenging configurations.</p>

<p>The Dockerfile created by <code class="highlighter-rouge">containerit</code> can then be used to build a
Docker image. Running the image will start an R session that closely
resembles the creating systems runtime environment. The image can be
shared and archived and works anywhere with a compatible Docker version.</p>

<p>To build images and run containers, the package integrates with the
<a href="https://github.com/wch/harbor">harbor</a> package and adds a few
convenience functions for interacting with Docker images and containers.
For concrete details on reading, loading, or installing the <em>exact</em>
versions of R packages including their system dependencies/libraries,
this project focuses on the geospatial domain. <code class="highlighter-rouge">containerit</code> uses the
package
<a href="https://cran.r-project.org/web/packages/futile.logger/"><code class="highlighter-rouge">futile.logger</code></a>
to provide information to the user at a configurable level of detail,
see <a href="https://cran.r-project.org/web/packages/futile.logger/README.html">futile.logger
documentation</a>.</p>

<p>In the remainder of this vignette, we first introduce the main usage
scenarios for <code class="highlighter-rouge">containerit</code> and document current challenges as well as
directions for future work.</p>

<h4 id="2-creating-a-dockerfile">2. Creating a Dockerfile</h4>

<h5 id="21-basics">2.1 Basics</h5>

<p>The easiest way to generate a Dockerfile is to run an analysis in an
interactive R session and create a Dockerfile for this session by
loading <code class="highlighter-rouge">containerit</code> and calling the <code class="highlighter-rouge">dockerfile()</code>- method with
default parameters. As shown in the example below, the result can be
pretty-printed and written to a file. If no <code class="highlighter-rouge">file</code> argument is supplied
to <code class="highlighter-rouge">write()</code>, the Dockerfile is written to the current working directory
as <code class="highlighter-rouge">./Dockerfile</code>, following the typical naming convention of Docker.</p>

<p>When packaging any resources, it is essential that the R working
directory is the same as the build context, to which the Dockerfile
refers. All resources must be located below this directory so that they
can be refered to by relative paths (e.g. for copy instructions). This
must also be considered when packaging R scripts that use relative
paths, e.g. for reading a file or sourcing another R script.</p>

<h5 id="22-packaging-an-interactive-session">2.2 Packaging an interactive session</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>library("containerit")

## 
## Attaching package: 'containerit'

## The following object is masked from 'package:base':
## 
##     Arg

# do stuff, based on demo("krige")
library("gstat")
library("sp")

data(meuse)
coordinates(meuse) = ~x+y
data(meuse.grid)
gridded(meuse.grid) = ~x+y
v &lt;- variogram(log(zinc)~1, meuse)
m &lt;- fit.variogram(v, vgm(1, "Sph", 300, 1))
plot(v, model = m)

# create Dockerfile representation
dockerfile_object &lt;- dockerfile()

## INFO [2017-05-30 14:49:20] Trying to determine system requirements for the package(s) 'sp, gstat, knitr, Rcpp, intervals, lattice, FNN, spacetime, zoo, digest, rprojroot, futile.options, backports, magrittr, evaluate, stringi, futile.logger, xts, rmarkdown, lambda.r, stringr, yaml, htmltools' from sysreq online DB
## INFO [2017-05-30 14:49:21] Adding CRAN packages: sp, gstat, knitr, Rcpp, intervals, lattice, FNN, spacetime, zoo, digest, rprojroot, futile.options, backports, magrittr, evaluate, stringi, futile.logger, xts, rmarkdown, lambda.r, stringr, yaml, htmltools
## INFO [2017-05-30 14:49:21] Created Dockerfile-Object based on sessionInfo
</code></pre></div></div>

<p>The representation of a Dockerfile in R is an instance of the S4 class
<code class="highlighter-rouge">Dockerfile</code>.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dockerfile_object

## An object of class "Dockerfile"
## Slot "image":
## An object of class "From"
## Slot "image":
## [1] "rocker/r-ver"
## 
## Slot "postfix":
## An object of class "Tag"
## [1] "3.4.0"
## 
## 
## Slot "maintainer":
## An object of class "Label"
## Slot "data":
## $maintainer
## [1] "daniel"
## 
## 
## Slot "multi_line":
## [1] FALSE
## 
## 
## Slot "instructions":
## [[1]]
## An object of class "Run_shell"
## Slot "commands":
## [1] "export DEBIAN_FRONTEND=noninteractive; apt-get -y update"
## [2] "apt-get install -y pandoc \\\n\tpandoc-citeproc"         
## 
## 
## [[2]]
## An object of class "Run"
## Slot "exec":
## [1] "install2.r"
## 
## Slot "params":
##  [1] "-r 'https://cloud.r-project.org'" "sp"                              
##  [3] "gstat"                            "knitr"                           
##  [5] "Rcpp"                             "intervals"                       
##  [7] "lattice"                          "FNN"                             
##  [9] "spacetime"                        "zoo"                             
## [11] "digest"                           "rprojroot"                       
## [13] "futile.options"                   "backports"                       
## [15] "magrittr"                         "evaluate"                        
## [17] "stringi"                          "futile.logger"                   
## [19] "xts"                              "rmarkdown"                       
## [21] "lambda.r"                         "stringr"                         
## [23] "yaml"                             "htmltools"                       
## 
## 
## [[3]]
## An object of class "Workdir"
## Slot "path":
## [1] "/payload/"
## 
## 
## 
## Slot "cmd":
## An object of class "Cmd"
## Slot "exec":
## [1] "R"
## 
## Slot "params":
## [1] NA
</code></pre></div></div>

<p>The printout below shows the rendered Dockerfile. Its instructions
follow a pre-defined order:</p>

<ol>
  <li>define the base image</li>
  <li>define the maintainer label</li>
  <li>install system dependencies and external software</li>
  <li>install the R packages themselves</li>
  <li>set the working directory</li>
  <li>copy instructions and metadata labels (see examples in
later sections)</li>
  <li><code class="highlighter-rouge">CMD</code> instruction (final line) defines the default command when
running the container</li>
</ol>

<p>Note that the maintainer label as well as the R version of the base
image are detected from the runtime environment, if not set to different
values manually.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print(dockerfile_object)

FROM rocker/r-ver:3.4.0
LABEL maintainer="daniel"
RUN export DEBIAN_FRONTEND=noninteractive; apt-get -y update \
 &amp;&amp; apt-get install -y pandoc \
    pandoc-citeproc
RUN ["install2.r", "-r 'https://cloud.r-project.org'", "sp", "gstat", "knitr", "Rcpp", "intervals", "lattice", "FNN", "spacetime", "zoo", "digest", "rprojroot", "futile.options", "backports", "magrittr", "evaluate", "stringi", "futile.logger", "xts", "rmarkdown", "lambda.r", "stringr", "yaml", "htmltools"]
WORKDIR /payload/
CMD ["R"]
</code></pre></div></div>

<p>Instead of printing out to the console, you can also write to a file:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>write(dockerfile_object, file = tempfile(fileext = ".dockerfile"))

## INFO [2017-05-30 14:49:21] Writing dockerfile to /tmp/Rtmp25OKLi/file1a9726e56459.dockerfile
</code></pre></div></div>

<h5 id="23-packaging-an-external-session">2.3 Packaging an external session</h5>

<p>Packaging an interactive session has the disadvantage that unnecessary
dependencies might be added to the Dockerfile and subsequently to the
container. For instance the package <code class="highlighter-rouge">futile.logger</code> is a dependency of
<code class="highlighter-rouge">containerit</code>, and it will be added to the container because it was
loaded into the same session were the analyses was executed. It cannot
be removed by default, because other packages in the session <em>might</em> use
it as well (even unintentionally in case of generic methods). Therefore,
it is safer not to tamper with the current session, but to run the
analysis in an isolated <em>vanilla</em> session, which does not have
<code class="highlighter-rouge">containerit</code> in it. The latter will batch-execute the commands in a
seperate instance of R and retrieves an object of class <code class="highlighter-rouge">sessionInfo</code>.
The session info is then used as input to <code class="highlighter-rouge">dockerfile()</code>. This is also
how <code class="highlighter-rouge">dockerfile()</code> works internally when packaging either expressions,
scripts or R markdown files.</p>

<p>The following code creates a Dockerfile for a list of expressions in a
vanilla session.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>exp &lt;- c(expression(library(sp)),
         expression(data(meuse)), 
         expression(mean(meuse[["zinc"]])))
session &lt;- clean_session(exp, echo = TRUE)

## INFO [2017-05-30 14:49:21] Creating an R session with the following arguments:
##   R  --silent --vanilla -e "library(sp)" -e "data(meuse)" -e "mean(meuse[[\"zinc\"]])" -e "info &lt;- sessionInfo()" -e "save(list = \"info\", file = \"/tmp/Rtmp25OKLi/rdata-sessioninfo1a9714893e92\")"

dockerfile_object &lt;- dockerfile(from = session)

## INFO [2017-05-30 14:49:23] Trying to determine system requirements for the package(s) 'sp, lattice' from sysreq online DB
## INFO [2017-05-30 14:49:24] Adding CRAN packages: sp, lattice
## INFO [2017-05-30 14:49:24] Created Dockerfile-Object based on sessionInfo

print(dockerfile_object)

FROM rocker/r-ver:3.4.0
LABEL maintainer="daniel"
RUN ["install2.r", "-r 'https://cloud.r-project.org'", "sp", "lattice"]
WORKDIR /payload/
CMD ["R"]
</code></pre></div></div>

<h5 id="24-packaging-an-r-script">2.4 Packaging an R script</h5>

<p>R scripts are packaged by just supplying the file path or paths to the
arguement <code class="highlighter-rouge">from</code> of <code class="highlighter-rouge">dockerfile()</code>. They are automatically copied into
the container‚Äôs working directory. In order to run the R script on
start-up, rather than an interactive R session, a CMD instruction can be
added by providing the value of the helper function <code class="highlighter-rouge">CMD_Rscript()</code> as
an argument to <code class="highlighter-rouge">cmd</code>.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># create simple script file
scriptFile &lt;- tempfile(pattern = "containerit_", fileext = ".R")
writeLines(c('library(rgdal)',
             'nc &lt;- rgdal::readOGR(system.file("shapes/", package="maptools"), "sids", verbose = FALSE)',
             'proj4string(nc) &lt;- CRS("+proj=longlat +datum=NAD27")',
             'plot(nc)'), scriptFile)

# use a custom startup command
scriptCmd &lt;- CMD_Rscript(basename(scriptFile))

# create Dockerfile for the script
dockerfile_object &lt;- dockerfile(from = scriptFile, silent = TRUE, cmd = scriptCmd)

print(dockerfile_object)

FROM rocker/r-ver:3.4.0
LABEL maintainer="daniel"
RUN export DEBIAN_FRONTEND=noninteractive; apt-get -y update \
 &amp;&amp; apt-get install -y gdal-bin \
    libgdal-dev \
    libproj-dev
RUN ["install2.r", "-r 'https://cloud.r-project.org'", "rgdal", "sp", "lattice"]
WORKDIR /payload/
COPY [".", "."]
CMD ["R", "--vanilla", "-f", "containerit_1a977e2dcdea.R"]
</code></pre></div></div>

<h5 id="25-packaging-an-r-markdown-file">2.5 Packaging an R Markdown file</h5>

<p>Similarly to scripts, R Markdown files can be passed to the <code class="highlighter-rouge">from</code>
argument. In the following example, a vignette from the Simple Features
package <code class="highlighter-rouge">sf</code> is packaged in a container. To render the document at
startup, the Dockerfile‚Äôs <code class="highlighter-rouge">CMD</code> instruction must be changed. To do this,
the <code class="highlighter-rouge">cmd</code> argument passed to <code class="highlighter-rouge">dockerfile()</code> is constructed using the
function <code class="highlighter-rouge">CMD_Render</code>. Note that, as shown in the Dockerfile, the GDAL
library has to be build from source for <code class="highlighter-rouge">sf</code> to work properly, because a
quite recent version of GDAL is required. This adaptation of the
installation instruction is based on an internal ruleset for the package
<code class="highlighter-rouge">sf</code>.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>response &lt;- file.copy(from = system.file("doc/sf3.Rmd",package = "sf"),
                        to = temp_workspace, recursive = TRUE)
vignette &lt;- "sf3.Rmd"

dockerfile_object &lt;- dockerfile(from = vignette, silent = TRUE, cmd = CMD_Render(vignette))

## Loading required namespace: sf

print(dockerfile_object)

FROM rocker/r-ver:3.4.0
LABEL maintainer="daniel"
RUN export DEBIAN_FRONTEND=noninteractive; apt-get -y update \
 &amp;&amp; apt-get install -y gdal-bin \
    libgeos-dev \
    libproj-dev \
    libudunits2-dev \
    make \
    pandoc \
    pandoc-citeproc \
    wget
WORKDIR /tmp/gdal
RUN wget http://download.osgeo.org/gdal/2.1.3/gdal-2.1.3.tar.gz \
 &amp;&amp; tar zxf gdal-2.1.3.tar.gz \
 &amp;&amp; cd gdal-2.1.3 \
 &amp;&amp; ./configure \
 &amp;&amp; make \
 &amp;&amp; make install \
 &amp;&amp; ldconfig \
 &amp;&amp; rm -r /tmp/gdal
RUN ["install2.r", "-r 'https://cloud.r-project.org'", "dplyr", "sf", "Rcpp", "assertthat", "digest", "rprojroot", "R6", "DBI", "backports", "magrittr", "evaluate", "units", "rlang", "stringi", "rmarkdown", "udunits2", "stringr", "yaml", "htmltools", "knitr", "tibble"]
WORKDIR /payload/
COPY ["sf3.Rmd", "sf3.Rmd"]
CMD ["R", "--vanilla", "-e", "rmarkdown::render(\"sf3.Rmd\", output_format = rmarkdown::html_document())"]
</code></pre></div></div>

<h5 id="26-packaging-a-workspace-directory">2.6 Packaging a workspace directory</h5>

<p>A typical case expected to be interesting for <code class="highlighter-rouge">containerit</code> users is
packaging a local directory with a collection of data and code files. If
providing a directory path to the <code class="highlighter-rouge">dockerfile()</code> function, the package
searches for the first occurence of an R script, or otherwise the first
occurence of an R markdown file. It then proceeds to package this file
along with all other resources in the directory, as shown in the next
section.</p>

<h4 id="3-including-resources">3. Including resources</h4>

<p>Analyses in R often rely on external files and resources that are
located located in the workspace. When scripts or R markdown files are
packaged, they are copied by default into the same location relative to
the working directory. The argument <code class="highlighter-rouge">copy</code> influences how <code class="highlighter-rouge">dockefile()</code>
behaves in this matter. It can either have the values <code class="highlighter-rouge">script</code> (default
behaviour), <code class="highlighter-rouge">script_dir</code> (copies the complete directory in which the
input file is located), or a custom list of files and directories inside
the current working directory</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">response</span> <span class="p">&lt;-</span> <span class="n">file</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="k">from</span> <span class="p">=</span> <span class="nf">system</span><span class="p">.</span><span class="n">file</span><span class="p">(</span><span class="s2">"simple_test_script_resources/"</span><span class="p">,</span> 
                                         <span class="k">package</span> <span class="p">=</span> <span class="s2">"containerit"</span><span class="p">),</span>
                      <span class="k">to</span> <span class="p">=</span> <span class="n">temp_workspace</span><span class="p">,</span> <span class="n">recursive</span> <span class="p">=</span> <span class="nb">TRUE</span><span class="p">)</span>


<span class="n">dockerfile_object</span> <span class="p">&lt;-</span> <span class="n">dockerfile</span><span class="p">(</span><span class="s2">"simple_test_script_resources/"</span><span class="p">,</span>
              <span class="n">copy</span> <span class="p">=</span> <span class="s2">"script_dir"</span><span class="p">,</span>
              <span class="n">cmd</span> <span class="p">=</span> <span class="n">CMD_Rscript</span><span class="p">(</span><span class="s2">"simple_test_script_resources/simple_test.R"</span><span class="p">))</span>

<span class="n">print</span><span class="p">(</span><span class="n">dockerfile_object</span><span class="p">)</span>

<span class="k">FROM</span> <span class="n">rocker</span><span class="p">/</span><span class="n">r</span><span class="p">-</span><span class="n">ver</span><span class="p">:</span><span class="m">3.4.0</span>
<span class="n">LABEL</span> <span class="n">maintainer</span><span class="p">=</span><span class="s2">"daniel"</span>
<span class="n">WORKDIR</span> <span class="p">/</span><span class="n">payload</span><span class="p">/</span>
<span class="n">COPY</span> <span class="p">[</span><span class="s2">"simple_test_script_resources"</span><span class="p">,</span> <span class="s2">"simple_test_script_resources/"</span><span class="p">]</span>
<span class="n">CMD</span> <span class="p">[</span><span class="s2">"R"</span><span class="p">,</span> <span class="s2">"--vanilla"</span><span class="p">,</span> <span class="s2">"-f"</span><span class="p">,</span> <span class="s2">"simple_test_script_resources/simple_test.R"</span><span class="p">]</span>
</code></pre></div></div>

<p>Including R objects works similar to resources, using the argument
<code class="highlighter-rouge">save_image</code>. The argument can be set to <code class="highlighter-rouge">TRUE</code> to save <em>all</em> objects of
the current workspace to an .RData file, which is then copied to the
container‚Äôs working directory and loaded on startup (based on
<code class="highlighter-rouge">save.image()</code>).</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>df &lt;- dockerfile(save_image = TRUE)
print(df)

FROM rocker/r-ver:3.4.0
LABEL maintainer="daniel"
RUN export DEBIAN_FRONTEND=noninteractive; apt-get -y update \
 &amp;&amp; apt-get install -y gdal-bin \
    libgeos-dev \
    libproj-dev \
    libudunits2-dev \
    make \
    pandoc \
    pandoc-citeproc \
    wget
WORKDIR /tmp/gdal
RUN wget http://download.osgeo.org/gdal/2.1.3/gdal-2.1.3.tar.gz \
 &amp;&amp; tar zxf gdal-2.1.3.tar.gz \
 &amp;&amp; cd gdal-2.1.3 \
 &amp;&amp; ./configure \
 &amp;&amp; make \
 &amp;&amp; make install \
 &amp;&amp; ldconfig \
 &amp;&amp; rm -r /tmp/gdal
RUN ["install2.r", "-r 'https://cloud.r-project.org'", "sp", "gstat", "knitr", "Rcpp", "magrittr", "units", "lattice", "rjson", "FNN", "udunits2", "stringr", "xts", "DBI", "lambda.r", "futile.logger", "htmltools", "intervals", "yaml", "rprojroot", "digest", "sf", "futile.options", "evaluate", "rmarkdown", "stringi", "backports", "spacetime", "zoo"]
WORKDIR /payload/
COPY ["./.RData", "./"]
CMD ["R"]
</code></pre></div></div>

<p>Alternatively, a object names as well as other arguments can be passed
as a list, which then are passed to the <code class="highlighter-rouge">save()</code> function.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>require(fortunes)

## Loading required package: fortunes

rm(list = ls())
calculation &lt;- 41 + 1
frtn &lt;- fortunes::fortune()
original_sessionInfo &lt;- sessionInfo()

df &lt;- dockerfile(silent = TRUE,
                 save_image = list("original_sessionInfo", "frtn"))

print(df)

FROM rocker/r-ver:3.4.0
LABEL maintainer="daniel"
RUN export DEBIAN_FRONTEND=noninteractive; apt-get -y update \
 &amp;&amp; apt-get install -y gdal-bin \
    libgeos-dev \
    libproj-dev \
    libudunits2-dev \
    make \
    pandoc \
    pandoc-citeproc \
    wget
WORKDIR /tmp/gdal
RUN wget http://download.osgeo.org/gdal/2.1.3/gdal-2.1.3.tar.gz \
 &amp;&amp; tar zxf gdal-2.1.3.tar.gz \
 &amp;&amp; cd gdal-2.1.3 \
 &amp;&amp; ./configure \
 &amp;&amp; make \
 &amp;&amp; make install \
 &amp;&amp; ldconfig \
 &amp;&amp; rm -r /tmp/gdal
RUN ["install2.r", "-r 'https://cloud.r-project.org'", "fortunes", "sp", "gstat", "knitr", "Rcpp", "magrittr", "units", "lattice", "rjson", "FNN", "udunits2", "stringr", "xts", "DBI", "lambda.r", "futile.logger", "htmltools", "intervals", "yaml", "rprojroot", "digest", "sf", "futile.options", "evaluate", "rmarkdown", "stringi", "backports", "spacetime", "zoo"]
WORKDIR /payload/
COPY ["./payload.RData", "./payload.RData"]
CMD ["R"]
</code></pre></div></div>

<h4 id="4-image-metadata">4. Image metadata</h4>

<p>Metadata can be added to Docker images using <a href="https://docs.docker.com/engine/reference/builder/#label">Label
instructions</a>.
Label instructions are key-value pairs of arbitrary content. A dublicate
key overwrites existing ones. Although it is up to the user how many
labels are created, it is recommended to bundle them into one Label
instruction in the Dockerfile. Each use of the <code class="highlighter-rouge">Label()</code> function
creates a seperate instruction in the Dockerfile.</p>

<p>As shown in section 2, the maintainer label is set by default to the top
as the dockerfile and contains the username of the current host system.
The maintainer can be changed with the <code class="highlighter-rouge">maintainer</code> argument of
<code class="highlighter-rouge">dockerfile()</code>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>labeled_dockerfile &lt;- dockerfile(from = clean_session(), maintainer = "Jon_Doe@example.com")
</code></pre></div></div>

<p>Labels can be applied to the existing Dockerfile object using the
<code class="highlighter-rouge">addInstructions()</code> function, which adds any newly created instructions
to the end of the Dockerfile but before the CMD statement. The <code class="highlighter-rouge">Label()</code>
constructor can be used for creating labels of arbitrary content and
works similar to creating named lists in R.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># A simple label that occupies one line:
label1 &lt;- Label(key1 = "this", key2 = "that", otherKey = "content")
addInstruction(labeled_dockerfile) &lt;- label1

#label with fixed namespace for all keys
label2 &lt;- Label("name"="A name", "description" = "A description", label_ns = "my.label.ns.")

# A multiline label with one key/value pair per line
label3 &lt;- Label("info.o2r.name" = "myProject_ImageName", "org.label-schema.name"="ImageName", 
                "yet.another_labelname"="true", multi_line = TRUE)
addInstruction(labeled_dockerfile) &lt;- list(label2, label3)
</code></pre></div></div>

<p>Metadata according to the <a href="http://label-schema.org/rc1/">Label Schema</a>
conventions can be created with a function constructed by the helper
factory <code class="highlighter-rouge">LabelSchemaFactory()</code>.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Label_LabelSchema &lt;- LabelSchemaFactory()
label &lt;- Label_LabelSchema(name = "ImageName", description = "Description of the image", build_date = Sys.time())
addInstruction(labeled_dockerfile) &lt;- label
</code></pre></div></div>

<p>You can also put session information, using either base R or <code class="highlighter-rouge">devtools</code>,
into a label as plain text or as json:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>addInstruction(labeled_dockerfile) &lt;- Label_SessionInfo(session = clean_session())
addInstruction(labeled_dockerfile) &lt;- Label_SessionInfo(session = devtools::session_info(), as_json = TRUE)
</code></pre></div></div>

<p>The resulting Dockerfile with all the labels:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print(labeled_dockerfile)

FROM rocker/r-ver:3.4.0
LABEL maintainer="Jon_Doe@example.com"
WORKDIR /payload/
LABEL key1="this" key2="that" otherKey="content"
LABEL my.label.ns.name="A name" my.label.ns.description="A description"
LABEL info.o2r.name="myProject_ImageName" \
    org.label-schema.name="ImageName" \
    yet.another_labelname="true"
LABEL org.label-schema.schema-version="1.0.0-rc.1" \
    org.label-schema.build-date="2017-05-30T14:49:39+0200" \
    org.label-schema.name="ImageName" \
    org.label-schema.description="Description of the image"
LABEL R.session-info="R version 3.4.0 (2017-04-21)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 16.04.2 LTS\n\nMatrix products: default\nBLAS: /usr/lib/libblas/libblas.so.3.6.0\nLAPACK: /usr/lib/lapack/liblapack.so.3.6.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_GB.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n[1] compiler_3.4.0"
LABEL R.session-info="{\"platform\":{\"version\":\"R version 3.4.0 (2017-04-21)\",\"system\":\"x86_64, linux-gnu\",\"ui\":\"X11\",\"language\":\"en\",\"collate\":\"en_US.UTF-8\",\"tz\":\"Europe/Berlin\",\"date\":\"2017-05-30\"},\"packages\":{\"package\":[\"backports\",\"base\",\"compiler\",\"containerit\",\"datasets\",\"DBI\",\"devtools\",\"digest\",\"evaluate\",\"FNN\",\"fortunes\",\"futile.logger\",\"futile.options\",\"graphics\",\"grDevices\",\"grid\",\"gstat\",\"htmltools\",\"intervals\",\"knitr\",\"lambda.r\",\"lattice\",\"magrittr\",\"memoise\",\"methods\",\"Rcpp\",\"rjson\",\"rmarkdown\",\"rprojroot\",\"sf\",\"sp\",\"spacetime\",\"stats\",\"stringi\",\"stringr\",\"tools\",\"udunits2\",\"units\",\"utils\",\"withr\",\"xts\",\"yaml\",\"zoo\"],\"*\":[\"\",\"*\",\"\",\"*\",\"*\",\"\",\"\",\"\",\"\",\"\",\"*\",\"\",\"\",\"*\",\"*\",\"\",\"*\",\"\",\"\",\"*\",\"\",\"\",\"\",\"\",\"*\",\"\",\"\",\"\",\"\",\"\",\"*\",\"\",\"*\",\"\",\"\",\"\",\"\",\"\",\"*\",\"\",\"\",\"\",\"\"],\"version\":[\"1.0.5\",\"3.4.0\",\"3.4.0\",\"0.2.0\",\"3.4.0\",\"0.6-1\",\"1.13.1\",\"0.6.12\",\"0.10\",\"1.1\",\"1.5-4\",\"1.4.3\",\"1.0.0\",\"3.4.0\",\"3.4.0\",\"3.4.0\",\"1.1-5\",\"0.3.6\",\"0.15.1\",\"1.16\",\"1.1.9\",\"0.20-35\",\"1.5\",\"1.1.0\",\"3.4.0\",\"0.12.11\",\"0.2.15\",\"1.5\",\"1.2\",\"0.4-3\",\"1.2-4\",\"1.2-0\",\"3.4.0\",\"1.1.5\",\"1.2.0\",\"3.4.0\",\"0.13\",\"0.4-4\",\"3.4.0\",\"1.0.2\",\"0.9-7\",\"2.1.14\",\"1.8-0\"],\"date\":[\"2017-01-18\",\"2017-04-21\",\"2017-04-21\",\"2017-05-30\",\"2017-04-21\",\"2017-04-01\",\"2017-05-13\",\"2017-01-27\",\"2016-10-11\",\"2013-07-31\",\"2016-12-29\",\"2016-07-10\",\"2010-04-06\",\"2017-04-21\",\"2017-04-21\",\"2017-04-21\",\"2017-03-12\",\"2017-04-28\",\"2015-08-27\",\"2017-05-18\",\"2016-07-10\",\"2017-03-25\",\"2014-11-22\",\"2017-04-21\",\"2017-04-21\",\"2017-05-22\",\"2014-11-03\",\"2017-04-26\",\"2017-01-16\",\"2017-05-15\",\"2016-12-22\",\"2016-09-03\",\"2017-04-21\",\"2017-04-07\",\"2017-02-18\",\"2017-04-21\",\"2016-11-17\",\"2017-04-20\",\"2017-04-21\",\"2016-06-20\",\"2014-01-02\",\"2016-11-12\",\"2017-04-12\"],\"source\":[\"CRAN (R 3.4.0)\",\"local\",\"local\",\"local\",\"local\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"local\",\"local\",\"local\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"cran (@1.16)\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.3.3)\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"local\",\"cran (@0.12.11)\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"local\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"local\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"local\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\",\"CRAN (R 3.4.0)\"]}}"
CMD ["R"]
</code></pre></div></div>

<h4 id="5-further-customization">5. Further customization</h4>

<p>The <code class="highlighter-rouge">dockerfile()</code> function allows further customization regarding the R
version or the used base image (cf. Rocker stack). Note that while
choosing an R version for the Dockerfile explicitly is possible, the
session to generate the required information (i.e. which packages are
attached etc.) is still running the R version of the generating machine.</p>

<p>The following examples show usage of these options and the respective
<code class="highlighter-rouge">FROM</code> statements in the Dockerfile.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>df_custom &lt;- dockerfile(from = NULL, r_version = "3.1.0", silent = TRUE)
print(df_custom@image)

FROM rocker/r-ver:3.1.0

df_custom &lt;- dockerfile(from = NULL, image = "rocker/geospatial", silent = TRUE)
print(df_custom@image)

FROM rocker/geospatial

df_custom &lt;- dockerfile(from = NULL, image = "rocker/verse:3.0.0", silent = TRUE)@image
print(df_custom@image)

[1] "rocker/verse"
</code></pre></div></div>

<h4 id="6-cli">6. CLI</h4>

<p>A command line interface to the package functions is also available for
Linux based on <a href="https://github.com/docopt/docopt.R">docopt.R</a>. This
allows integration into workflows and tools written in other programming
languages than R.</p>

<p>You can make the command <code class="highlighter-rouge">containerit</code> available on your maching by
linking the R script file delivered with the package as follows:</p>

<p><code class="highlighter-rouge">ln -s $(Rscript -e "cat(system.file(\"cli/container_it.R\", package=\"containerit\"))") /usr/local/bin/containerit</code></p>

<p>CLI Examples:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  containerit --help
  
  # runs the first R markdown or R script file locally 
  # prints Dockerfile without writing a file
  containerit dir -p --no-write  
  
  # Packages R-script 
  # saves a workspace image (-i parameter)
  # Writes Dockerfile (overwrite with -f)
  # execute the script on start-up
  containerit file -ifp --cmd-R-file path/example.R

  # Creates an empty R session with the given R commands
  # Set R version of the container to 3.3.0
  containerit session -p -e "library(sp)" -e "demo(meuse, ask=FALSE)" --r_version 3.3.0
</code></pre></div></div>

<h4 id="7-challenges">7. Challenges</h4>

<p>We encountered several challenges during <code class="highlighter-rouge">containerit</code>‚Äôs development.
First and foremost, a well known limitation is that R packages don‚Äôt
define system dependencies and do not provide explicit versions for R
package dependencies. The <code class="highlighter-rouge">sysreqs</code> package is a promising approach
towards handling system requirements, but so far lists package names but
does not provide version information. The
<a href="https://github.com/rstudio/shinyapps-package-dependencies">shinyapps-package-dependencies</a>
demonstrate a (currently system dependent) alternative. The high value
of R might well lie in the fact that ‚Äúpackages currently on CRAN‚Äù should
work well with each other.</p>

<p>An unmet challenge so far is the installation of specific versions of
external libraries (see
<a href="https://github.com/o2r-project/containerit/issues/46">issue</a>). A
package like <code class="highlighter-rouge">sf</code> relies on well-tested and powerful system libraries,
see <code class="highlighter-rouge">sf::sf_extSoftVersion()</code>, which ideally should be matched in the
created container.</p>

<p>And of course users may do things that <code class="highlighter-rouge">containerit</code> cannot capture from
the session state ‚Äúafter the analysis is completed‚Äù, such as detaching
packages or removing relevant files, and unknown side-effects might
occur.</p>

<p>All software is presumed to be installed and run on the host system.
Although it is possible to use deviating versions of R or even create
Dockerfiles using sessionInfo-objects created on a different host, this
may lead to unexpected errors because the setup cannot be tested
locally.</p>

<h4 id="8-conclusions-and-future-work">8. Conclusions and future work</h4>

<p><code class="highlighter-rouge">containerit</code> alows to create and costumize Dockerfiles with minimal
effort, which are suitable for packaging R analyses in the persistant
runtime environment of a software container. So far, we were able to
reproduce complete R sessions regarding loaded and attached packages and
mitigate some challenges towards reproducible computational research.</p>

<p>Although we are able to package different versions of R, we still do not
fully support the installation of specific versions of R packages and
external software libraries, which R itself does not support. This
should be tested in the future by evaluating version-stable package
repositories like MRAN and GRAN or utility packages such as packrat ‚Äì
see the <a href="https://github.com/o2r-project/containerit/issues/new">GitHub
issues</a> for the
status of these plans or provide your own ideas there.</p>

<p>Related to installing specific versions is support for other package
repositories, such as Bioconductor, git, BitBucket, or even local files.
For now, it is recommended that users have all software up-to-date when
building a software container, as the latest version are installed from
CRAN during the image build, to have matching package versions between
the creation runtime environment and the container. All Dockerfiles and
instructions are adjusted to the Rocker image stack and assume a
Debian/Linux operating system. As we are not yet supporting the build of
Docker images from scratch, we are restricted to this setup.</p>

<p>The package is a first prototype available via GitHub. While a
publication on CRAN is a goal, it should be preceded by feedback from
the user community and ideally be accompanied by related packages, such
as <a href="https://github.com/wch/harbor/issues/5">harbor</a>, being available on
CRAN, too. The prototype of <code class="highlighter-rouge">containerit</code> was developed and tested only
on Ubuntu/Linux, which should be extended before releasing a stable
version on CRAN.</p>

<p>As part of the o2r project, it is planned to integrate <code class="highlighter-rouge">containerit</code> in
a <a href="https://o2r.info/architecture">web service</a> for creating archivable
research in form of <a href="https://doi.org/10.1045/january2017-nuest">Executable Research Compendia
(ERC)</a>. Making <code class="highlighter-rouge">containerit</code>
itself easier to use for end-users is a secondary but worthwhile goal, for example by
building a graphical user interface for metadata creation. Country
locales are also not supported yet. We may want to support other
container OS (e.g. windows container or other Linux distributions) or
even containerization solutions such as
<a href="http://singularity.lbl.gov/">Singularity</a> or the <a href="https://www.opencontainers.org/">Open Container
Initiative</a>‚Äôs (OCI) <a href="https://github.com/opencontainers/image-spec">Image
Format</a>.</p>

<p>Feedback and contributions are highly welcome <a href="https://github.com/o2r-project/containerit/issues">on
GitHub</a> or
<a href="https://twitter.com/o2r_project">o2r_project</a> on Twitter.</p>

<h4 id="metadata">Metadata</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sessionInfo()

## R version 3.4.0 (2017-04-21)
## Platform: x86_64-pc-linux-gnu (64-bit)
## Running under: Ubuntu 16.04.2 LTS
## 
## Matrix products: default
## BLAS: /usr/lib/libblas/libblas.so.3.6.0
## LAPACK: /usr/lib/lapack/liblapack.so.3.6.0
## 
## locale:
##  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
##  [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_US.UTF-8    
##  [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_US.UTF-8   
##  [7] LC_PAPER=en_GB.UTF-8       LC_NAME=C                 
##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C       
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] fortunes_1.5-4    sp_1.2-4          gstat_1.1-5       containerit_0.2.0
## [5] knitr_1.16       
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_0.12.11         rstudioapi_0.6       magrittr_1.5        
##  [4] devtools_1.13.1      units_0.4-4          lattice_0.20-35     
##  [7] rjson_0.2.15         FNN_1.1              udunits2_0.13       
## [10] stringr_1.2.0        tools_3.4.0          xts_0.9-7           
## [13] grid_3.4.0           DBI_0.6-1            withr_1.0.2         
## [16] lambda.r_1.1.9       futile.logger_1.4.3  htmltools_0.3.6     
## [19] intervals_0.15.1     yaml_2.1.14          rprojroot_1.2       
## [22] digest_0.6.12        sf_0.4-3             futile.options_1.0.0
## [25] memoise_1.1.0        evaluate_0.10        rmarkdown_1.5       
## [28] stringi_1.1.5        compiler_3.4.0       backports_1.0.5     
## [31] spacetime_1.2-0      zoo_1.8-0
</code></pre></div></div>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2017/05/17/2nd-workshop-external-partners/">State of the project and next steps</a></h3>
<span class="post-date">17 May 2017 | By Daniel N√ºst, Markus Konkol, Marc Schutzeichel</span>
<p>Yesterday the <a href="/about">o2r team</a> met <a href="/2016/06/07/workshop-external-partners/">for the second time</a> with a group of experts to request feedback on the state of the project.</p>

<p><img src="/public/images/2017-05_o2r-workshop.jpg" alt="workshop participants" title="o2r external partner workshop participants. image license: CC BY-NC-ND" width="500" /></p>
<p class="attributionInlineImage">Image is licensed under a <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" title="Creative Commons Attribution Non-Commercial No-Derivatives 4.0 International License">CC BY-NC-ND 4.0 International</a> license.</p>

<p>Thanks to the valuable questions and comments by our external partners, the project tasks were assessed and refocussed. On top of it, we agreed to collaborate even further and sketched first ideas for putting o2r‚Äôs prototypes into real-world settings.</p>

<p>This workshop <!--more-->was only possible thanks to our partner‚Äôs commitment, enthusiasm, and continued interest in the project. Our heartfelt thanks go to</p>

<ul>
  <li><a href="https://twitter.com/xeniavanedig">Xenia van Edig</a>, Business Development Manager, <a href="http://www.copernicus.org/about_us.html">Copernicus Publications</a>,</li>
  <li><a href="https://www.linkedin.com/in/maarten-cleeren-3bb39032/">Maarten Cleeren</a>, Director of Product Management, Enriched Content at <a href="https://www.elsevier.com/">Elsevier</a>, and</li>
  <li><a href="https://twitter.com/LinkedScience">Tomi Kauppinen</a> from the <a href="http://cs.aalto.fi/en/">Department of Computer Science at Aalto University</a></li>
</ul>

<p>As last year, the full day meeting took place in the countryside at the lovely Wersehaus. Unlike last year, we skipped lightning talks and profited from the existing understanding of the project. Instead we dove right into the project‚Äôs significant progress: survey results which motivated our design decisions, a critical view on the project schedule and completed/open tasks, the <a href="https://o2r.info/erc-spec">specification for executable research compendia (ERC)</a>, our <a href="https://o2r.info/architecture/">architecture</a>, the <a href="https://o2r.info/api/">API</a>, and most importantly the Open Source <a href="https://github.com/o2r-project">reference implementation</a> and its integration with <a href="http://sciebo.de/">Sciebo</a> and <a href="http://zenodo.org/">Zenodo</a>.</p>

<p>Just as intented these topics were merely started as presentations and led to an active discussion. They were evaluated and connected to the partners perspectives, not the least by putting more ambitious goals (<em>‚Äúlet‚Äôs completely change the way scholarly publishing works!‚Äù</em>) into perspective and defining concrete steps ahead to (i) spread understanding of reproducible research, and (ii) show the potential for enhancements by computational reproducibility with ERC. Many valuable insights will keep the o2r team busy in the following weeks.</p>

<p>In the <a href="/2016/06/07/workshop-external-partners/">blog post of the first workshop</a>, we included some statements on <em>what will we understand in two years time that we do not know now?</em>, and here is the original (left) and updated version:</p>

<div style="font-size: 90%">
<table>
  <tr>
    <td><i>We have a good understanding of how far the process of creating research compendia can be automated, and what efforts remain for authors or preservationists that must be counterbalanced with incentives.</i></td>
    <td>Our understanding is consolidated in specifications, in well-defined user workflows, and is demonstrated by a reference implementation. On the topic of incentives, the need for a cultural change (_"it takes a generation"_) was re-stated at the workshop but we can better communicate o2r's actual contributions.</td>
  </tr>
  <tr>
    <td><i>We know the potential of user interface bindings as the connecting entity of research compendia.</i></td>
    <td>By conducting a survey and interviews with geoscientists, we identified promising use cases for UI bindings. e.g. change an analysis variable and update a diagram. The conceptual description (an ontology) underlying these use cases is in progress. It is an open question if we can realise a generic solution to generate UI bindings automatically, and how much effort by the author is required.</td>
  </tr>
  <tr>
    <td><i>We show the improvements in discovery and understanding of research when all aspects of research are explicitly linked in a meaningful way.</i></td>
    <td>Thanks to feedback by last year's workshop and continued interaction with other researchers at conferences and workshops, we decided to concentrate on these challenging topics first: easily packaging research into ERC, integrating with data repositories, and interacting with ERC. Therefore discovery is a topic for the second half of 2017, including a recently started master thesis.</td>
  </tr>
  <tr>
    <td><i>We get to know the common language as well as points of contact for the involved parties as we create a closer connection between research, preservation, and publication communities.</i></td>
    <td>Success! The prototypes are received well by all of the parties. They provide unifying concepts and workflows and are even seen as ready for pilot studies.</td>
  </tr>
</table>
</div>

<p>We hope to have another inspirational meeting like this in 2018! To keep in touch, follow us on <a href="https://twitter.com/o2r_project">Twitter</a> or <a href="https://github.com/o2r-project">GitHub</a>.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2017/05/10/o2r-at-AGILE/">Opening Reproducible Research at AGILE 2017 conference in Wageningen</a></h3>
<span class="post-date">10 May 2017 | By Daniel N√ºst</span>
<p>This week o2r participates in another conference, which is partly a repetition but also a contrast to the last one:</p>

<p><em>Again</em>, o2r team members (<a href="https://orcid.org/0000-0001-6651-0976">Markus</a> and <a href="https://orcid.org/0000-0002-0024-5046">Daniel</a>) are fortunate to co-organize a workshop about reproducible research: <a href="/agile-2017/">‚ÄúReproducible Geosciences Discussion Forum‚Äù</a> at the <a href="https://agile-online.org/index.php/home-2017">20th AGILE International Conference on Geographic Information Science</a> in Wageningen, The Netherlands, took place yesterday. <strong>Read the short recap on the <a href="/agile-2017/">workshop website</a></strong>.</p>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Thx! Fun, educational &amp; productive workshop today on <a href="https://twitter.com/hashtag/reproducible?src=hash">#reproducible</a> <a href="https://twitter.com/hashtag/geosciences?src=hash">#geosciences</a> at <a href="https://twitter.com/hashtag/agilewag2017?src=hash">#agilewag2017</a> <a href="https://twitter.com/hashtag/agile2017nl?src=hash">#agile2017nl</a> Report soon via <a href="https://twitter.com/o2r_project">@o2r_project</a> <a href="https://t.co/MjrWPQyoQ2">pic.twitter.com/MjrWPQyoQ2</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/861966842373472256">May 9, 2017</a></blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Daniel will also present<!--more--> a poster on o2r titled <em>‚ÄúAn Architecture for Reproducible Computational Geosciences‚Äù</em>. <strong>Please visit the AGILE 2017 poster session tomorrow at 15:00</strong> and discuss with us how our <a href="https://doi.org/10.1045/january2017-nuest">ERC</a> fits into the geosciences landscape.</p>

<p><span style="color: red; font-wight: bold;">Update:</span> Download the <a href="https://agile-online.org/images/conference_2017/Proceedings2017/posters/108_PosterAbstract_in_PDF.pdf">abstract</a> and the <a href="https://doi.org/10.5281/zenodo.1478542">poster</a>.</p>

<p><img src="https://agile-online.org/images/stories/banner/AGILE2017-Wageningen.png" alt="agile conference banner" width="500" /></p>
<p class="attributionInlineImage">Image courtesy of AGILE website.</p>

<p><em>Completely different</em> is the scale of this weeks conference: unlike <a href="/2017/05/03/2017_o2r-at-EGU/">EGU general assembly</a>, AGILE is a small conference with an informal feeling. While the attendees represent diverse topics, the common connection to GI Science is strong and while the programme is packed at times (5 parallel tracks - hard to choose!), there is ample room to focus, for example in the single track keynote or poster sessions, but also to chat and learn, which we hope to do by spreading questions on reproducibility of the works presented at AGILE.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2017/05/04/o2r-at-EGU/">Opening Reproducible Research at EGU General Assembly 2017</a></h3>
<span class="post-date">04 May 2017 | By Daniel N√ºst</span>
<p><img src="http://blogs.egu.eu/geolog/files/2017/04/EGU-17-700x400.jpg" alt="EGU logo" title="European Geophysical Union General Assembly 2017" width="300" class="img rightfloat" /></p>

<p>Last week the largest European geosciences conference of the year took place in Vienna: the <a href="http://www.egu2017.eu/" title="EGU General Assembly 2017 Website">European Geophysical Union General Assembly 2017</a>.</p>

<p>o2r took part by co-organising a <a href="/2017/05/03/egu-short-course-recap/">workshop on reproducible research</a> and co-convening the session <a href="http://meetingorganizer.copernicus.org/EGU2017/session/23924" title="poster session description"><em>IE2.4/ESSI3.10 Open Data, Reproducible Research, and Open Science</em></a>.</p>

<p>o2r team member <a href="https://orcid.org/0000-0002-0024-5046">Daniel N√ºst</a> presented the abstract <a href="http://meetingorganizer.copernicus.org/EGU2017/EGU2017-7215.pdf" title="abstract PDF download"><em>‚ÄúExecutable research compendia in geoscience research infrastructures‚Äù</em></a> (<a href="http://presentations.copernicus.org/EGU2017-7215_presentation.pdf" title="poster PDF download">download poster</a>) and supported <a href="https://orcid.org/0000-0001-5281-3896">Marius Appel</a> and <a href="http://orcid.org/0000-0001-8049-7069">Edzer Pebesma</a> in their work on <a href="http://meetingorganizer.copernicus.org/EGU2017/EGU2017-8525.pdf" title="abstract PDF download"><em>‚ÄúReproducible Earth observation analytics: challenges, ideas, and a study case on containerized land use change detection‚Äù</em></a> (<a href="http://presentations.copernicus.org/EGU2017-8525_presentation.pdf" title="poster PDF download">download poster</a>) in the ESSI3.10‚Äôs poster session.</p>

<p>It was a great experience to<!--more-->meet fellow scientists interested in, and worried about, reproducibility of scholarly works.
We got useful feedback on our practical work and are encouraged again to continue spreading the word on the general topic of reproducibility alongside our research.</p>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Poster in EGU17 final session is ready for business. Come to X4.123 at 17:00 and talk <a href="https://twitter.com/hashtag/openscience?src=hash">#openscience</a> <a href="https://twitter.com/hashtag/reproduciblersearch?src=hash">#reproduciblersearch</a> Survey going well! <a href="https://t.co/at2eem44Md">pic.twitter.com/at2eem44Md</a></p>&mdash; o2r (@o2r_project) <a href="https://twitter.com/o2r_project/status/857962352196681728">April 28, 2017</a></blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>


</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2017/05/03/egu-short-course-recap/">Reproducible Research at EGU GA - A short course recap</a></h3>
<span class="post-date">03 May 2017 | By Daniel N√ºst, Vicky Steeves, R√©mi Rampin</span>
<p>At last week‚Äôs <a href="http://egu2017.eu/">EGU general assembly</a> members of the <a href="https://o2r.info">o2r</a> and <a href="https://reprozip.org/">ReproZip</a> projects organized the short course <a href="http://meetingorganizer.copernicus.org/EGU2017/session/25726"><em>‚ÄúReproducible computational research in the publication cycle‚Äù</em></a>. This post is a recap of the course by <a href="http://danielnuest.de/">Daniel N√ºst</a>, <a href="https://vickysteeves.com/">Vicky Steeves</a>, and <a href="https://remirampin.com/">R√©mi Rampin</a>.</p>

<p><img src="/public/images/2017-05_egu-01.jpg" alt="short course room photo" title="Ready to start - the short course room filling up" width="300" class="img rightfloat" /></p>

<p>All <strong>materials for the course are published in an Open Science Framework repository at <a href="https://osf.io/umy6g/">https://osf.io/umy6g/</a></strong> and you can learn about the motivation for the course in the <a href="http://meetingorganizer.copernicus.org/EGU2017/session/25726">course page at EGU</a>.</p>

<p>The short was divided into two parts:<!--more--> a practical introduction to selected tools supporting computational reproducibility, and talks by stakeholders in the scientific publication process followed by a lively panel discussion.</p>

<p><strong>In the first part</strong>, Daniel and Vicky began with sharing some literature on reproducible research (RR) with the roughly 30 participants. After all, the participants should take home something useful, so a reading list seems reasonable for RR newcomers but also for researchers writing about the reproducibility aspects in upcoming papers.</p>

<p>Then Daniel fired up a console and took a deep dive into <strong>using containers to encapsulate environments for reproducible computational research</strong>. He started with a very quick introduction to Docker and then demonstrated some containers useful to researchers, i.e. Jupyter Notebook and RStudio.</p>

<p>The material presented by Daniel is a <a href="https://nuest.github.io/docker-reproducible-research/">starting point for an Author Carpentry lesson</a>, which is currently <a href="https://github.com/nuest/docker-reproducible-research">developed on GitHub</a>, so he highly appreciates any feedback, especially by shourt course attendees. We were surprised to learn a good portion of the participants had already some experience with Docker. But even better was realizing a few actually hacked along as Daniel raced through command-line interface examples! This ‚Äúraw‚Äù approach to packaging research in containers was contrasted in the second section.</p>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">.<a href="https://twitter.com/nordholmen">@nordholmen</a> forked author carpentry to make a lesson for us today! About to look at rstudio &amp; jupyter notebooks w/ Docker!  <a href="https://twitter.com/hashtag/egu2017?src=hash">#egu2017</a> <a href="https://t.co/ekgYuJPkS6">pic.twitter.com/ekgYuJPkS6</a></p>&mdash; Vicky Steeves (@VickySteeves) <a href="https://twitter.com/VickySteeves/status/856475174165721088">April 24, 2017</a></blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Under the title <strong>‚ÄúReproZip for geospatial analyses‚Äù</strong>, Vicky and R√©mi showcased <a href="https://reprozip.org">ReproZip</a>, a tool for automatically tracing and packaging scientific analyses for easily achieved computational reproducibility. The resulting file is a ReproZip package (<code class="highlighter-rouge">.rpz</code>), which can be easily shared due to it‚Äôs small size, and contains everything necessary to reproduce research (input files, environmental information etc.) across different operating systems. They demonstrated their various unpackers and showed how these <code class="highlighter-rouge">.rpz</code> files can be used for reproducibility and archiving. They also demoed they brand new user interface for the first time in Europe.</p>

<p>The materials presented by Vicky and R√©mi are also available on both the Open Science Framework <a href="https://osf.io/umy6g/">here</a> and on the <a href="https://examples.reprozip.org">ReproZip examples website</a>.</p>

<blockquote class="twitter-tweet" data-conversation="none" data-lang="en"><p lang="en" dir="ltr"><a href="https://twitter.com/edzerpebesma">@edzerpebesma</a> <a href="https://twitter.com/benmarwick">@benmarwick</a> <a href="https://twitter.com/o2r_project">@o2r_project</a> And <a href="https://twitter.com/VickySteeves">@VickySteeves</a>  and  <a href="https://twitter.com/remram44">@remram44</a> showing <a href="https://twitter.com/hashtag/reprozip?src=hash">#reprozip</a> <a href="https://t.co/4hxpEsmqPN">pic.twitter.com/4hxpEsmqPN</a></p>&mdash; Daniel N√ºst (@nordholmen) <a href="https://twitter.com/nordholmen/status/856488328190930944">April 24, 2017</a></blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>The practical demonstrations paved the way for the <strong>second part</strong> of the short course, which was more abstract yet proofed to excellently demonstrate the breadth of reproducible research. Selected speakers provided their perspectives on the topic of reproducing scientific papers in the broader context of the scientific publication cycle. In short talks they wore a specific role of the scholarly publication process and shared their experience as as researcher, infrastructure provider, publisher, reviewer, librarian, or editor. The speakers:</p>

<ul>
  <li><a href="https://orcid.org/0000-0001-8049-7069">Edzer Pebesma</a> talked about his experiences as journal editor for <a href="http://jstatsoft.org/">JStatSoft</a> as well as <a href="http://www.journals.elsevier.com/computers-and-geosciences/">Computers &amp; Geosciences</a>, and his original motivation to enter the area of reproducible research with <a href="http://pebesma.staff.ifgi.de/epic.pdf">his prize-winning ‚Äúone-click reproduce‚Äù concept</a> and initiator of <a href="https://o2r.info">o2r</a>: annoyance by not being able to share the full integrated material of his works easily.</li>
  <li><a href="https://www.dkrz.de/about/Organisation/mitarbeiter/TobiasWeigel">Tobias Weigel</a> from the <a href="https://www.dkrz.de/dkrz-en?set_language=en&amp;cl=en">german national climate computing center</a> introduced the challenges and limitations for a supercomputer facility which provides crucial resources for reproducibility.</li>
  <li><a href="https://orcid.org/0000-0001-9545-9110">David Ham</a> shared the priorities of the <a href="http://www.geoscientific-model-development.net/">journal Geoscientific Model Development (GMD)</a> where he is editor, when it comes to reproducibility and the issues they face. Proper provenance and citations are examples for the former, the ephemerality of code and data for the latter.</li>
  <li><a href="https://orcid.org/0000-0003-2510-0529">Xenia van Edig</a> lead us through the stages of Open Access that <a href="http://publications.copernicus.org/">Copernicus</a> went and is going through as a publisher: from public data (1.0) via interactive articles and public peer review (2.0) to the future of open science and executable papers (3.0)</li>
  <li><a href="http://vickysteeves.com/">Vicky Steeves</a> advertised the expertise of librarians worldwide in supporting research in all aspects, including reproducibility, writing grants, or data management plans, but also pointed out the necessity to support scientists with proper tools and teach the required skills.</li>
  <li><a href="http://danielnuest.de/">Daniel N√ºst</a> (research software engineer perspective)</li>
</ul>

<p><img src="/public/images/2017-05_egu-01.jpg" alt="short course discussion panel" title="panel discussion photo" width="300" class="img rightfloat" /></p>

<p>All speakers touched on the topic of <em>scientific culture</em>, which was seen in a process of changing towards more openness, but with still quite some way to go. The cultural aspects and larger scale challenges were a recurring topic in the panel discussion after the short talks. These aspects included resistance to share supplemental material, so that journals cannot make sharing everything mandatory, for example because of unwillingness (fear of stealing) or because authors might not be allowed to do so. A member of the audience could share that in their experience as a publisher, requiring data and software publication did not result in a decrease in submissions when accompanied by transparent and helpful author guidelines. Such guidelines for both data and code are lacking for many journals but are a means to improve the overall situation - and make the lives of editors simpler.
When the progress of the last years on Open <em>Data</em> was pointed out as largely a top down political endeavour, the contrast to <em>Open Source</em> as a bottom-up grassroots initiative became clear. Nevertheless, the hope was phrased that with the success of Open Data, things might go smoother with Open Source in science.</p>

<p>A further topic the discussion covered for some time was <em>creditation</em>, and the need to update the ways researchers get <em>and give</em> credit as part of grant-based funding and publishing scholarly articles. Though it was pointed out that RR is also about ‚Äúdoing the right thing‚Äù. Credit and culture were seen as closely linked topics, which can only be tackled by improving the education of scientists, both as authors and reviewers(!), and spreading the word about the importance of reproducibility for all of science, not least in the light of the marches for sciences taking place just a few days before the short course.</p>

<p>While one could say we were mostly preaching to the choir, it was great to see an interest in the topic of reproducible research amongst EGU attendees. <strong>This workshop being the first of its kind at the EGU general assembly hopefully was a step towards even higher visibility and interest for RR as a crucial topic in today‚Äôs research.</strong></p>

<p>We thank the short course attendees and invited speakers for turning the first afternoon of EGU 2017 into an instructive and diverting few hours. <em>Will there be a reproducible research short course next year at EGU?</em> We don‚Äôt know yet, but please do get in touch if you would like to support the planning. It could be worth providing a longer course targeted as <a href="http://www.egu.eu/ecs/">early career scientists</a>, giving the <a href="https://deevybee.blogspot.de/2017/05/reproducible-practices-are-future-for.html">next generation</a> the tools to work reproducibly.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2017/03/30/remote-sensing-article-published/">Docker for GEOBIA - new article published</a></h3>
<span class="post-date">30 Mar 2017 | By Daniel N√ºst</span>
<p><a href="http://dx.doi.org/10.3390/rs9030290"><img src="/public/images/2017-03_rs-article.jpg" alt="article cover screenshot" title="screenshot of article at Remote Sensing journal" width="300" class="img rightfloat" /></a></p>

<p>We are happy to announce that o2r team member <a href="https://orcid.org/0000-0002-0024-5046">Daniel</a> published a new article together with <a href="https://orcid.org/0000-0003-0797-7853">Christian Knoth</a> in the journal Remote Sensing. The special issue <a href="http://www.mdpi.com/journal/remotesensing/special_issues/GEOBIA2016">‚ÄúAdvances in Object-Based Image Analysis‚ÄîLinking with Computer Vision and Machine Learning‚Äù</a> comprising six papers was published in connection with the 6th <a href="https://www.geobia2016.com/">GEOBIA conference (2016)</a>, where Daniel and Christian‚Äôs work was previously honoured with the best student paper award.</p>

<p>The article <strong>Reproducibility and Practical Adoption of GEOBIA with Open-Source Software in Docker Containers</strong> is available as Open Access: <strong><a href="http://dx.doi.org/10.3390/rs9030290">doi:10.3390/rs9030290</a></strong></p>

<script type="text/javascript" src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>

<div data-badge-popover="right" data-badge-type="donut" data-doi="10.3390/rs9030290" class="altmetric-embed" style="float:left; margin: 0.5em 1em 0 0"></div>
<p>Knoth, C., N√ºst, D., 2017. Reproducibility and Practical Adoption of GEOBIA with Open-Source Software in Docker Containers. Remote Sensing 9, 290. doi:10.3390/rs9030290</p>

<div style="clear: both;"></div>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2017/03/24/open-science-conference/">o2r @ Open Science Conference 2017, Berlin</a></h3>
<span class="post-date">24 Mar 2017 | By Markus Konkol</span>
<p><img src="https://www.open-science-conference.eu/wp-content/themes/science20/images/banner_2017.png" alt="open science conference banner" width="500" /></p>
<div style="font-size: 0.6em; color: rgba(67,69,83,1); margin: -1em 0 1em 0; padding: 0;">Foto: open-science-conference.eu</div>

<p>Due to the overall topic of our project, we felt the <a href="https://www.open-science-conference.eu/">Open Science Conference</a> (<a href="http://twitter.com/search?q=%23osc2017">#osc2017</a>) taking place this week in Berlin would be a great chance to share our ideas and meet like-minded folks. We were happy about the notification that our poster was accepted and even made it into the top ten (of altogether 57 submissions), which allowed o2r team member Markus to give a three-minute <a href="https://www.open-science-conference.eu/wp-content/uploads/2016/02/04_Talk.pdf">lightning talk</a> and present a project <a href="https://www.open-science-conference.eu/wp-content/uploads/2017/03/04_Poster.pdf">poster</a>. Both days included interesting talks given by international speakers (see <a href="https://www.open-science-conference.eu/programme/">full programme</a>) and in this post Markus reports on the trip.
<!--more-->
The first day covered several topics related to o2r, for example, data infrastructures (see <a href="https://ec.europa.eu/research/openscience/index.cfm?pg=open-science-cloud">European Open Science Cloud</a>). Speakers also mentioned social challenges such as a new reward system and incentives required to motivate scientists to conduct Open Science ‚Äì a key issue in the Executable Research Compendium-concept as well. In times of <em>fake news</em> and the <em>credibility crisis</em>, <a href="https://www.open-science-conference.eu/">keynote</a> speaker Prof. Johannes Vogel strongly encouraged in his opening talk to set a good example in the field of Open Science and convincingly put scientists in charge of the issue.</p>

<p>A few people I talked to liked the idea of making the dataset the actual publication and the paper being ‚Äúonly‚Äù the supplementary material. It might be interesting to play around with some thoughts on that: Will institutes focus on publishing datasets instead of papers? Is ‚Äúdata collector‚Äù a new job title?</p>

<p>The lightning talks and the poster session were a success. Several visitors were keen to ask questions and to get explanations on technical and conceptual details. I hope that I was able to answer all of them in sufficient detail. If you think I didn‚Äôt, please don‚Äôt hesitate to ask me or in case of doubts, my colleagues Docker Daniel and Metadata Marc. You should also take a look at <a href="http://conquaire.uni-bielefeld.de/">Conquaire</a>, an interesting project in the context of reproducible research.</p>

<p>One highlight was a visit by <a href="http://www.openscienceradio.de/">Open Science Radio</a>, who also published <a href="http://www.openscienceradio.de/2017/03/22/osr079-opening-reproducible-research-poster-session-osc2017-en/">a short interview on opening reproducible research</a>.</p>

<p>In the evening, we had a wonderful dinner next to dinosaurs (I am not talking about the scientists üòâ) organized by <a href="https://www.naturkundemuseum.berlin/">Museum f√ºr Naturkunde Berlin</a>, a museum of natural science. In this impressive atmosphere, we were able to network a bit and to continue discussions.</p>

<p>The second day was rather education-driven. However, we do also want to enhance and extend the understanding of scientists when examining a paper by using our ERC. Why not addressing students, too? We still dream of a reproducible and interactive atlas.</p>

<p>It was interesting to see that the great majority of guests and speakers focused on open data when discussing challenges in Open Science. Mentioning source-code was rather the exception although reproducibility was perceived as being part of Open Science. For this reason, I think that our contribution to the conference was relevant as we treat (open) code and software as being equally important. I mentioned this aspect in my lightning talk, too, and tried to highlight the importance of source code during the poster presentation. One might argue that open code is implicitly included in open data or open methodology. However, we should not rely on vague interpretations and make explicit what is required to rerun analyses. In the future, submitting, for example, analysis scripts should be as mandatory as it is demanded for datasets.</p>

<p>To conclude, here a few <strong>take home messages</strong>:</p>

<ol>
  <li>Rewards and incentives that motivate to conduct Open Science are key issues</li>
  <li>We have to engage people from society to increase trust in scientific results (tackle credibility crisis)</li>
  <li>Problems are social ‚Äì not technical. BUT: we have to provide scientists with working examples, otherwise they don‚Äôt know why to use it and how.</li>
  <li>Open Science strongly focuses on data and educational aspects.</li>
</ol>

<p>P.S. The next time you read about guidelines, recommendations on open data, try to replace it by source code. The argument still works, right?</p>


</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2017/02/14/egu-short-course-and-session/">EGU short course scheduled and session programme upcoming</a></h3>
<span class="post-date">14 Feb 2017 | By Daniel N√ºst</span>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Join our short course &quot;<a href="https://twitter.com/hashtag/Reproducible?src=hash">#Reproducible</a> <a href="https://twitter.com/hashtag/computational?src=hash">#computational</a> <a href="https://twitter.com/hashtag/research?src=hash">#research</a> in the publication cycle&quot; at <a href="https://twitter.com/hashtag/EGU2017?src=hash">#EGU2017</a> <a href="https://twitter.com/hashtag/SC81?src=hash">#SC81</a> <a href="https://t.co/zPbvGUDsCy">https://t.co/zPbvGUDsCy</a></p>&mdash; o2r (@o2r_project) <a href="https://twitter.com/o2r_project/status/823508737809858560">January 23, 2017</a></blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>The short course <strong>Reproducible computational research in the publication cycle</strong> (SC81) at the <a href="http://www.egu2017.eu/">EGU general assembly</a> was accepted by the short course programme group and scheduled <strong>Monday, April 24th, 2017</strong> in the afternoon. Thanks!</p>

<p>We are grateful for the change to share our work on reproducible research together with members of the <a href="https://www.reprozip.org/">ReproZip</a> team in a practical, hands-on short course.
Afterwards we welcome a number of esteemed speakers to share their views <!--more-->on reproducibility as researcher, reviewer, editor, publisher, and preservationist.</p>

<p>See the <a href="http://meetingorganizer.copernicus.org/EGU2017/session/25726">full session description</a> in the EGU programme.</p>

<p><em>Please register for the short course for free</em> by filling in your name and email in this Doodle poll: <a href="http://doodle.com/poll/2yvi7y9tine2x3pf">http://doodle.com/poll/2yvi7y9tine2x3pf</a>.</p>

<p>Earlier this year we also announced a <a href="/2016/11/09/egu-ga-session-call/">call for a session on reproducibility at EGU general assembly</a>.
The contributions to this session was merged with other sessions to create the session <strong>IE2.4/ESSI3.10 Open Data, Reproducible Research, and Open Science</strong>, see <a href="http://meetingorganizer.copernicus.org/EGU2017/session/23924">session description in the EGU GA programme</a>.</p>

<p>The session programme will be published March 1st, 2017, so stay tuned for the official announcements.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2017/01/16/dlib-magazine-article-published/">D-Lib Magazine Article Published</a></h3>
<span class="post-date">16 Jan 2017 | By Daniel N√ºst</span>
<p><img src="/public/images/2017-01_d-lib-magazine-cover.jpg" alt="article cover screenshot" title="screenshot of article at D-Lib Magazine website" width="300" class="img rightfloat" /></p>

<p>We are happy to announce that our article <strong>Opening the Publication Process with Executable Research Compendia</strong> is now published in D-Lib Magazine‚Äôs <a href="https://doi.org/10.1045/january2017-editorial">current issue</a>:</p>

<p><strong><a href="https://doi.org/10.1045/january2017-nuest">https://doi.org/10.1045/january2017-nuest</a></strong></p>

<p>This paper was originally presented at the <a href="/2016/09/23/repscience-workshop-tpdl-hannover/">RepScience Workshop</a> in September 2016 and was peer-reviewed as part of the workshop submission. It is published as Open Access along with <a href="http://www.dlib.org/dlib/january17/01contents.html">other papers from the conference</a>.</p>

<div class="attribution">N√ºst, D., Konkol, M., Pebesma, E., Kray, C., Schutzeichel, M., Przibytzin, H., Lorenz, J., 2017. Opening the Publication Process with Executable Research Compendia. D-Lib Magazine 23. doi:10.1045/january2017-nuest</div>

<div style="clear: both;"></div>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2017/01/05/agile-conference-workshop-reproducibility/">Reproducible Computational Geosciences Workshop at AGILE Conference</a></h3>
<span class="post-date">05 Jan 2017 | By Daniel N√ºst</span>
<p>We are happy to announce that a pre-conference workshop <a href="https://o2r.info/agile-2017/">‚ÄúReproducible Computational Geosciences‚Äù</a> at the <a href="https://agile-online.org/index.php/home-2017">20th AGILE International Conference on Geographic Information Science</a> will be held on May 9 2017 in Wageningen, The Netherlands.</p>

<p>With this half day workshop we want to introduce the topic of reproducible research to the AGILE conference series, the most prominent and long-standing GIScience and GIS conference in Europe.
The 3-day conference is accompanied by <a href="https://agile-online.org/index.php/programme-2017/agile-workshops-2017"><em>13</em> workshops on diverse topics</a>.</p>

<p><img src="https://agile-online.org/images/stories/banner/AGILE2017-Wageningen.png" alt="agile conference banner" width="500" /></p>
<p class="attributionInlineImage">Image courtesy of AGILE website.</p>

<p><em>Submit your abstract <a href="https://o2r.info/agile-2017/">here</a></em> and share your experiences in reproducibility of geospatial analysis. Challenges, reproducibility studies, archiving, educational or legal aspects are among the welcomed topics.</p>

<p>The workshop is co-organized by o2r team members and Frank Osterman from ITC, Enschede. Contributions and a public peer review are done via GitHub and supported by a great programme committee of distinguished researchers. <em>Please share this information with potentially interested parties (and <a href="https://twitter.com/o2r_project/status/811967235082293248">retweet</a>). Thanks!</em></p>

<p>We look forward to your submission!</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2016/12/15/investigating-docker-and-R/">Investigating Docker and R</a></h3>
<span class="post-date">15 Dec 2016 | By Daniel N√ºst</span>
<div style="border: 2px solid #CE5100; background-color: #ffe2d4; padding: 1em; margin: 1em 0;">
<p>üì¢ PREPRINT PUBLISHED üéâ</p>

<p><a href="https://arxiv.org/abs/2001.10641" title="Link to arXiv"><strong>The Rockerverse: Packages and Applications<br />for Containerization with R</strong></a><br />
Daniel N√ºst, Dirk Eddelbuettel, Dom Bennett, Robrecht Cannoodt, Dav Clark, Gergely Daroczi, Mark Edmondson, Colin Fay, Ellis Hughes, Sean Lopp, Ben Marwick, Heather Nolis, Jacqueline Nolis, Hong Ooi, Karthik Ram, Noam Ross, Lori Shepherd, Nitesh Turaga, Craig Willis, Nan Xiao, Charlotte Van Petegem. 2020. <a href="https://arxiv.org/abs/2001.10641" title="Link to arXiv">arXiv:2001.10641</a> [cs.SE]</p>

<p><em>This post gave the idea for the paper above. It will not be updated anymore.</em></p>
</div>

<p><em><del>This post is regularly updated (cf. <a href="https://github.com/o2r-project/o2r-project.github.io/issues/10">GH issue</a>) and available under the URL <strong><a href="http://bit.ly/docker-r">http://bit.ly/docker-r</a></strong>.</del> Last update: 11 Jan 2018.</em></p>

<p>Docker and R: How are they used and could they be used together?
That is the question that we regularly ask ourself.
And we try to keep up with other people‚Äôs work! In this post, we are going to share our insights with you.</p>

<p><img src="/public/images/docker-loves-r.png" alt="Docker loves R, R loves Docker" title="Docker loves R, R loves Docker" width="400" /></p>

<p><em>Thanks to <a href="http://faculty.washington.edu/bmarwick/">Ben Marwick</a> for <a href="https://github.com/o2r-project/o2r-project.github.io/pull/6">contributing</a> to this post! You know about a project using Docker and R? <a href="https://github.com/o2r-project/o2r-project.github.io/issues/new">Get in touch</a>.</em></p>

<h4 id="dockerising-r">Dockerising R</h4>

<p>Several implementations of besides the one by R-core exist today, together with numerous integrations into open source and proprietary software (cf. <a href="https://en.wikipedia.org/wiki/R_(programming_language)#Implementations">English</a> and <a href="https://de.wikipedia.org/wiki/R_(Programmiersprache)#Alternative_Open-Source-Interpreter">German</a> Wikipedia pages).
In the following we present the existing efforts for using <em>open source</em> R implementation with Docker.</p>

<h5 id="rocker">Rocker</h5>

<p>The most prominent effort<!--more--> in this area is the <strong>Rocker</strong> project (<a href="http://rocker-project.org/">http://rocker-project.org/</a>).
It was initiated by <a href="http://dirk.eddelbuettel.com/">Dirk Eddelbuettel</a> and <a href="http://www.carlboettiger.info/">Carl Boettiger</a> and containerises the main R implementation based on <a href="https://www.debian.org">Debian</a>.
For an introduction, you may read their blog post <a href="http://dirk.eddelbuettel.com/blog/2014/10/23/">here</a> or follow <a href="http://ropenscilabs.github.io/r-docker-tutorial/">this tutorial</a> from rOpenSci.</p>

<p><img src="/public/images/rocker-logo.png" alt="Rocker logo" title="Rocker logo" width="200" class="img rightfloat" /></p>

<p>With a big choice of pre-build Docker images, Rocker provides optimal solutions for those who want to run R from Docker containers.
Explore it on <a href="https://github.com/rocker-org/">Github</a> or <a href="https://hub.docker.com/u/rocker/">Docker Hub</a>, and soon you will find out that it takes just one single command to run instances of either <a href="https://hub.docker.com/r/rocker/r-base/">base R</a>, <a href="https://hub.docker.com/r/rocker/r-devel/">R-devel</a> or <a href="https://hub.docker.com/r/rocker/rstudio/">Rstudio Server</a>.
Moreover, you can run <a href="https://hub.docker.com/r/rocker/r-versioned/">specific versions of R</a> or use one of the many bundles with commonly used R packages and other software, namely <a href="https://hub.docker.com/r/rocker/tidyverse/">tidyverse</a> and <a href="https://hub.docker.com/r/rocker/ropensci/">rOpenSci</a>).</p>

<p>Images are build monthly on Docker Hub, except <em>devel</em> tags which are build nightly.
Automated builds are disabled, instead builds are triggered by CRON jobs running on a third party server (cf. <a href="https://github.com/rocker-org/rocker-versioned/issues/42#issuecomment-316149983">GitHub comment</a>).</p>

<h5 id="bioconductor">Bioconductor</h5>

<p>If you come from bioinformatics or neighboring disciplines, you might be delighted that <a href="http://bioconductor.org/"><strong>Bioconductor</strong></a> provides several images based on Rocker‚Äôs <code class="highlighter-rouge">rocker/rstudio</code> images.
See the <a href="http://bioconductor.org/help/docker/">help page</a>, <a href="https://github.com/Bioconductor/bioc_docker">GitHub</a>, and <a href="https://hub.docker.com/u/bioconductor/">Open Hub</a> for more information.
In short, the Bioconductor core team maintains <em>release</em> and <em>devel</em> images (e.g. <code class="highlighter-rouge">bioconductor/release_base2</code>), and contributors maintain image with different levels of pre-installed packages (each in <em>release</em> and <em>devel</em> variants), which are based on Bioconductor views (e.g. <code class="highlighter-rouge">bioconductor/devel_proteomics2</code> installs the views <a href="https://www.bioconductor.org/packages/devel/BiocViews.html#___Proteomics">Proteomics</a> and <a href="https://www.bioconductor.org/packages/devel/BiocViews.html#___MassSpectrometryData">MassSpectrometryData</a>).</p>

<p>Image updates occur with each Bioconductor release, except the <em>devel</em> images which are build weekly with the latest versions of R and Bioconductor based on <code class="highlighter-rouge">rocker/rstudio-daily</code>.</p>

<h5 id="centos-based-r-containers">CentOS-based R containers</h5>

<p><a href="http://meanmean.me/">Jonathan Lisic</a> works on a collection of Dockerfiles building on <a href="https://www.centos.org/">CentOS</a> (6 and 7) and other operating systems as an alternative to the Debian-based Rocker stack.
The Dockerfiles are on GitHub: <a href="https://github.com/jlisic/R-docker-centos">https://github.com/jlisic/R-docker-centos</a></p>

<h5 id="mro">MRO</h5>

<p><img src="/public/images/mro-logo.png" alt="MRO logo" title="MRO logo (C) Microsoft" width="150" class="img rightfloat" /></p>

<p>Microsoft R Open (<a href="https://mran.microsoft.com/open">MRO</a>) is an ‚Äúenhanced R distribution‚Äù, formerly known as Revolution R Open (RRO) before <a href="https://en.wikipedia.org/wiki/Revolution_Analytics">Revolution Analytics</a> was acquired by Microsoft.
MRO is compatible with main R and it‚Äôs packages.
‚ÄúIt includes additional capabilities for improved performance, reproducibility, and platform support.‚Äù (<a href="https://mran.revolutionanalytics.com/rro/">source</a>); most notably these are the <a href="http://mran.revolutionanalytics.com/">MRAN repository</a> a.k.a. CRAN Time Machine, which is also used by versioned Rocker images, and the (optional) integration with <a href="https://software.intel.com/en-us/mkl">Intel¬Æ Math Kernel Library</a> (MKL) for <a href="https://mran.revolutionanalytics.com/documents/rro/multithread">multi-threaded performance</a> in linear algebra operations (<a href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms">BLAS</a> and <a href="https://en.wikipedia.org/wiki/LAPACK">LAPACK</a>).</p>

<p>o2r team member Daniel created a Docker image for MRO including MKL.
It is available <a href="https://hub.docker.com/r/nuest/mro/">on Docker Hub</a> as <code class="highlighter-rouge">nuest/mro</code>, with <a href="https://github.com/nuest/mro-docker">Dockerfile on GitHub</a>.
It is inspired by the Rocker images and can be used in the same fashion.
Please note the extended licenses printed at every startup for MKL.</p>

<p><a href="#centos-based-r-containers">Jonathan Lisic</a> published a Dockerfile for a CentOS-based MRO <a href="https://github.com/jlisic/R-docker-centos">on GitHub</a>.</p>

<p><a href="https://www.linkedin.com/in/alikzaidi/">Ali Zaidi</a> published <a href="https://github.com/akzaidi/mrclient-docker">Dockerfiles on GitHub</a> and <a href="https://hub.docker.com/r/akzaidi/mrclient-docker/">images on Docker Hub</a> for <a href="https://docs.microsoft.com/en-us/machine-learning-server/r-client/what-is-microsoft-r-client">Microsoft R Client</a>, which is based on MRO.</p>

<blockquote>
  <p><em>R Client adds to MRO by including a couple of ‚ÄúScaleR‚Äù machine learning algorithms and packages for parallelisation and remote computing.</em></p>
</blockquote>

<h5 id="renjin">Renjin</h5>

<p><img src="/public/images/renjin-logo-v4.svg" alt="Renjin logo" title="Renjin logo" width="150" class="img rightfloat" /></p>

<p><a href="http://www.renjin.org/about.html">Renjin</a> is a <a href="https://en.wikipedia.org/wiki/Java_virtual_machine">JVM</a>-based interpreter for the R language for statistical computing developed by <a href="http://www.bedatadriven.com/">BeDataDriven</a>.
It was developed for big data analysis using existing R code seamlessly in cloud infrastructures, and allows Java/Scala developers to easily combine R with all benefits of Java and the JVM.</p>

<p>While it is not primarily build for interactive use on the command line, this is possible.
So o2r team member Daniel created a Docker image for Renjin for you to try it out.
It is available <a href="https://hub.docker.com/r/nuest/renjin/">on Docker Hub</a> as <code class="highlighter-rouge">nuest/renjin</code>, with <a href="https://github.com/nuest/renjin-docker">Dockerfile on GitHub</a>.</p>

<h5 id="pqr">pqR</h5>

<p><a href="http://www.pqr-project.org/"><strong>pqR</strong></a> tries to create <em>‚Äúa pretty quick version of R‚Äù</em> and fixing some perceived issues in the R language.
While this is a one man project by <a href="http://www.cs.toronto.edu/~radford/">Radford Neal</a>, it‚Äôs worth trying out such contributions to the open source community and to the discussion on how R should look like in the future (cf. <a href="http://www.cs.toronto.edu/~radford/RIOT2017-lang.pdf">a recent presentation</a>), even if things might get <a href="https://github.com/radfordneal/pqR/issues/30#issuecomment-251188198">personal</a>.
As you might have guess by now, Daniel created a Docker image for you to try out pqR: It is available <a href="https://hub.docker.com/r/nuest/pqr/">on Docker Hub</a> as <code class="highlighter-rouge">nuest/pqr</code>, with <a href="https://github.com/nuest/pqr-docker">Dockerfile on GitHub</a>.</p>

<h5 id="wip-fastr">[WIP] FastR</h5>

<p>Also targeting performance, <a href="https://github.com/graalvm/fastr"><strong>FastR</strong></a> is <em>‚Äúis an implementation of the R Language in Java atop <a href="https://github.com/graalvm/graal/blob/master/truffle/README.md">Truffle</a>, a framework for building self-optimizing AST interpreters.‚Äù</em> FastR is planned as a drop-in replacement for R, but <a href="https://github.com/graalvm/fastr/blob/master/documentation/Limitations.md">relevant limitations</a> apply.</p>

<p>While GraalVM has a <a href="https://hub.docker.com/u/graalvm/">Docker Hub user</a>, no images are published probably because of licensing requirements, as can be seen in the GitHub repository <a href="https://github.com/oracle/docker-images/tree/master/GraalVM/graalvm-0.22">oracle/docker-images</a>, where users must manually download a GraalVM release, which requires an Oracle Account‚Ä¶ so the current tests available in <a href="https://github.com/nuest/fastr-docker">this GitHub repository</a>, trying to build FastR from source based on the newest OpenJDK Java 9.</p>

<h4 id="dockerising-research-and-development-environments">Dockerising Research and Development Environments</h4>

<p>So why, apart from the incredibly easy usage, adoption and transfer of typical R environments, would you want to combine R with Docker?</p>

<p>Ben Marwick, Associate Professor at the University of Washington, explains in <a href="https://benmarwick.github.io/UW-eScience-docker-for-reproducible-research/">this presentation</a> that it helps you manage dependencies.
It gives a computational environment that is isolated from the host, and at the same time transparent, portable, extendable and reusable.
Marwick uses Docker and R for <strong>reproducible research</strong> and thus bundles up his works to a kind of <em>Research Compendium</em>; an instance is available <a href="https://github.com/benmarwick/1989-excavation-report-Madjebebe">here</a>, and a template <a href="https://github.com/benmarwick/researchcompendium">here</a>.</p>

<p><a href="https://doi.org/10.1145/2723872.2723882"><img src="/public/images/boettiger-acm.jpg" alt="Screenshot Boettiger ACM paper" title="Screenshot Boettiger ACM paper" width="150" class="img rightfloat" /></a></p>

<p>Carl Boettiger, Assistant Professor at UC Berkeley, wrote in detail about using Docker for reproducibility in his ACM SIGOPS paper <a href="https://doi.org/10.1145/2723872.2723882">‚ÄòAn introduction to Docker for reproducible research, with examples from the R environment‚Äô</a>.</p>

<p>Both Ben and Carl contributed case studies using Docker for research compendia in the book <a href="https://www.gitbook.com/book/bids/the-practice-of-reproducible-research/details">‚ÄúThe Practice of Reproducible Research - Case Studies and Lessons from the Data-Intensive Sciences‚Äù</a>: <a href="https://www.practicereproducibleresearch.org/case-studies/benmarwick.html">Using R and Related Tools for Reproducible Research in Archaeology</a> and <a href="https://www.practicereproducibleresearch.org/case-studies/cboettig.html">A Reproducible R Notebook Using Docker</a>.</p>

<p>An R extension you may want to dockerise is <strong>Shiny</strong>.
Flavio Barros dedicated two articles on R-bloggers to this topic: <a href="https://www.r-bloggers.com/dockerizing-a-shiny-app/">Dockerizing a Shiny App</a> and <a href="https://www.r-bloggers.com/share-your-shiny-apps-with-docker-and-kitematic/">Share Shiny apps with Docker and Kitematic</a>.
The majority of talks at <a href="https://user2017.brussels">useR!2017</a> presenting <a href="https://user2017.brussels/schedule">real-world deployments of Shiny</a> mentioned using dockerised Shiny applications for reasons of scalability and ease of installation.</p>

<p>The company <a href="https://www.sevenbridges.com/">Seven Bridges</a> provides an example for a public container encapsulating a specific research environment, in this case the product <a href="https://www.sevenbridges.com/platform/">Seven Bridges Platform</a> (<em>‚Äúa cloud-based environment for conducting bioinformatic analyses‚Äù</em>), its tools and the Bioconductor package <a href="https://www.bioconductor.org/packages/devel/bioc/html/sevenbridges.html"><code class="highlighter-rouge">sevenbridges</code></a>.
The published image <a href="https://hub.docker.com/r/sevenbridges/sevenbridges-r/"><code class="highlighter-rouge">sevenbridges/sevenbridges-r</code></a> includes both RStudio Server and Shiny, see the <a href="https://www.bioconductor.org/packages/devel/bioc/vignettes/sevenbridges/inst/doc/rstudio.html">vignette ‚ÄúIDE Container‚Äù</a>.</p>

<p>A new solution to ease the creation of Docker containers for specific research environments is <a href="https://github.com/o2r-project/containerit"><strong><code class="highlighter-rouge">containerit</code></strong></a>.
It creates <code class="highlighter-rouge">Dockerfile</code>s (using Rocker base images) from R sessions, R scripts, R Markdown files or R workspace directories, including the required system dependencies.
The package was <a href="/2017/07/07/useR2017">presented at useR!2017</a> and can currently only be installed from GitHub.</p>

<p>While Docker is made for running tools and services, and providing user interfaces via web protocols (e.g. via a local port and a website opened in a browser, as with <code class="highlighter-rouge">rocker/rstudio</code> or Jupyter Notebook images), several activities exists that try to package <strong>GUI applications in containers</strong>.
Daniel explores some alternatives for running RStudio in <a href="https://github.com/nuest/x11rockerstudio">this GitHub repository</a>, just for the fun of it.
In this particular case it may not be very sensible, because <em>RStudio Desktop</em> is already effectively a browser-based UI (unlike other GUI-based apps packages this way), but for users with reluctance to a browser UI and/or command line interfaces, the ‚ÄúDesktop in a container‚Äù approach might be useful.</p>

<h4 id="running-tests">Running Tests</h4>

<p>The package <a href="https://github.com/traitecoevo/dockertest"><strong><code class="highlighter-rouge">dockertest</code></strong></a> makes use of the isolated environment that Docker provides: R programmers can set up test environments for their R packages and R projects, in which they can rapidly test their works on Docker containers that only contain R and the relevant dependencies.
All of this without cluttering your development environment.</p>

<p>The package <a href="https://cran.r-project.org/package=gitlabr"><strong><code class="highlighter-rouge">gitlabr</code></strong></a> does not use Docker itself, but wraps the <a href="https://docs.gitlab.com/ce/api/README.html">GitLab API</a> in R functions for easy usage.
This includes starting continuous integration (CI) tests (function <a href="https://www.rdocumentation.org/packages/gitlabr/versions/0.9/topics/gl_ci_job"><code class="highlighter-rouge">gl_ci_job</code></a>), which <a href="https://docs.gitlab.com/ce/ci/docker/using_docker_images.html">GitLab can do using Docker</a>, so the function has an argument <code class="highlighter-rouge">image</code> to select the image run to perform a CI task.</p>

<p>In a completely different vein but still in the testing context, <a href="https://cran.r-project.org/package=sanitizers"><strong><code class="highlighter-rouge">sanitizers</code></strong></a> is an R package for testing the compiler setup across different compiler versions to detect code failures in sample code.
This allows testing completely different environments on the same host, without touching the well-kept development environment on the host.
The packages‚Äô images are now <em>deprecated</em> and superseded by Rocker images (<code class="highlighter-rouge">rocker/r-devel-san</code> and <code class="highlighter-rouge">rocker/r-devel-ubsan-clang</code>).</p>

<h4 id="dockerising-documents-and-workflows">Dockerising Documents and Workflows</h4>

<p>Some works are dedicated to <em>dockerising R-based documents</em>.</p>

<p><img src="/public/images/liftr-logo.png" alt="liftr logo" title="liftr logo" width="100" class="img rightfloat" /></p>

<p>The package <a href="http://liftr.me/"><strong><code class="highlighter-rouge">liftr</code></strong></a> (<a href="https://cran.r-project.org/package=liftr">on CRAN</a>) for R lets users enhance Rmd files with YAML-metadata (<a href="https://github.com/road2stat/dockflow/blob/master/config/sequencing.yml">example</a>), which enables rendering R Markdown documents in Docker containers.
Unlike <code class="highlighter-rouge">containerit</code>, this metadata must be written by the author of the R Markdown document.</p>

<p><code class="highlighter-rouge">liftr</code> is used in the <a href="https://dockflow.org/"><strong>DockFlow</strong></a> initiative to containerise a selection of <a href="https://bioconductor.org/help/workflows/">Bioconductor workflows</a> as presented in <a href="https://nanx.me/papers/dockflow-poster-bioc2017.pdf">this poster</a> at BioC 2017 conference.
Liftr also supports <a href="https://www.rabix.org/">Rabix</a>, a Docker-based toolkit for portable bioinformatics workflows.
That means that users can have Rabix workflows run inside the container and have the results integrated directly into the final document.</p>

<p>The Bioconductor package <a href="https://www.bioconductor.org/packages/devel/bioc/html/sevenbridges.html"><code class="highlighter-rouge">sevenbridges</code></a> (see also above) has <a href="http://www.tengfei.name/sevenbridges/vignettes/docker.html">a vignette on creating reproducible reports with Docker</a>.
In recommends a reproducible script or report with <code class="highlighter-rouge">docopt</code> respectively R markdown (parametrised reports).
The cloud-based Seven Bridges platform can fulfill requirements, such as required Docker images, within their internal JSON-based workflow and ‚ÄúTool‚Äù description format (<a href="https://github.com/sbg/sevenbridges-r/blob/master/inst/docker/sevenbridges/rabix/runif.json#L91">example</a>), for which the package provides helper functions to create Tools and execute them, see <a href="http://www.tengfei.name/sevenbridges/vignettes/api.html#import-cwl-app-and-run-a-task">this example in a vignette</a>.
Docker images are used for <a href="http://www.tengfei.name/sevenbridges/vignettes/apps.html">local testing of these workflows</a> based on Rabix (see above), where images are started automatically in the background for a user, who only uses R functions.
Automated builds for workflows on Docker Hub are also encouraged.</p>

<p><a href="http://rcloud.social"><strong>RCloud</strong></a> is a collaborative data analysis and visualization platform, which you can not only try out online but also host yourself with Docker.
Take a look at <a href="https://github.com/att/rcloud/tree/master/docker">their Dockerfiles</a> or try out their image <a href="https://hub.docker.com/r/rcl0ud/rcloud/"><code class="highlighter-rouge">rcl0ud/rcloud</code></a>.</p>

<h4 id="control-docker-containers-from-r">Control Docker Containers from R</h4>

<p>Rather than running R inside Docker containers, it can be beneficial to call Docker containers from inside R.
This is what the packages in this section do.</p>

<p>The <a href="https://github.com/wch/harbor/"><strong><code class="highlighter-rouge">harbor</code> package</strong></a> for R (only available via GitHub) provides all Docker commands with R functions.
It may be used to control Docker containers that run either locally or remotely.</p>

<p>A more recent alternative to <code class="highlighter-rouge">harbor</code> is the package <a href="https://bhaskarvk.github.io/docker/"><strong><code class="highlighter-rouge">docker</code></strong></a>, also available <a href="https://cran.r-project.org/package=docker">on CRAN</a> with source code <a href="https://github.com/bhaskarvk/docker">on GitHub</a>.
Using a <a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">DRY</a> approach, it provides a thin layer to the Docker API using the <a href="https://docker-py.readthedocs.io/en/stable/">Docker SDK for Python</a> via the package <a href="https://rstudio.github.io/reticulate/"><code class="highlighter-rouge">reticulate</code></a>.
The package is best suited for apt Docker users, i.e. if you know the Docker commands and life cycle.
However, thanks to the abstraction layer provided by the Docker SDK for Python, <code class="highlighter-rouge">docker</code> also runs on various operating systems (including Windows).</p>

<p><a href="https://github.com/cboettig/dockermachine"><strong><code class="highlighter-rouge">dockermachine</code></strong></a> provides a convenient R interface to the <a href="https://docs.docker.com/machine/overview/"><code class="highlighter-rouge">docker-machine</code></a> command, so you can provision easily local or remote/cloud instances of containers.</p>

<p><a href="http://www.seleniumhq.org/"><strong>Selenium</strong></a> provides tools for browser automation, which are also <a href="https://hub.docker.com/u/selenium/">available as Docker images</a>.
They can be used, amongst others, for testing web applications or controlling a headless web browser from your favorite programming language.
In <a href="https://rpubs.com/johndharrison/RSelenium-Docker">this tutorial</a>, you can see how and why you can use the package <code class="highlighter-rouge">RSelenium</code> to interact with your Selenium containers from R.</p>

<p><a href="https://cloudyr.github.io/googleComputeEngineR/"><strong><code class="highlighter-rouge">googleComputeEngineR</code></strong></a> provides an R interface to the Google Cloud Compute Engine API.
It includes a function called <code class="highlighter-rouge">docker_run</code> that starts a Docker container in a Google Cloud VM and executes R code in it.
Read <a href="https://cloudyr.github.io/googleComputeEngineR/articles/docker-ssh-futures.html">this article</a> for details and examples.
There are similar ambitions to implement Docker capabilities in the <a href="https://github.com/sckott/analogsea"><strong><code class="highlighter-rouge">analogsea</code> package</strong></a> that interfaces the Digital Ocean API.
<code class="highlighter-rouge">googleComputeEngineR</code> and <code class="highlighter-rouge">analogsea</code> use functions from <code class="highlighter-rouge">harbor</code> for container management.</p>

<h4 id="r-and-docker-for-complex-web-applications">R and Docker for Complex Web Applications</h4>

<p>Docker, in general, may help you to build complex and scalable web applications with R.</p>

<p>If you already have a <a href="https://shiny.rstudio.com/">Shiny</a> app, then <a href="http://colebrokamp.com/">Cole Brokamp‚Äôs</a> package <a href="https://github.com/cole-brokamp/rize"><code class="highlighter-rouge">rize</code></a> makes you just one function call away from building and viewing your dockerised Shiny application.</p>

<p>If you want to get serious with Shiny, take a look at <a href="https://www.shinyproxy.io/">ShinyProxy</a> by <a href="https://www.openanalytics.eu/">Open Analytics</a>.
ShinyProxy is a Java application (<a href="https://github.com/openanalytics/shinyproxy">see GitHub</a>) to deploy Shiny applications.
It <a href="https://github.com/openanalytics/shinyproxy/blob/master/src/main/java/eu/openanalytics/services/DockerService.java#L388">creates a container</a> with the Shiny app for each user to ensure scalability and isolation and has some other ‚Äúenterprise‚Äù features.</p>

<p>Mark McCahill presented at <a href="https://sites.duke.edu/researchcomputing/2014/09/23/duke-docker-day-was-great/">an event</a> of the Duke University in North Carolina (USA) how he provided 300+ students each with private RStudio Server instances.
In his presentation (<a href="https://sites.duke.edu/researchcomputing/files/2014/09/mccahill-DockerDays.pdf">PDF</a> / <a href="https://people.duke.edu/~mdelong/mccahill-DockerDays.mov">MOV</a> (398 MB)), he explains his <strong>RStudio farm</strong> in detail.</p>

<p>If you want to use <strong>RStudio with cloud services</strong>, you may find delight in these articles from the SAS and R blog: <a href="http://sas-and-r.blogspot.de/2016/12/rstudio-in-cloud-with-amazon-lightsail.html">RStudio in the cloud with Amazon Lightsail and docker</a>, <a href="http://sas-and-r.blogspot.de/2016/01/set-up-rstudio-in-cloud-to-work-with.html">Set up RStudio in the cloud to work with GitHub</a>, <a href="http://sas-and-r.blogspot.de/2014/12/rstudio-in-cloud-for-dummies-20142015.html">RStudio in the cloud for dummies, 2014/2015 edition</a>.</p>

<p>The platform <a href="https://github.com/r-hub"><strong>R-hub</strong></a> helps R developers with solving package issues prior to submitting them to CRAN.
In particular, it provides services that build packages on all CRAN-supported platforms and checks them against the latest R release.
The services utilise backends that perform regular R builds inside of Docker containers.
Read the <a href="https://github.com/r-hub/proposal">project proposal</a> for details.</p>

<p>The package <a href="https://cran.r-project.org/package=plumber"><strong><code class="highlighter-rouge">plumber</code></strong></a> (<a href="https://www.rplumber.io/">website</a>, <a href="https://github.com/trestletech/plumber">repository</a>) allows creating web services/HTTP APIs in pure R.
The maintainer provides a ready to use Docker image <code class="highlighter-rouge">trestletech/plumber</code> to run/host these applications with <a href="https://www.rplumber.io/docs/hosting.html#docker">excellent documentation</a> including topics such as multiple images under one port and load balancing.</p>

<h4 id="batch-processing">Batch processing</h4>

<p>The package <a href="https://cran.r-project.org/package=batchtools"><strong><code class="highlighter-rouge">batchtools</code></strong></a> (<a href="https://github.com/mllg/batchtools">repository</a>, <a href="http://dx.doi.org/10.21105/joss.00135">JOSS paper</a>) provides a parallel implementation of <a href="https://en.wikipedia.org/wiki/Map_(parallel_pattern)">Map</a> for <a href="https://en.wikipedia.org/wiki/Supercomputer">HPC</a> for different <a href="https://en.wikipedia.org/wiki/Job_scheduler">schedulers</a>, including <a href="https://docs.docker.com/engine/swarm/">Docker Swarm</a>.
A job can be executed on a Docker cluster with a <a href="https://mllg.github.io/batchtools/reference/makeClusterFunctionsDocker">single R function call</a>, for which a Docker CLI command is <a href="https://github.com/mllg/batchtools/blob/master/R/clusterFunctionsDocker.R#L49">constructed as a string and executed with <code class="highlighter-rouge">system2(..)</code></a>.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2016/11/09/egu-ga-session-call/">"Reproducible research for big data in practice": call for abstracts EGU GA 2017 session</a></h3>
<span class="post-date">09 Nov 2016 | By Daniel N√ºst</span>
<p>We are happy to announce that a session convened by o2r team member <a href="http://orcid.org/0000-0001-8049-7069">Edzer Pebesma</a> along with co-conveners <a href="http://orcid.org/0000-0001-8465-8341">Yolanda Gil</a>, <a href="http://www.ldeo.columbia.edu/user/lehnert">Kerstin Lehnert</a>, <a href="http://orcid.org/0000-0001-5911-6022">Jens Klump</a>, <a href="https://www.linkedin.com/in/martinhammitzsch">Martin Hammitzsch</a>, and <a href="http://orcid.org/0000-0002-0024-5046">Daniel N√ºst</a> was accepted at <a href="http://egu2017.eu">next year‚Äôs European Geosciences Union General Assembly</a>.</p>

<p>The <a href="http://meetingorganizer.copernicus.org/EGU2017/sessionprogramme"><strong>call for abstracts</strong></a> is now open. The abstract submission deadline is 11 Jan 2017, 13:00 CET. So there is plenty of time to contribute, prepare an abstract and share your experience of reproducible research.</p>

<p>Please <a href="https://twitter.com/o2r_project/status/796007146366365697">spread the word</a> and find out more at <a href="https://bit.ly/rregu17">https://bit.ly/rregu17</a>.</p>

<p>From the session description:</p>

<blockquote>
  <p>This session will showcase papers that <!--more-->focus on big data analysis and take reproducibility and openness into account. It is open to members of all programme groups and scientific disciplines to present how they conduct data-based research in a reproducible way. They are welcome to share practical advice, lessons learned, practical challenges of reproducibility, and report on the application of tools and software that support computational reproducibility.</p>
</blockquote>

<p>The session is co-organized as part of the Interdisplinary Event ‚ÄúBig Data in the Geosciences‚Äù (IE 3.3), and the <a href="http://essi.egu.eu/">division on Earth &amp; Space Science Informatics</a> (ESSI ESSI4.11). ‚ÄúUsing computers‚Äù is the unifying feature of many a researcher in the <a href="http://www.egu.eu/structure/divisions/">scientific divisions</a>, so we look forward to meet a diverse group of people next year in Vienna. In the session description the conveners point out that‚Ä¶</p>

<blockquote>
  <p>[c]omputational reproducibility is especially important in the context of big data. Readers of articles must be able to trust the applied methods and computations because [..] data are also unique, observed by a single entity, or synthetic and simulated. Contributions based on small datasets are of special interest to demonstrate the variety in big data. Topics may include, but are not limited to, reproducibility reports and packages for previously published computational research, practical evaluations of reproducibility solutions for a specific research use case, best practices towards reproducibility in a specific domain such as publishing guidelines for data and code, or experiences from teaching methods for computational reproducibility.</p>
</blockquote>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2016/10/24/oa-week/">Open in Action</a></h3>
<span class="post-date">24 Oct 2016 | By Marc Schutzeichel</span>
<p>The Open Access movement has improved the foundation for research reproducibility in that it has greatly advanced the accessibility of research data and text. This year‚Äôs theme for the <a href="http://www.openaccessweek.org/">International Open Access Week</a> is ‚ÄúOpen in Action‚Äù. The o2r team joins in by creating <a href="https://www.uni-muenster.de/Publizieren/open-access/">local awareness</a> for what may come beyond Open Access.</p>

<p><img src="/public/images/2016-10-24_oaweek.png" alt="OA week logo" width="600" /></p>
<p class="attributionInlineImage">Image by <a href="http://openaccessweek.org" title="Open Access Week">openaccessweek.org</a>, licensed under <a href="https://creativecommons.org/licenses/by/4.0/" title="Creative Commons Attribution 4.0 International">CC BY 4.0 Int.</a></p>

<p>To transform access into action, the o2r team is working towards the implementation of a simple technical solution. A <a href="http://pebesma.staff.ifgi.de/epic.pdf">‚Äúone click reproduce‚Äù</a> button is one of the extremes within the continuum of reproducibility.
It enables the user to recreate the original results of a study with only a mouse click. In order to realize that, a new format for the publication of research findings has to be created and integrated into the publication cycle.</p>

<p>In o2r we envision a container format that implements the <em>executable research compendium</em> (<a href="http://presentations.copernicus.org/EGU2016-7396_presentation.pdf">ERC</a>) to encapsulate any information relevant to constitutating a complete set of research data, code, text and UI. This includes any necessary specification of the working and run time environments.</p>

<p>Towards the other end of the continuum of reproducibility we find examples of published code and data that are openly accessible and yet fail to be rebuild easily by another scholar. By being dependent on other software, vanished packages and specific versions or environments, such cases leave it to the user to reconstruct the individual computational dependency architectures.
This strongly increases the efforts to rebuild, run, or compile the code and thus effectively blocks <em>Open Action</em>.</p>

<p>With the use of ERCs such obstacles can be resolved: The orginial analysis underlying a scientific publication becomes fully reproducible for independent researchers and anyone interested.
Opening reproducibility is where we see the biggest need for Open Action in science.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2016/09/23/repscience-workshop-tpdl-hannover/">Workshop on Reproducible Open Science</a></h3>
<span class="post-date">23 Sep 2016 | By Daniel N√ºst, Markus Konkol</span>
<p>Just two weeks ago, o2r team members <a href="https://orcid.org/0000-0002-0024-5046">Daniel</a> and <a href="http://orcid.org/0000-0001-6651-0976">Markus</a> proudly presented the project‚Äôs first workshop paper <em>‚ÄúOpening the Publication Process with Executable Research Compendia‚Äù</em> at the <a href="http://repscience2016.research-infrastructures.eu">First International Workshop on Reproducible Open Science</a> held in conjunction with the <a href="http://www.tpdl2016.org/">20th International Conference on Theory and Practice of Digital Libraries</a> and suppored by <a href="http://europe.rd-alliance.org/">RDA Europe</a>.</p>

<p>The workshop was a great event with contributions from very diverse backgrounds, ranging from computer science to library technology, and use cases, from big data to metadata interoperability or microscopic experiments.</p>

<p>The talks we‚Äôre accompanied by excellent <strong>keynotes</strong> given by <a href="http://orcid.org/0000-0003-1219-2137">Carole Goble</a> on the <a href="http://repscience2016.research-infrastructures.eu/img/CaroleGoble-ReproScience2016v2.pdf">‚ÄúR* Brouhaha‚Äù</a> and <a href="http://orcid.org/0000-0002-6137-2348">S√ºnje Dallmeier-Tiessen</a> on CERNs hard <a href="http://repscience2016.research-infrastructures.eu/img/Sunje-RepScience2016.pdf">work towards reproducible research</a>.</p>

<p>The presentations were followed by a <strong>general discussion session</strong>, which touched, for example, the topics of publication bias/negative results, education having a higher potential than yet another infrastructure (‚Äúsoftware data carpentry works‚Äù, says Carole Goble), and the necessity to communicate better about reproducible research. The latter lead to the idea of ‚Äúfive stars of reproducibility‚Äù inspired by the tremendously useful <a href="http://5stardata.info/">5 ‚òÖ Open Data</a> and also the <a href="http://www.nature.com/articles/sdata201618">FAIR principles</a> .</p>

<p>All the <strong>slides</strong> are <a href="http://repscience2016.research-infrastructures.eu/index.php?d=sessions">available online</a>, including <a href="http://repscience2016.research-infrastructures.eu/img/Hannover_Workshop_RepScience_TDPL2016.pdf">our own</a>.</p>

<p>It was great for us to share our ideas of an <em>Executable Research Compendium</em> with the workshop attendees. The discussions and feedback was very helpful. We especially realized that we need to sharpen the distinctive aspects of our project when we talk about it. We‚Äôre now working hard to implement this in a paper draft we‚Äôre working on.</p>

<p>We thank the <a href="http://repscience2016.research-infrastructures.eu/index.php?d=committee">organizers</a> <a href="https://orcid.org/0000-0002-4259-9774">Amir Aryani</a>, <a href="https://orcid.org/0000-0002-9260-0753">Oscar Corcho</a>, <a href="https://orcid.org/0000-0001-7291-3210">Paolo Manghi</a>, and <a href="http://orcid.org/0000-0002-0458-1004">Jochen Schirrwagen</a> for the well-run event! Hopefully there is going to be a second edition next year.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2016/09/06/foss4g-docker/">Docker presentation at FOSS4G conference</a></h3>
<span class="post-date">06 Sep 2016 | By Daniel N√ºst</span>
<p><strong>Update</strong>: A video recoriding of the presentation is now published on the TIB AV-Portal: <a href="http://dx.doi.org/10.5446/20330">http://dx.doi.org/10.5446/20330</a></p>

<iframe width="560" height="315" scrolling="no" src="//av.tib.eu/player/20330" frameborder="0" allowfullscreen=""></iframe>

<p>o2r team member <a href="https://twitter.com/nordholmen">Daniel N√ºst</a> recently participated in the worlds largest conference for geospatial open source software. The <a href="http://2016.foss4g.org">FOSS4G 2016</a> was hosted by the Open Source Geospatial Foundation (<a href="http://www.osgeo.org/">OSGeo</a>) and took place close to home, namely in Bonn. Therefore Daniel was extremely happy that <!--more--> his <a href="http://2016.foss4g.org/talks.html#146">talk</a> ‚ÄúAn overview of Docker images for geospatial applications‚Äù was voted to be presented by the OSGeo community. Daniel presented an evaluation into the existing containers for FOSS4G software. After an introduction into Docker and some live demos, the takeaway was that everybody should use Docker more, and many different application scenarios (development, demos, training, cloud deployment) exist.</p>

<p>The presentation was very well attended (~ 120 people), albeit taking place in the first session on Friday morning after the conference dinner the night before. <a href="https://twitter.com/search?q=foss4g%20docker&amp;src=typd">Reactions on Twitter</a> were also quite positive, several <a href="https://twitter.com/foss4g/status/769081504718852119">good question</a>s were asked, and great discussions followed throughout the day.</p>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Much interest in Docker containerization, <a href="https://twitter.com/hashtag/foss4g?src=hash">#foss4g</a> <a href="https://t.co/i55KphJwKv">pic.twitter.com/i55KphJwKv</a></p>&mdash; michael GOULD (@0mgould) <a href="https://twitter.com/0mgould/status/769075459225219072">August 26, 2016</a></blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>The main part of the work is published in the OSGeo wiki: a comprehensive list of Docker containers published by projects or third parties to use a large variety of tools, libraries, or Desktop applications in Docker containers. Check out the list at <strong><a href="https://wiki.osgeo.org/wiki/DockerImages">https://wiki.osgeo.org/wiki/DockerImages</a></strong>. Contributions are welcome!</p>

<p><em>How is this related to the o2r project?</em> The expertise build up around Docker should be shared with the communities we know. And more concretely, many applications in the geospatial world are build upon services and APIs, so scientific work building upon these APIs will require to archive such services, too. This is a topic we will experiment on in the second year of o2r.</p>

<p><img src="http://geocontainers.org/img/geocontainers-logo.png" alt="geocontainers logo" title="geocontainers logo" width="100" class="img rightfloat" />As some popular projects surprisingly did not have Docker images yet, Daniel started a new independent project <a href="https://github.com/geocontainers/">on GitHub</a> to provide a place for FOSS4G-related containers and to expand the knowledge and application of containers for geospatial applications: <strong><a href="http://geocontainers.org/">geocontainers</a></strong>. Inspired by <a href="http://biodocker.org/">Biodocker</a>, geocontainers is intended to be a place to experiment and collaborate on containers without any initial rules or guidelines.</p>

<p>All of this is described in detail in <a href="http://www.slideshare.net/nuest/docker-foss4g-2016-bonn-public">his presentation</a>, which is also available as a <a href="http://ftp5.gwdg.de/pub/misc/openstreetmap/FOSS4G-2016/foss4g-2016-1146-an_overview_of_docker_images_for_geospatial_applications-hd.mp4">video recording</a>. Feedback welcome!</p>

<p><a href="http://ftp5.gwdg.de/pub/misc/openstreetmap/FOSS4G-2016/foss4g-2016-1146-an_overview_of_docker_images_for_geospatial_applications-hd.mp4"><img src="/public/images/2016-08_foss4g-video-docker.jpg" alt="presentation video screenshot" title="presentation video screenshot" width="600" /></a></p>

<p>The conference was excellently organized in <a href="http://www.worldccbonn.com/en/history.html">a great venue</a> which includes the former Plenary Chambers of the Bundestag. Indeed a very special place to meet the people behind the projects of Free and Open Source Software for Geospatial.</p>

<p><img src="/public/images/2016-09_foss4g-plenary-chamber.jpg" alt="FOSS4G keynote in Bundestag's old Plenary Chamber" title="FOSS4G keynote in Bundestag's old Plenary Chamber" width="600" /></p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2016/08/12/nodejs-orcid/">Summer break technical post: ORCID OAuth with passport.js</a></h3>
<span class="post-date">12 Aug 2016 | By Daniel N√ºst, Jan Koppe</span>
<p>With the University in a rather calm state during summer, the o2r team continues to work on the first prototypes for testing and demonstrating our ideas. This is the first post on a technical topic, and we will occasionally write about topics that are not related to the scientific work but either kept us busy for some time or might be useful to others.</p>

<p>Last week o2r team member Jan struggled with the implementation of the <strong>login feature</strong> for a <a href="https://nodejs.org/en">Node.js</a> <a href="https://en.wikipedia.org/wiki/Microservices">microservice</a>. <em>Why would we bother with that?</em>
<!--more-->Because we want to share our prototypes publicly and invite you to try them out, but at the same time not have to worry about one of your most valuable possessions: your password.</p>

<p>Therefore we decided early on to rely on <a href="http://oauthbible.com/#oauth-2-three-legged">three legged <strong>OAuth 2.0</strong></a> for handling user authentication. We opted for <a href="http://orcid.org/"><strong>ORCID</strong></a> as the authorization server because it is the most widespread identification for researchers today<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>, and because of the potential for useful integrations in the future<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup>.</p>

<p>The solution<sup id="fnref:3"><a href="#fn:3" class="footnote">3</a></sup> required to dig a bit deeper into the code of the used libraries, namely <a href="http://passportjs.org/">passport.js</a> with the plugin <a href="https://github.com/jaredhanson/passport-oauth4">passport-oauth4</a>. Jan summarizes everything nicely <a href="https://gist.github.com/JanKoppe/1491e37d1022c77a286087e6c81d6092">in <strong>this Gist</strong></a> and the working implementation is part of our component <a href="https://github.com/o2r-project/o2r-bouncer">o2r-bouncer</a>. The ORCID support team was even so kind to include our solution on their <a href="https://members.orcid.org/api/code-examples">code examples page</a> and we shared it with the <a href="https://groups.google.com/forum/#!topic/orcid-api-users/RRyhC-2L64U">ORCID API Users mailing list</a> in the hope that future developers will find this information helpful.</p>

<p>So in the end, a full day of work to figure out two missing lines of code, but still many days saved on bullet-proofing standalone authentication and password storage.</p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>The used libraries would allow us to quickly add more authorization services, such as Google or GitHub.¬†<a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>Wouldn‚Äôt you like to have a research container be automatically added to your publication list?¬†<a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p>In a nutshell, the <code class="highlighter-rouge">passReqToCallback</code> option must be enabled when creating the <code class="highlighter-rouge">OAuth4Strategy</code> and the <a href="https://github.com/o2r-project/o2r-bouncer/blob/dd3416e8a349aaa4a57ab8b061fe1556dd6d7041/index.js#L47">used callback function</a> must include 6 arguments. Only then the <a href="https://github.com/jaredhanson/passport-oauth4/blob/1eb4f22d5f6ca8bc6b08856f91779f67e5082fe0/lib/strategy.js#L184">function with the largest number of arguments</a> is used and the content of the accessToken-request answer, which includes the ORCID id and user name, is accessible in your own code. They can be found in the <code class="highlighter-rouge">params</code> parameter of the function, not as part of <code class="highlighter-rouge">profile</code> as one is used to with other OAuth servers. This seems to be a slight deviation from the standard by the ORCID folks.¬†<a href="#fnref:3" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2016/06/07/workshop-external-partners/">Feedback on and Focus for the o2r Vision</a></h3>
<span class="post-date">07 Jun 2016 | By Daniel N√ºst</span>
<p>A couple of weeks ago the <a href="/about">o2r team</a> met with a group of experts to discuss the project‚Äôs outline and scope. Being a few months into the project, the team members were eager to get feedback on their plans, which they created based on the original project proposal, the first practical evaluations, and extensive reviews of research literature. To give this feedback, we invited a group of external partners to a full day meeting at the  <a href="https://goo.gl/maps/jsBqYExXjR52">Wersehaus</a>, a small boathouse in the countryside next to the Werse river.</p>

<p><img src="/public/images/2016-05_o2r-workshop.jpg" alt="workshop participants group picture" title="o2r external partner workshop participants. image license: CC BY-NC-ND" width="400" /></p>
<p class="attributionInlineImage">Image is licensed under a <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" title="Creative Commons Attribution Non-Commercial No-Derivatives 4.0 International License">CC BY-NC-ND 4.0 International</a> license.</p>

<p>This workshop was already planned in the project proposal and proved to be worth the preparation and, first and foremost, the efforts of our guests to travel to M√ºnster. The external participants were<!--more--> <a href="https://twitter.com/xeniavanedig">Xenia van Edig</a> from <a href="http://www.copernicus.org/about_us.html">Copernicus</a>‚Äôs business development team, <a href="https://twitter.com/hkoers">Hylke Koers</a>, Head of Content Innovation at <a href="https://www.elsevier.com/">Elsevier</a>, <a href="http://geographicknowledge.de/">Simon Scheider</a> from the <a href="http://www.uu.nl/en/research/human-geography-and-spatial-planning">Department of Humany Geography and Spatial Planning at Utrecht University</a>, <a href="https://twitter.com/LinkedScience">Tomi Kauppinen</a> from the <a href="http://cs.aalto.fi/en/">Department of Computer Science at Aalto University</a>, and Werner Kuhn from the <a href="http://spatial.ucsb.edu/people/werner-kuhn/">Center for Spatial Studies at University of California, Santa Barbara</a>. The photo above also shows the o2r team members participating: Edzer Pebesma, Daniel N√ºst, Markus Konkol, Chris Kray (all ifgi), Holger Przibytzin, and Marc Schutzeichel (both ULB).</p>

<p>We started the day with talks by the external partners and project grantees. With such a select group, we were not surprised to get an excellent discussion rolling from the first talk on! You can download the talks‚Äô slides below if available, just click on the person‚Äôs name.</p>

<ul>
  <li><a href="/public/download/o2r-workshop-2016_lightning-talk_edzer-pebesma.pdf">Edzer</a> set the context of the project and took a look back at the motivation for the project (among which is personal annoyance!)</li>
  <li><a href="/public/download/o2r-workshop-2016_lightning-talk_werner-kuhn.pdf">Werner</a> discussed the products of research (hypotheses, software, data, narratives) and provided some claims on these that fueled a lively discussion.</li>
  <li><a href="/public/download/o2r-workshop-2016_lightning-talk_tomi-kauppinen.pdf">Tomi</a> approached reproducibility from the question ‚ÄúHow science works?‚Äù and connected it to his work on Linked Open Science (see also the original <a href="https://prezi.com/oaikop2s2ppa/my-take-on-reproducibility-presented-at-o2r-workhop/#">Prezi</a>).</li>
  <li>Holger introduced the interests and role of the university library in the project.</li>
  <li><a href="/public/download/o2r-workshop-2016_lightning-talk_xenia-van-edig.pdf">Xenia</a> presented different levels of open access publication workflows and shared experiences from the publication domain and enforcement of openness.</li>
  <li><a href="/public/download/o2r-workshop-2016_lightning-talk_hylke-koers.pdf">Hylke</a> talked about content innovation‚Äôs relation to reproducibility and showed a variety of work around interactivity in the article of the future.</li>
  <li><a href="/public/download/o2r-workshop-2016_lightning-talk_chris-kray.pdf">Chris</a> related reproducible research to ifgi‚Äôs vision of an open geoinformatics platform, and critically discussed benefits and challenges.</li>
</ul>

<p>We continued the day with intensive discussions on the project‚Äôs schedule for the first year, stretching across all aspects such as preservation metadata, usability and user interaction, and compendium specification. After lunch these areas were explored more deeply in an Open Space setting prepared by the projects full-time employees Marc, Markus, and Daniel. Afterwards we drilled deeper to identify potentials risks and their mitigations, as well as answering the crucial question: Where can the project have the largest impact?</p>

<p>We found that a narrow focus is crucial for the project to succeed. Since we‚Äôre not going to change the publishing landscape in one step and we want to make an impact in the community we know best, geoinformatics, we see these high priority goals for the foreseeable project‚Äôs future:</p>

<ul>
  <li>New means of <em>interaction with and exploration of scientific spatio-temporal data, analyses, and visualisations</em> based on linked research compendia contents.</li>
  <li><em>Automatic</em> (bordering on <a href="https://en.wikipedia.org/wiki/Clarke's_three_laws">magical</a>) <em>creation of executable research compendia</em> based on typical science workspaces for R-based geosciences.</li>
  <li>Specification of an <em>executable research compendium rooted firmly</em> in users‚Äô requirements, preservation requirements, the currently dominating procedures in scientific publications, and reality of highly diverse scientific workflows.</li>
  <li>New ways for <em>searching scientific work</em> based on the integrated and linked parts of a research compendium (text, code, data, user interface bindings).</li>
</ul>

<p><em>So what will we understand in two years time that we do not know now?</em></p>

<ul>
  <li>We have a good understanding of how far the process of creating research compendia can be automated, and what efforts remain for authors or preservationists that must be counterbalanced with incentives.</li>
  <li>We know the potential of user interface bindings as the connecting entity of research compendia.</li>
  <li>We show the improvements in discovery and understanding of research when all aspects of research are explicitly linked in a meaningful way.</li>
  <li>We get to know the common language as well as points of contact for the involved parties as we create a closer connection between research, preservation, and publication communities.</li>
</ul>

<p>What do you think? Ambitious goals, or nothing new? Give the new discussion feature below this post a try!</p>

<p>We thank again our guests for their valuable inputs. Having their backgrounds in research as well as scientific publishing, their critical evaluation helps us to shape a clear direction for our work. To keep in touch, follow us on <a href="https://twitter.com/o2r_project">Twitter</a> or <a href="https://github.com/o2r-project">GitHub</a>.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2016/05/20/daspos-workshop/">Container Strategies for Data &amp; Software Preservation that Promote Open Science (DASPOS workshop)</a></h3>
<span class="post-date">20 May 2016 | By Daniel N√ºst</span>
<p>In the last two days o2r team member <a href="https://nordholmen.net">Daniel</a> participated in a workshop organized by the project ‚ÄúData and Software Preservation Open Science‚Äù (<a href="https://daspos.crc.nd.edu">DASPOS</a>) at the University of Notre Dame, USA.
It was organized in an excellent fashion and in perfect amenities by the Center for Research Computing (<a href="https://crc.nd.edu/">CRC</a> at the University of Notre Dame.</p>

<p>The workshop title <em>‚ÄúContainer Strategies for Data &amp; Software Preservation that Promote Open Science‚Äù</em> fits perfectly with our own project goals, so Daniel was not surprised learn about a lot of great initiatives and projects.
A great group of researchers and librarians, mostly from the US, presented diverse topics almost all of which had one connection or another with o2r.
The general connecting feature between all participants were (Docker) containers and the interest in preservation.
Different approaches were presented in hands-on sessions, for example <a href="http://reprozip.org/">ReproZip</a>, <a href="https://daspos.crc.nd.edu/images/reports/umbrella-vtdc15.pdf">Umbrella</a> and the NDS Dashboard.
You can check the <a href="https://daspos.crc.nd.edu/index.php/workshops/container-strategies-for-data-software-preservation-that-promote-open-science">full schedule and participant list</a> for details.</p>

<p>A few highlights from Daniel‚Äôs perspective were the shared understanding that a common language and terms would be needed going forward when containerisation is applied more widely for openness and transparency of research.
But at the same time, and certainly at the current point in time of implementations, diversity is good and some amount of re-doing existing ‚Äúfeatures‚Äù is unavoidable.</p>

<p>You can find <a href="https://osf.io/h4u6w/">Daniel‚Äôs presentation</a> (also <a href="https://www.slideshare.net/nuest/opening-reproducible-research-lightning-talk-daspos-containerization-workshop-2016">on SlideShare</a>), as well as <a href="https://osf.io/y9mpx/">all other‚Äôs slides and other (reading) material</a>, on the Open Science Framework (OSF) website.
The presentations were recorded and you can watch Daniel‚Äôs talk as well as <a href="https://osf.io/upwdj/">all the others</a>:</p>

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/YuDdUqMGQAs?start=770" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>Daniel would like to thank the DASPOS team for the invitation and the excellent filming and transcribing.
It was a great experience to meet the leaders in the field.
The workshop was an awesome opportunity to share the o2r vision and to learn about other projects, ideas and concepts at this stage of our project.</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2016/05/02/egu-review/">Looking back at EGU General Assembly</a></h3>
<span class="post-date">02 May 2016</span>
<p>o2r team members Edzer Pebesma and Daniel N√ºst published a short blog article on <a href="https://r-spatial.org">r-spatial</a> about the project in general, and more specifically about the poster presented at EGU General Assembly <a href="/2016/04/08/o2r-at-EGU/">a couple of weeks ago</a>.</p>

<p>Read the blog here: <a href="https://r-spatial.org/r/2016/04/29/o2r.html">https://r-spatial.org/r/2016/04/29/o2r.html</a></p>

<p>The EGU poster is now also <a href="https://presentations.copernicus.org/EGU2016-7396_presentation.pdf">available for download on the EGU website</a>. The survey is also still running - please participate <a href="/2016/04/21/first-survey/">here</a>!</p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2016/04/21/first-survey/">Join our first survey</a></h3>
<span class="post-date">21 Apr 2016 | By Markus Konkol</span>
<p>Getting user input and evaluating our ideas is a crucial part of the project. Therefore, starting today, we run an <strong><a href="http://konkol.staff.ifgi.de/survey/index.php/811822?lang=en">online questionnaire</a></strong> investigating user interaction in the context of reproducible research. The survey is also advertised <a href="/2016/04/08/o2r-at-EGU/">this week at the EGU General Assembly</a>.</p>

<p>Please take a few minutes to help understanding reproducibility in geoscience research by participating in the <a href="http://konkol.staff.ifgi.de/survey/index.php/811822?lang=en">first o2r survey at https://o2r.info/survey</a>.</p>

<!-- ![survey link QR code](/public/images/qrcode-o2rinfoslashsurvey.svg){:width="100px"} -->


</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2016/04/08/o2r-at-EGU/">Opening Reproducible Research at EGU General Assembly 2016</a></h3>
<span class="post-date">08 Apr 2016 | By Daniel N√ºst</span>
<p><img src="http://blogs.egu.eu/geolog/files/2016/03/GA-twitter-700x400.jpg" alt="EGU logo" title="European Geophysical Union General Assembly 2016" width="300" class="img rightfloat" /> Next week the largest European geosciences conference of the year will take place in Vienna: the <a href="http://www.egu2016.eu/" title="EGU General 2016 Assembly Website">European Geophysical Union General Assembly 2016</a>. It takes place in the Austria Center Vienna for a full week and expects to welcome over <a href="http://media.egu.eu/" title="EGU General Assembly media information page">thirteen thousand scientists</a> from all over the world. A vast variety of research across all disciplines of the Earth, planetary and space sciences will be presented in a <a href="http://meetingorganizer.copernicus.org/EGU2016/meetingprogramme" title="General Assembly Programme">meeting programme</a> featuring workshops, lectures, talks, and posters.</p>

<p>One of the participants will be o2r team member Edzer Pebesma (<a href="https://twitter.com/edzerpebesma">@edzerpebesma</a> and <a href="http://r-spatial.org">http://r-spatial.org</a>).</p>

<p>Edzer presents our abstract <a href="http://meetingorganizer.copernicus.org/EGU2016/EGU2016-7396.pdf" title="Abstract PDF download"><em>‚ÄúOpening Reproducible Research‚Äù</em></a> in the poster session <a href="http://meetingorganizer.copernicus.org/EGU2016/posters/20148" title="Poster session description"><em>ESSI3.4 Open Access to Research Data and Public Sector Information towards Open Science</em></a> The session takes places on <em>Thursday, April 21st, from 17:30 to 19:00 in Hall A</em>. Make sure to drop by and get a glance at our first plans and the many other <a href="http://meetingorganizer.copernicus.org/EGU2016/orals/20148" title="Orals session description">talks</a> and <a href="http://meetingorganizer.copernicus.org/EGU2016/posters/20148" title="Poster session description">poster presentations</a> in this <a href="http://meetingorganizer.copernicus.org/EGU2016/session/20148" title="Session description">session</a>.</p>

<p>We look forward to the discussions about reproducible research and to get feedback about the project.</p>


</div>

<div style="page-break-before: always !important;"></div>

<div class="post">
<h3 class="post-title"><a href="/2016/01/19/introducing-o2r/">Introducing o2r</a></h3>
<span class="post-date">19 Jan 2016</span>
<p>Welcome to the new website of the research project <em>Opening Reproducible Research</em>.</p>

<p>You can learn the basics of the project and get to know the participants on the <a href="/about">About</a> page.</p>

<p>In short, we will develop new methods to make geosciences research reproducible. We will create open source tools and standards to compile text, data, and code (both sources and binary executables) into research compendia. These compendia will be easy to create for non-developers, executable in a web-based infrastructure, and allow exchanging of data and methods between compatible compendia.</p>

<p>You can follow our work on <a href="https://github.com/o2r-project">GitHub</a>.</p>

</div>

<div style="page-break-before: always !important;"></div>

<h2 id="website-pages">Website pages</h2>

<div class="page">
<h3 class="page-title">üîì About</h3>
<p>Opening Reproducible Research (o2r) is a project by the Institute for Geoinformatics (ifgi) and University and Regional Library (ULB) at the University of M√ºnster, Germany.</p>

<div style="display: flex; justify-content:space-between;">
  <a href="https://www.uni-muenster.de/Geoinformatics/" title="ifgi website"><img src="/public/images/ifgilogo.svg" height="80" alt="ifgi Logo" /></a>
  <a href="https://www.ulb.uni-muenster.de/" title="ULB website"><img src="/public/images/ulblogo.svg" height="80" alt="ULB Logo" /></a>
  <a href="https://www.uni-muenster.de/" title="WWU website"><img src="/public/images/wwulogo.svg" height="80" alt="WWU Logo" /></a>
</div>

<h4 id="goals">Goals</h4>

<p>Open access is not only a form of publishing such that research papers become available to the large public free of charge, it also refers to a trend in science that the act of doing research becomes more open and transparent when it comes to data and methods.
Increasingly, scientific results are generated by numerical manipulation of data that were already collected, and may involve simulation experiments that are entirely carried out computationally.
Reproducibility of research findings, the ability to repeat experimental procedures and confirm previously found results, is at the heart of the scientific method.</p>

<p>As opposed to the collection of experimental data in labs or nature, computational experiments lend themselves very well for reproduction. 
Some of the reasons why scientists do not publish data and computational procedures that allow reproduction will be hard to change, e.g. privacy concerns in the data, fear for embarrassment or of losing a competitive advantage.
Others reasons however involve technical aspects, and include the lack of standard procedures to publish such information and the lack of benefits after publishing them.
<em>We aim to resolve these two technical aspects.</em></p>

<p>We propose a system that supports the evolution of scientific publications from static papers into dynamic, executable research documents and aim for the main aspects of open access: improving the exchange of, facilitating productive access to, and simplifying reuse of research results that are published over the internet.</p>

<p>Building on existing open standards and software, this project develops standards and tools for executable research documents, and will demonstrate and evaluate these, initially focusing on the geosciences domains.
Building on recent advances in mainstream IT, o2r envisions a new architecture for storing, executing and interacting with the original analysis environment alongside the corresponding research data and manuscript.
<em>o2r bridges the gaps between long-term archiving, practical geoscientific research, and publication media.</em>
The o2r team collaborates with publishers to achieve the following goals:</p>

<ul>
  <li>Identify key barriers to working reproducibly</li>
  <li>Design and evaluate ways to overcome these barriers</li>
  <li>Develop approach to reap the benefits of reproducible research</li>
  <li>Implement platform that realises approach and test it</li>
</ul>

<p>Learn about the accomplishment of these goals on the <strong><a href="/results">results page</a></strong> and stay updated <a href="https://twitter.com/o2r_project">via Twitter</a>.</p>

<h4 id="open-source">Open Source</h4>

<p>For Open Science and reproducible research, we see not alternative to Open Source software.
All scripts, code, and libraries supporting a computational analysis must be open for scrutiny by fellow scientists.
We publish current code online, instead of holding back until publication of a paper, to profit from interaction with the Free and Open Source Software (FOSS) community.
Even the software of supported workflows (i.e. R) and underlying technologies (i.e. Docker) are published under FOSS principles.
Already in the project proposal, we set a clear agenda on the question of software licenses:</p>

<blockquote>
  <p>All software developed by project staff will be distributed under a permissive open source license that allows reuse, modification and integration in commercial systems (e.g., Apache 2.0). Development happens openly at GitHub and all developments are visible directly instead of after the end of the project.</p>
</blockquote>

<p>See our <a href="/results">results</a> page for more information about all software projects.</p>

<h4 id="people">People</h4>

<p>o2r team members, supporting university staff, and external advisory board members in alphabetical order.</p>

<h5 id="team">Team</h5>

<ul>
  <li>Juan Sebastian Garzon (student assistant, 2020-01 to ..)</li>
  <li>Philipp Glahe (student assistant, 2019-04 to 2019-09)</li>
  <li>Laura Goulier (student assistant, 2019-06 to ..)</li>
  <li>Nick Jakuschona (student assistant, 2019-04 to ..)</li>
  <li>Dr. Stephanie Kl√∂tgen (ULB)</li>
  <li><a href="http://www.uni-muenster.de/Geoinformatics/en/institute/staff/index.php/125/Markus_Konkol">Dr. Markus Konkol</a> (ifgi)</li>
  <li><a href="http://www.uni-muenster.de/Geoinformatics/institute/staff/index.php/118/Christian_Kray">Prof. Dr. Christian Kray</a> (ifgi)</li>
  <li>J√∂rg Lorenz (ULB)</li>
  <li>Tom Niers (student assistant, 2019-04 to ..)</li>
  <li><a href="http://www.uni-muenster.de/Geoinformatics/en/institute/staff/index.php/35/Daniel_N%C3%BCst">Daniel N√ºst</a> (ifgi)</li>
  <li><a href="http://www.uni-muenster.de/Geoinformatics/institute/staff/index.php/119/Edzer_Pebesma">Prof. Dr. Edzer Pebesma</a> (ifgi)</li>
  <li>Holger Przibytzin (ULB)</li>
  <li><a href="https://www.ulb.uni-muenster.de/~personal/troeger">Dr. Beate Tr√∂ger</a> (ULB)</li>
</ul>

<p><strong>Contact</strong>: <a href="mailto:o2r.team@uni-muenster.de">o2r.team@uni-muenster.de</a></p>

<p><a href="https://www.ulb.uni-muenster.de/"><img src="/public/images/ulblogo.svg" height="80" style="float: left" alt="ULB Logo" /></a></p>

<p><a href="https://www.uni-muenster.de/Geoinformatics/"><img src="/public/images/ifgilogo.svg" height="80" style="float: right" alt="ifgi Logo" /></a></p>

<div style="clear: both;"></div>

<h5 id="former-team-members">Former team members</h5>

<ul>
  <li>Rehan Chaudhary (ifgi, intern, 2017-01-17 to 2017-07-17)</li>
  <li>Matthias Hinz (ifgi, research assistant, 2016-12 to 2017-03)</li>
  <li>Jan Koppe (ifgi, student assistant, 2016-03 to 2016-08)</li>
  <li>Torben Kraft (ifgi, student assistant, 2017-01 to 2017-12)</li>
  <li>Timm K√ºhnel (ifgi, student assistant, 2017-01 to 2018-06)</li>
  <li>Lukas Lohoff (ULB, student assistant, 2016-12 to 2018-03)</li>
  <li>Yousef Qamaz (ifgi, student assistant, 2019-06 to 2020-03)</li>
  <li>Dr. Marc Schutzeichel (ULB, research associate, 2016-02 to 2018-01)</li>
  <li>Jan Suleiman (ifgi, student assistant, 2016-04 to 2017-12)</li>
</ul>

<h5 id="external-partners">External partners</h5>

<p>The o2r project is connected to external partners since its inception, and the group has been extended since then.
They come from different disciplines and provide valuable feedback on project plans and decisions.</p>

<p><a href="https://www.copernicus.org/"><img src="/public/images/logo_copernicus_publications_rgb.png" style="float:right;" height="30" alt="Copernicus Logo" /></a><a href="http://www.copernicus.org/contact_us.html">Dr. Xenia van Edig</a> (Business Development, Copernicus.org)</p>

<p><a href="http://sci.aalto.fi/en/"><img src="https://upload.wikimedia.org/wikipedia/en/thumb/2/2f/Aalto_University_School_of_Science.svg/137px-Aalto_University_School_of_Science.svg.png" style="float:right;" height="50" alt="Aalto University School of Science Logo" /></a><a href="http://www.kauppinen.net/tomi/">Dr. Tomi Kauppinen</a> (Department of Computer Science, Aalto University School of Science, Finland)</p>

<p><a href="http://spatial.ucsb.edu/"><img src="/public/images/spatial-ucsb-logo.jpg" style="float:right;" height="40" alt="Spatial@UCSB Logo" /></a> <a href="http://geog.ucsb.edu/~kuhn/">Prof. Dr. Werner Kuhn</a> (Center for Spatial Studies, University of California Santa Barbara, Santa Barbara, CA)</p>

<p><a href="http://www.ojs-de.net/"><img src="https://www.ojs-de.net/fileadmin/logos/logo-ojs-deDOTnet.svg" style="float:right;" width="60" alt="OJS-de.net Logo" /></a> Dr. Albert Geukes, <a href="https://www.cedis.fu-berlin.de/">CeDIS</a>, FU Berlin, Germany &amp; <a href="http://www.ojs-de.net/">OJS-de.net</a></p>

<p><a href="https://www.uu.nl/"><img src="https://www.uu.nl/medewerkers/static/img/logo.27b569c.svg" style="float:right;" width="100" alt="Universiteit Utrecht Logo" /></a><a href="https://www.uu.nl/staff/SScheider/Profile">Dr. Simon Scheider</a>, Department of Human Geography and Spatial Planning, Universiteit Utrecht, The Netherlands</p>

<p><a href="https://www.zib.de"><img src="https://www.zib.de/sites/all/themes/zib/images/zib_logo_header.png" style="float:right; background: #04879F;" height="50" alt="ZIB Logo" /></a><a href="https://www.zib.de/members/peters-kottig">Dr. Wolfgang Peters-Kottig</a>, Konrad-Zuse-Zentrum f√ºr Informationstechnik, Berlin, Germany</p>

<p><a href="http://elsevier.com/"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Elsevier.svg/218px-Elsevier.svg.png" style="float:right;" width="80" alt="Elsevier Logo" /></a> Laura Hassink, Senior Vice President Publishing Transformation at RELX (previously <a href="https://www.linkedin.com/in/maarten-cleeren-3bb39032/">Maarten Cleeren</a> - Director of Product Management, Enriched Content at Elsevier; <a href="https://www.linkedin.com/in/hylke-koers-b826141">Dr. Hylke Koers</a> - Head of Content Innovation, Elsevier)</p>

<div style="clear: both;"></div>

<h4 id="funding">Funding</h4>

<p>This project <em>Opening Reproducible Research</em> (see also <a href="https://gepris.dfg.de/gepris/projekt/274927273">Offene Reproduzierbare Forschung</a> and <a href="https://gepris.dfg.de/gepris/projekt/415851837">Offene Reproduzierbare Forschung II</a> @ DFG GEPRIS) receives funding by the German Research Foundation (Deutsche Forschungsgemeinschaft, DFG) under project numbers PE¬†1632/10-1, KR¬†3930/3-1 and TR¬†864/6-1 from 2016/01 to 2018/06, and under project numbers PE¬†1632/17-1, KR¬†3930/8-1, and TR¬†864/12-1 from 2019/04 to 2021.</p>

<p><a href="http://www.dfg.de"><img src="/public/images/dfg_logo_schriftzug_schwarz.png" alt="DFG Logo" /></a></p>

</div>

<div style="page-break-before: always !important;"></div>

<div class="page">
<h3 class="page-title">üöÄ Pilots</h3>
The primary objective of the second phase of the project [Opening Reproducible Research](https://o2r.info) (o2r) is _"Use ERCs for actual scientific publications"_.
In several work packages the o2r team will implement pilots.
In _collaboration pilots_, we work with publishers on Virtual Special Issues (VSIs).
In these VSIs, submitted articles will have [ERCs](/results) as supplemental material - an evolutionary use of ERCs.
In a _self-hosted pilot_, we want to realise a more revolutionary use of ERCs.
By extending [Open Journal Systems](https://pkp.sfu.ca/ojs/) (OJS), we make the ERC the item under review in a demonstration journal.
The pilots are supported by operating infrastructure and we will support authors, reviewers, and readers to enhance their scholarly communication with ERCs.

Together, the three pilots cover current publication practices from large scale publishers to independent journals.
The pilots are accompanied by monitoring and user studies and thereby provide crucial data to learn about the costs and benefits of ERC-based research publications.
All pilots require the integration of o2r services and tools in existing, established IT systems and organisational workflows - _we thank the collaborating publishers and editors as well as all authors and editors for their participation and open-mindedness!_

------

## Collaboration pilots

The diversity of the VSIs, potentially covering journals from a variety of geoscience disciplines, allows to reach the broad authorship and readership of the involved journals.
It evaluates the creation and inspection process for ERCs outside of a prototypical lab setting, so the technical infrastructure for ERCs is completely overhauled to support a growing number of users.

### Get help

If you have any questions please do not hesitate to contact us:

- ‚ùì Ask a question on [Stackoverflow](https://stackoverflow.com) using the tag [`erc`](https://stackoverflow.com/questions/tagged/erc) or [`executable-research-compendium`](https://stackoverflow.com/questions/tagged/executable-research-compendium).
- üì® Send us an email to **[o2r.support@uni-muenster.de](mailto:o2r.support@uni-muenster.de)** if you have specific questions you prefer not to share publicly.
- üí¨ Join our [public pilots chat room](https://gitter.im/o2r-project/pilots) on Gitter: [![Gitter]( {{ 'public/images/gitter-pilots.svg' | absolute_url }})](https://gitter.im/o2r-project/pilots)

### ‚úçÔ∏è Information for authors

The o2r team develops [_Author Guidelines for Creating ERCs_](https://docs.google.com/document/d/1skV3niWpQDYrtLWHob3UbP-Ejgbx1sG6opLcJ1WjZng/edit?usp=sharing).
Please also check below information for specific aspects for the different virtual special issues (see below), see our [call for almost reproducible papers](/almost) if you have doubts, and [contact us with any questions](#get-help).

### üïµÔ∏è Information for reviewers

The o2r team develops [_Reviewer Guidelines for Creating ERCs_](https://docs.google.com/document/d/1oXmg-V62UWCoHHstclDisrtNYZmjr2E1YuHxMw7O6dk/edit?usp=sharing).
Please also check below information for specific aspects for the different virtual special issues (see below) and [contact us with any questions](#get-help).

### Copernicus Publications Virtual Special Issue
<a name="copernicus">

**Status:** First review started with loose integration or ERC (communication of ERC URL via coverletter and handling editor)

**Participating journals:**

- [ESSD](https://www.earth-syst-sci-data.net/)

**Next steps:**

- _We are looking for more Copernicus journals to participate in the virtual special issue!_ See the [Open Call for Participation in Virtual Special Issue for Reproducible Research](/public/download/o2r-vsi_editors-wanted_EGU2019.pdf).
- Integration of ERC form field to submission forms and adding of extra reviewer questions to the review form.
- Direct display of ERCs from the article reading page.

### Elsevier virtual special issue
<a name="elsevier">

**Status:** Looking for collaborating journals

See the [informative leaflet for a virtual special issue for Elsevier journals based on containers and R](/public/download/o2r-vsi_elsevier-pilot.pdf).

------

## Self-hosted pilot

The self-hosted pilot replaces the traditional paper with ERCs.
It demonstrates ERCs' potential to stakeholders and provides a platform for evaluation of ERCs in education.
The self-hosted pilot will be used to investigate the impact of ERCs on understanding by preparing articles used in education as an ERC as a replacement or complement to reading material in a geoinformatics seminar.
We plan to partly replace the reading material, originally PDFs, in a MSc seminar at ifgi with ERCs and make these available in a self-hosted OJS installation featuring integration of ERCs.
The students will also make first experiences as academic authors when they submit they final project report as an ERC.

_The first plans for the self-hosted pilot based on OJS are described in this blog post: [https://o2r.info/2019/10/15/Opening-Reproducible-Research-with-OJS/](https://o2r.info/2019/10/15/Opening-Reproducible-Research-with-OJS/)._

#### üëâ We are open for collaborations with OJS journals
<a name="ojs">

_We are looking for feedback on these plans and are open for collaboration with OJS developers and OJS journal maintainers who are interested in enhanced reviews and publications powered by ERC on OJS._

&lt;/div&gt;

<div style="page-break-before: always !important;"></div>













<div class="page">
<h3 class="page-title">‚öôÔ∏è Results</h3>
## Publications &amp; theses

Please find a complete list of publications, talks and posters on the [üìÑ&nbsp;publications&nbsp;page](/publications) and respective files in the [o2r community on Zenodo](https://zenodo.org/communities/o2r/).

The [üìñ&nbsp;theses&nbsp;page](/theses) presents all BSc and MSc theses with a relation to o2r project goals and tasks.

## Specifications &amp; documentation

o2r is an open project, so all our components are openly developed [on GitHub]({{ site.github.org }}). The project's findings manifest themselves in the following core specifications and documents, all of which are under development.

- **[ERC specification](https://o2r.info/erc-spec)** ([source](https://github.com/o2r-project/erc-spec)) formally defines the Executable Research Compendium and provides some background.
- **[Architecture](https://o2r.info/architecture/)** ([source](https://github.com/o2r-project/architecture)) describes multiple levels of architecture, from the relation of our reprocibility service with other platforms down to internal microservices.
- **[Web API](https://o2r.info/api/)** ([source](https://github.com/o2r-project/api)) defines a RESTful API for our reproducibility service, also used by our platform client.

To cite the specifications and documentations please use

&gt; N√ºst, Daniel, 2018. Reproducibility Service for Executable Research Compendia: Technical Specifications and Reference Implementation. Zenodo. doi:[10.5281/zenodo.2203844](http://doi.org/10.5281/zenodo.2203844)

## Implementation &amp; demo

We develop a reference implementation of the mentioned specification as Open Source software on GitHub: **[{{ site.github.org }}]({{ site.github.org }})**

**Try the online demo at [https://o2r.uni-muenster.de](https://o2r.uni-muenster.de)** and if you are a developer find the web API endpoint at [<code>https://o2r.uni-muenster.de/api/v1/</code>](https://o2r.uni-muenster.de/api/v1/).

**Try it out on your own machine with the [reference-implementation](/2017/10/31/reference-implementation/)** (only Docker required!):

`git clone https://github.com/o2r-project/reference-implementation`
`docker-compose up`

Watch a short **video** of our platform prototype (turn on subtitles!):

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/Vy9b3pIWPd0?rel=0" frameborder="0" allowfullscreen=""></iframe>

To cite the reference implementation please use

&gt; N√ºst, Daniel, 2018. Reproducibility Service for Executable Research Compendia: Technical Specifications and Reference Implementation. Zenodo. doi:[10.5281/zenodo.2203844](http://doi.org/10.5281/zenodo.2203844)

## Software

Learn more about our projects on [Open Hub](https://www.openhub.net/orgs/o2r) and [GitHub](https://github.com/o2r-project), where we currently have <span id="gh-stats-repo-count">[NA]</span> repositories with <span id="gh-stats-forks-count">[NA]</span> forks using <span id="gh-stats-languages-count">[NA]</span> languages.

<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.1.0/jquery.js"></script>
<script type="text/javascript">
$(document).ready(function(){
    // get repo count
    $.ajax({
        type: "get",
        url: "https://api.github.com/orgs/o2r-project",
        success: function(data) {
            var repo_count = data.public_repos;
            $("#gh-stats-repo-count").html(repo_count);
        },
        error: function(err, status) {
            console.log("Error getting repo count from GitHub API: " + err);
        }
    });

    // get languages and forks
    $.ajax({
        type: "get",
        url: "https://api.github.com/users/o2r-project/repos?sort=pushed&per_page=100",
        success: function(data) {
            let languages = new Set();
            let forks = 0;
            data.forEach(function(item) {
                languages.add(item.language);
                forks += item.forks_count;
            });
            $("#gh-stats-languages-count").html(languages.size);
            $("#gh-stats-forks-count").html(forks);
        },
        error: function(err, status) {
            console.log("Error getting repo details from GitHub API: " + err);
        }
    });
});
</script>

<!--
<script type="text/javascript" src="https://www.openhub.net/orgs/o2r/widgets/portfolio_projects_activity?format=js"></script>
-->

</div>

<div style="page-break-before: always !important;"></div>











































































</a></a></a></div>
:ET