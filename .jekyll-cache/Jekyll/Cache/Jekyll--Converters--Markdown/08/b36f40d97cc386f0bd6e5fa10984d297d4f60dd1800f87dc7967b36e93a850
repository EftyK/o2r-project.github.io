I"€<p>The o2r project website‚Äôs first entry <a href="/2016/01/19/introducing-o2r/">Introducing o2r</a> was published <a href="https://www.timeanddate.com/date/durationresult.html?d1=19&amp;m1=1&amp;y1=2016&amp;d2=24&amp;m2=2&amp;y2=2019">1132 days ago</a>.
Since then we‚Äôve published short and long reports about events the o2r team participated in, advertised new scholarly publications we were lucky to have accepted in journals, and reported on results of workshops organised by o2r.
But there has also been some original content from time to time, such as the extensive articles on <a href="/2016/12/15/investigating-docker-and-R/">Docker and R</a>, which received several updates over the last years (some still pending), on the <a href="/2018/11/21/elife-sprint-integrating-stencila-and-binder/">integration of Stencila and Binder</a>, or on <a href="/2019/02/04/write-reproducible-manuscripts-for-copernicus-publications-journals/">writing reproducible articles for Copernicus Publications</a>.
These posts are a valuable output of the project, and contribute to the scholarly discussion.
Therefore, when it came to writing a report on the project‚Äôs activities and outputs, it was time to consider the <a href="https://en.wikipedia.org/wiki/Digital_preservation">preservation</a> of the project website and blog.
The website is built with <a href="http://jekyllrb.com/">Jekyll</a> (with Markdown source files) and <a href="https://github.com/o2r-project/o2r-project.github.io">hosted with GitHub pages</a>, but GitHub may disappear and Jekyll might stop working at some point.</p>

<p><em>So how can we archive the blog post and website in a sustainable way, without any manual interference?</em></p>

<p>Today‚Äôs blog post documents the steps to automatically deposit the sources, the HTML rendering, a PDF rendering, and the whole git repository in a new version of a <a href="https://doi.org/10.5281/zenodo.1485437">Zenodo deposit</a> with each new blog post using <a href="help.zenodo.org#versioning">Zenodo‚Äôs DOI versioning</a>.
The PDF was especially tricky but is very important, because the format is established for archival of content, while using the Zenodo API was pretty straightforward.
We hope the presented workflow might be useful for other websites and blogs in a scientific context.
It goes like this:</p>

<ol>
  <li>The <a href="https://en.wikipedia.org/wiki/Makefile">Makefile</a> target <code class="language-plaintext highlighter-rouge">update_zenodo_deposit</code> starts the whole process with <code class="language-plaintext highlighter-rouge">make update_zenodo_deposit</code>. It triggers several other make targets, some of which require two processes to run at the same time:</li>
  <li>Remove previously existing outputs (‚Äúclean‚Äù).</li>
  <li>Build the whole page with Jekyll and <a href="https://jekyllrb.com/docs/usage/">serve</a> it using a local web server.</li>
  <li>Create a PDF from the whole website from the local web server using <a href="https://wkhtmltopdf.org/"><code class="language-plaintext highlighter-rouge">wkhtmltopdf</code></a> and the special page <a href="/all_content">/all_content</a>, which renders <em>all</em> blog entries in a suitable layout together with an automatically compiled list of author names and all website pages, unless they are excluded from the menu (e.g. manual redirection/shortened URLs) or excluded from ‚Äúall pages‚Äù (e.g. the 404 page, blogroll, or publications list).</li>
  <li>Create a ZIP archive with the sources, HTML rendering and PDF capture.</li>
  <li>Run a Python script to upload the PDF and ZIP files to Zenodo using the <a href="http://developers.zenodo.org/">Zenodo API</a>, which includes several requests to retrieve the latest version metadata, check that there really is a new blog post, create a new deposit, remove the existing files in the deposit, upload the new files, and eventually publish the record.</li>
  <li>Kill the still running web server.</li>
</ol>

<p>For these steps to run automatically, the <del><a href="https://travis-ci.org/">Travis CI</a> configuration file, <a href="https://github.com/o2r-project/o2r-project.github.io/commit/5699871682178c500fe02fead163640cb480ea6f"><code class="language-plaintext highlighter-rouge">.travis.yml</code></a> (link to commit where Travis CI configuration was removed in favour of‚Ä¶)</del> the GitHub action configuration <a href="https://github.com/o2r-project/o2r-project.github.io/blob/master/.github/workflows/deposit.yml"><code class="language-plaintext highlighter-rouge">deposit.yml</code></a>, installs the required software environment to conduct all above steps during each change to the main branch.
A secure environment variable for the repository is used to store a Zenodo API key, so the build system can manipulate the record.
The first version of this record, including its description, authors, tags, etc., was created manually.</p>

<p><a href="https://doi.org/10.5281/zenodo.1485437"><img src="/public/images/2019-02_zenodo-record-screenshot.png" alt="Zenodo record screenshot" width="300" class="img rightfloat" /></a></p>

<p><em>So what is possible now?</em>
As pointed out in the citation note at the bottom of pages and posts, the Digital Object Identifier (<a href="https://en.wikipedia.org/wiki/Digital_object_identifier">DOI</a>) allows referencing the whole website or specific posts (via pages in the PDF) in scholarly publications.
Manual archival from a local computer is still possible by triggering the same make target.
As long as Zenodo exists, readers have access to all content published by the o2r research project on its website.</p>

<p>There are no specific next steps planned, but there‚Äôs surely room for improvement as the current workflow is pretty complex.
The post publication date is the trigger for a new version, so changes in a page such as <a href="/about">About</a> or in an existing post requires a manual triggering of the workflow (and commenting out the check for a new post) or wait for the next blog entry.
The created PDF <a href="https://github.com/o2r-project/o2r-project.github.io/issues/29">could be made compliant</a> with <a href="https://en.wikipedia.org/wiki/PDF/A">PDF/A</a>.
The control flow could also be implemented completely in Python instead of using multiple files and languages; a Python module might even properly manage the system dependencies.
Though large parts of the process are not limited to pages generated with Jekyll (the capturing and uploading), it might be effectively wrapped in a standalone Jekyll <a href="https://jekyllrb.com/docs/plugins/">Jekyll plugin</a>, or a combination of a Zenodo plugin together with the (stale?) <a href="https://github.com/abeMedia/jekyll-pdf"><code class="language-plaintext highlighter-rouge">jekyll-pdf</code> plugin</a>?
<em>Your feedback is very welcome!</em></p>
:ET